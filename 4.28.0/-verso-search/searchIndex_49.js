window.docContents[49].resolve({"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Command-Line-Interface--Building-and-Running":{"contents":"\n\nBuilds the specified facts of the specified targets.Each of the targets is specified by a string of the form:The optional @ and + markers can be used to disambiguate packages and modules from file paths as well as executables, and libraries, which are specified by name as target.\nIf not provided, package defaults to the workspace's root package.\nIf the same target name exists in multiple packages in the workspace, then the first occurrence of the target name found in a topological sort of the package dependency graph is selected.\nModule targets may also be specified by their filename, with an optional facet after a colon.The available facets depend on whether a package, library, executable, or module is to be built.\nThey are listed in the section on facets.When using the local artifact cache, the -o option saves a mappings file that tracks the inputs and outputs of each step in the build.\nThis file can be used with cache get and cache put to interact with a remote cache.\nThe mappings file is in JSON Lines format, with one valid JSON object per line, and its filename extension is conventionally .jsonl.\n\nTarget and Facet Specifications* a* The default facet(s) of target a\n* @a* The default targets of package a\n* +A* The Lean artifacts of module A (because the default facet of modules is leanArts)\n* @a/b* The default facet of target b of package a\n* @a/+A:c* The C file compiled from module A of package a\n* :foo* The root package's facet foo\n* A/B/C.lean:o* The compiled object code for the module in the file A/B/C.lean\n\n\n\nExits with code 0 if the workspace's root package has any default targets configured.\nErrors (with exit code 1) otherwise.check-build does not verify that the configured default targets are valid.\nIt merely verifies that at least one is specified.\n\n\n\n\n\nBuilds a set of targets, reporting progress on standard error and outputting the results on standard out.\nTarget results are output in the same order they are listed and end with a newline.\nIf --json is set, results are formatted as JSON.\nOtherwise, they are printed as raw strings.Targets which do not have output configured will be printed as an empty string or null.\nFor executable targets, the output is the path to the built executable.Targets are specified using the same syntax as in build.\n\nLooks for the executable target exe-target in the workspace, builds it if it is out of date, and then runs\nit with the given args in Lake's environment.See build for the syntax of target specifications and env for a description of how the environment is set up.\n\n\n\nIf no package is specified, deletes the build directories of every package in the workspace.\nOtherwise, it just deletes those of the specified packages.\n\n\n\nWhen cmd is provided, it is executed in the Lake environment with arguments args.If cmd is not provided, Lake prints the environment in which it runs tools.\nThis environment is system-specific.\n\n\n\nBuilds the imports of the given file and then runs lean on it using the workspace's root package's additional Lean arguments and the given args, in that order.\nThe lean process is executed in Lake's environment.\n\n","context":"Lean Reference\u0009Build Tools\u0009Lake\u0009Command-Line Interface","header":"24.1.2.6. Building and Running","id":"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Command-Line-Interface--Building-and-Running"},"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Command-Line-Interface--Development-Tools--Tests-and-Linters":{"contents":"\n\nTest the workspace's root package using its configured test driver.A test driver that is an executable will be built and then run with the package configuration's testDriverArgs plus the CLI args.\nA test driver that is a Lake script is run with the same arguments as an executable test driver.\nA library test driver will just be built; it is expected that tests are implemented such that failures cause the build to fail via elaboration-time errors.\n\n\n\nLint the workspace's root package using its configured lint driverA script lint driver will be run with the  package configuration's\nlintDriverArgs plus the CLI args. An executable lint driver will be\nbuilt and then run like a script.\n\n\n\nCheck if there is a properly configured test driverExits with code 0 if the workspace's root package has a properly\nconfigured lint driver. Errors (with code 1) otherwise.Does NOT verify that the configured test driver actually exists in the\npackage or its dependencies. It merely verifies that one is specified.This is useful for distinguishing between failing tests and incorrectly configured packages.\n\n\n\nCheck if there is a properly configured lint driverExits with code 0 if the workspace's root package has a properly\nconfigured lint driver. Errors (with code 1) otherwise.Does NOT verify that the configured lint driver actually exists in the\npackage or its dependencies. It merely verifies that one is specified.This is useful for distinguishing between failing lints and incorrectly configured packages.\n\n","context":"Lean Reference\u0009Build Tools\u0009Lake\u0009Command-Line Interface\u0009Development Tools","header":"24.1.2.8.1. Tests and Linters","id":"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Command-Line-Interface--Development-Tools--Tests-and-Linters"},"/Functors___-Monads-and--do--Notation/Varieties-of-Monads/#The-Lean-Language-Reference--Functors___-Monads-and--do--Notation--Varieties-of-Monads--Exceptions--___Finally___-Computations":{"contents":"Monads that provide the ability to ensure an action happens, regardless of exceptions or other\nfailures.MonadFinally.tryFinally' is used to desugar try ... finally ... syntax.Runs an action, ensuring that some other action always happens afterward.More specifically, tryFinally' x f runs x and then the “finally” computation f. If x\nsucceeds with some value a : α, f (some a) is returned. If x fails for m's definition of\nfailure, f none is returned.tryFinally' can be thought of as performing the same role as a finally block in an imperative\nprogramming language.\n\n","context":"Lean Reference\u0009Functors, Monads and  do -Notation\u0009Varieties of Monads\u0009Exceptions","header":"18.5.7.3. “Finally” Computations","id":"/Functors___-Monads-and--do--Notation/Varieties-of-Monads/#The-Lean-Language-Reference--Functors___-Monads-and--do--Notation--Varieties-of-Monads--Exceptions--___Finally___-Computations"},"/Namespaces-and-Sections/#section-variables":{"contents":"Section variables are parameters that are automatically added to declarations that mention them.\nThis occurs whether or not the option autoImplicit is true.\nSection variables may be implicit, strict implicit, or explicit; instance implicit section variables are treated specially.\n\nWhen the name of a section variable is encountered in a non-theorem declaration, it is added as a parameter.\nAny instance implicit section variables that mention the variable are also added.\nIf any of the variables that were added depend on other variables, then those variables are added as well; this process is iterated until no more dependencies remain.\nAll section variables are added in the order in which they are declared, before all other parameters.\nSection variables are added only when they occur in the statement of a theorem.\nOtherwise, modifying the proof of a theorem could change its statement if the proof term made use of a section variable.\n\nVariables are declared using the variable command.\n\nVariable Declarations\n\nThe bracketed binders allowed after variable match the syntax used in definition headers.\n\nSection VariablesIn this section, automatic implicit parameters are disabled, but a number of section variables are defined.section\nset_option autoImplicit false\nuniverse u\nvariable {α : Type u} (xs : List α) [Zero α] [Add α]\nBecause automatic implicit parameters are disabled and β is neither a section variable nor bound as a parameter of the function, the following definition fails:def addAll (lst : List β) : β :=\n  lst.foldr (init := 0) (· + ·)\nUnknown identifier `β`\n\nNote: It is not possible to treat `β` as an implicitly bound variable here because the `autoImplicit` option is set to `false`.\nOn the other hand, not even xs needs to be written directly in the definition when it uses the section variables:def addAll :=\n  xs.foldr (init := 0) (· + ·)\n\n\nTo add a section variable to a theorem even if it is not explicitly mentioned in the statement, mark the variable with the include command.\nAll variables marked for inclusion are added to all theorems.\nThe omit command removes the inclusion mark from a variable; it's typically a good idea to use it with in.\n\n\n\nIncluded and Omitted Section VariablesThis section's variables include a predicate as well as everything needed to prove that it holds universally, along with a useless extra assumption.section\nvariable {p : Nat → Prop}\nvariable (pZero : p 0) (pStep : ∀ n, p n → p (n + 1))\nvariable (pFifteen : p 15)\nHowever, only p is added to this theorem's assumptions, so it cannot be proved.theorem p_all : ∀ n, p n := by\n  intro n\n  induction n\nThe include command causes the additional assumptions to be added unconditionally:include pZero pStep pFifteen\n\ntheorem p_all : ∀ n, p n := by\n  intro n\n  induction n <;> simp [*]\nBecause the spurious assumption pFifteen was inserted, Lean issues a warning:automatically included section variable(s) unused in theorem `p_all`:\n  pFifteen\nconsider restructuring your `variable` declarations so that the variables are not in scope or explicitly omit them:\n  omit pFifteen in theorem ...\n\nNote: This linter can be disabled with `set_option linter.unusedSectionVars false`\nThis can be avoided by using omit to remove pFifteen:include pZero pStep pFifteen\n\nomit pFifteen in\ntheorem p_all : ∀ n, p n := by\n  intro n\n  induction n <;> simp [*]\nend\n\n\n\n\n","context":"Lean Reference\u0009Namespaces and Sections\u0009Section Scopes","header":"6.2.2. Section Variables","id":"/Namespaces-and-Sections/#section-variables"},"/The-Type-System/Inductive-Types/#mutual-inductive-types":{"contents":"Inductive types may be mutually recursive.\nMutually recursive definitions of inductive types are specified by defining the types in a mutual ... end block.\n\nMutually Defined Inductive TypesThe type EvenOddList in a prior example used a Boolean index to select whether the list in question should have an even or odd number of elements.\nThis distinction can also be expressed by the choice of one of two mutually inductive types EvenList and OddList:mutual\n  inductive EvenList (α : Type u) : Type u where\n    | nil : EvenList α\n    | cons : α → OddList α → EvenList α\n  inductive OddList (α : Type u) : Type u where\n    | cons : α → EvenList α → OddList α\nend\n\nexample : EvenList String := .cons \"x\" (.cons \"y\" .nil)\nexample : OddList String := .cons \"x\" (.cons \"y\" (.cons \"z\" .nil))\nexample : OddList String := .cons \"x\" (.cons \"y\" .nil)\nUnknown constant `OddList.nil`\n\nNote: Inferred this name from the expected resulting type of `.nil`:\n  OddList String\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Type System\u0009Inductive Types","header":"4.4.5. Mutual Inductive Types","id":"/The-Type-System/Inductive-Types/#mutual-inductive-types"},"/Type-Classes/Instance-Synthesis/#instance-synth":{"contents":"Instance synthesis is a recursive search procedure that either finds an instance for a given type class or fails.\nIn other words, given a type that is registered as a type class, instance synthesis attempts to construct a term with said type.\nIt respects reducibility: semireducible or irreducible definitions are not unfolded, so instances for a definition are not automatically treated as instances for its unfolding unless it is reducible.\nThere may be multiple possible instances for a given class; in this case, declared priorities and order of declaration are used as tiebreakers, in that order, with more recent instances taking precedence over earlier ones with the same priority.\n\nThis search procedure is efficient in the presence of diamonds and does not loop indefinitely when there are cycles.\nDiamonds occur when there is more than one route to a given goal, and cycles are situations when two instances each could be solved if the other were solved.\nDiamonds occur regularly in practice when encoding mathematical concepts using type classes, and Lean's coercion feature  naturally leads to cycles, e.g. between finite sets and finite multisets.\n\nInstance synthesis can be tested using the #synth command.\nAdditionally, inferInstance and inferInstanceAs can be used to synthesize an instance in a position where the instance itself is needed.\n\ninferInstance synthesizes a value of any target type by typeclass\ninference. This function has the same type signature as the identity\nfunction, but the square brackets on the [i : α] argument means that it will\nattempt to construct this argument by typeclass inference. (This will fail if\nα is not a class.) Example:#check (inferInstance : Inhabited Nat) -- Inhabited Nat\n\ndef foo : Inhabited (Nat × Nat) :=\n  inferInstance\n\nexample : foo.default = (default, default) :=\n  rfl\n\n\ninferInstanceAs α synthesizes a value of any target type by typeclass\ninference. This is just like inferInstance except that α is given\nexplicitly instead of being inferred from the target type. It is especially\nuseful when the target type is some α' which is definitionally equal to α,\nbut the instance we are looking for is only registered for α (because\ntypeclass search does not unfold most definitions, but definitional equality\ndoes.) Example:#check inferInstanceAs (Inhabited Nat) -- Inhabited Nat\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Type Classes","header":"10.3. Instance Synthesis","id":"/Type-Classes/Instance-Synthesis/#instance-synth"},"/ValidatingProofs/#The-Lean-Language-Reference--Validating-a-Lean-Proof--The-Blue-Double-Check-Marks--Comments":{"contents":"In the Visual Studio Code extension settings, the symbol can be changed.\nEditors other than VS Code may have a different indication.\n\nRunning build +Module, where Module refers to the file containing the theorem, and observing success without error messages or warnings provides the same guarantees.\n\n","context":"Lean Reference\u0009Validating a Lean Proof\u0009The Blue Double Check Marks","header":"Comments","id":"/ValidatingProofs/#The-Lean-Language-Reference--Validating-a-Lean-Proof--The-Blue-Double-Check-Marks--Comments"},"/platforms/#platforms":{"contents":"\n\n\n\n","context":"Lean Reference","header":"Supported Platforms","id":"/platforms/#platforms"},"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Other":{"contents":"* #7326 updates the release notes script to better indent PR\ndescriptions.* #7453 adds \"(kernel)\" to the message for the kernel-level application\ntype mismatch error.* #7769 fixes a number of bugs in the release automation scripts, adds a\nscript to merge tags into remote stable branches, and makes the main\nrelease_checklist.py script give suggestions to call the\nmerge_remote.py and release_steps.py scripts when needed.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.19.0 (2025-05-01)","header":"Other","id":"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Other"},"/releases/v4.27.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___27___0-_LPAR_2026-01-24_RPAR_--Other":{"contents":"* #11328 fixes freeing memory accidentally retained for each document\nversion in the language server on certain elaboration workloads. The\nissue must have existed since 4.18.0.* #11437 adds recording functionality such that shake can more\nprecisely track whether an import should be preserved solely for its\nattribute commands.* #11496 implements new flags and annotations for shake for use in\nMathlib:Options:\n--keep-implied\nPreserves existing imports that are implied by other imports and thus\nnot technically needed\nanymore--keep-prefix\nIf an import X would be replaced in favor of a more specific import\nX.Y... it implies,\npreserves the original import instead. More generally, prefers\ninserting import X even if it\nwas not part of the original imports as long as it was in the original\ntransitive import closure\nof the current module.--keep-public\nPreserves all public imports to avoid breaking changes for external\ndownstream modules--add-public\nAdds new imports as public if they have been in the original public\nclosure of that module.\nIn other words, public imports will not be removed from a module\nunless they are unused even\nin the private scope, and those that are removed will be re-added as\npublic in downstream\nmodules even if only needed in the private scope there. Unlike\n--keep-public, this may\nintroduce breaking changes but will still limit the number of inserted\nimports.Annotations:\nThe following annotations can be added to Lean files in order to\nconfigure the behavior of\nshake. Only the substring shake:  directly followed by a directive\nis checked for, so multiple\ndirectives can be mixed in one line such as -- shake: keep-downstream, shake: keep-all, and they\ncan be surrounded by arbitrary comments such as -- shake: keep (metaprogram output dependency).* module -- shake: keep-downstream:\nPreserves this module in all (current) downstream modules, adding new\nimports of it if needed.* module -- shake: keep-all:\nPreserves all existing imports in this module as is. New imports now\nneeded because of upstream\nchanges may still be added.* import X -- shake: keep:\nPreserves this specific import in the current module. The most common\nuse case is to preserve a\npublic import that will be needed in downstream modules to make sense\nof the output of a\nmetaprogram defined in this module. For example, if a tactic is\ndefined that may synthesize a\nreference to a theorem when run, there is no way for shake to detect\nthis by itself and the\nmodule of that theorem should be publicly imported and annotated with\nkeep in the tactic's\nmodule.public import X  -- shake: keep (metaprogram output dependency)\n\n...\n\nelab \\\"my_tactic\\\" : tactic => do\n... mkConst ``f -- f, defined in X, may appear in the output of\nthis tactic\n```* #11507 optimizes the filesystem accesses during importing for a ~3% win\non Linux, potentially more on other platforms.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.27.0 (2026-01-24)","header":"Other","id":"/releases/v4.27.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___27___0-_LPAR_2026-01-24_RPAR_--Other"},"/releases/v4.28.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___28___0-rc1-_LPAR_2026-01-26_RPAR_--Tactics":{"contents":"* #11664 adds support for Nat.cast in grind linarith. It now uses\n  Grind.OrderedRing.natCast_nonneg. Example:open Lean Grind Std\nattribute [instance] Semiring.natCast\n\nvariable [Lean.Grind.CommRing R] [LE R] [LT R] [LawfulOrderLT R] [IsLinearOrder R] [OrderedRing R]\n\nexample (a : Nat) : 0 ≤ (a : R) := by grind\nexample (a b : Nat) : 0 ≤ (a : R) + (b : R) := by grind\n* #11677 adds basic support for equality propagation in grind linarith\n  for the IntModule case. This covers only the basic case. See note in\n  the code.\n  We remark this feature is irrelevant for CommRing since grind ring\n  already has much better support for equality propagation.* #11678 fixes a bug in registerNonlinearOccsAt used to implement\n  grind lia. This issue was originally reported at:\n  https://leanprover.zulipchat.com/#narrow/channel/113489-new-members/topic/Weirdness.20with.20cutsat/near/562099515* #11691 fixes grind to support dot notation on declarations in the\n  lemma list.* #11700 adds a link to the grind docstring. The link directs users to\n  the section describing grind in the reference manual.* #11712 avoids invoking TC synthesis and other inference mechanisms in\n  the simprocs of bv_decide. This can give significant speedups on\n  problems that pressure these simprocs.* #11717 improves the performance of bv_decide's rewriter on large\n  problems.* #11736 fixes an issue where exact? would not suggest private\n  declarations defined in the current module.* #11739 turns even more commonly used bv_decide theorems that require\n  unification into fast simprocs\n  using syntactic equality. This pushes the overall performance across\n  sage/app7 to <= 1min10s for\n  every problem.* #11749 fixes a bug in the function selectNextSplit? used in grind.\n  It was incorrectly computing the generation of each candidate.* #11758 improves support for nonstandard Int/Nat instances in\n  grind and simp +arith.* #11765 implements user-defined grind attributes. They are useful for\n  users that want to implement tactics using the grind infrastructure\n  (e.g., progress* in Aeneas). New grind attributes are declared using\n  the commandregister_grind_attr my_grind\nThe command is similar to register_simp_attr. Recall that similar to\n  register_simp_attr, the new attribute cannot be used in the same file\n  it is declared.opaque f : Nat → Nat\nopaque g : Nat → Nat\n\n@[my_grind] theorem fax : f (f x) = f x := sorry\n\nexample theorem fax2 : f (f (f x)) = f x := by\n  fail_if_success grind\n  grind [my_grind]\n* #11769 uses the new support for user-defined grind attributes to\n  implement the default [grind] attribute.* #11770 implements support for user-defined attributes at\n  grind_pattern. After declaring a grind attribute with\n  register_grind_attr my_grind, one can write:grind_pattern [my_grind] fg => g (f x)\n* #11776 adds the attributes [grind norm] and [grind unfold] for\n  controlling the grind normalizer/preprocessor.* #11785 disables closed term extraction in the reflection terms used by\n  bv_decide. These terms do\n  not profit at all from closed term extraction but can in practice cause\n  thousands of new closed term\n  declarations which in turn slows down the compiler.* #11787 adds support for incrementally processing local declarations in\n  grind. Instead of processing all hypotheses at once during goal\n  initialization, grind now tracks which local declarations have been\n  processed via Goal.nextDeclIdx and provides APIs to process new\n  hypotheses incrementally.\n  This feature will be used by the new SymM monad for efficient symbolic\n  simulation.* #11788 introduces SymM, a new monad for implementing symbolic\n  simulators (e.g., verification condition generators) in Lean. The monad\n  addresses performance issues found in symbolic simulators built on top\n  of user-facing tactics like apply and intros.* #11792 adds isDebugEnabled for checking whether grind.debug is set\n  to true when grind was initialized.* #11793 adds functions for creating maximally shared terms from\n  maximally shared terms. It is more efficient than creating an expression\n  and then invoking shareCommon. We are going to use these functions for\n  implementing the symbolic simulation primitives.* #11797 simplifies AlphaShareCommon.State by separating the persistent\n  and transient parts of the state.* #11800 adds the function Sym.replaceS, which is similar to\n  replace_fn available in the kernel but assumes the input is maximally\n  shared and ensures the output is also maximally shared. The PR also\n  generalizes the AlphaShareBuilder API.* #11802 adds the function Sym.instantiateS and its variants, which are\n  similar to Expr.instantiate but assumes the input is maximally shared\n  and ensures the output is also maximally shared.* #11803 implements intro (and its variants) for SymM. These versions\n  do not use reduction or infer types, and ensure expressions are\n  maximally shared.* #11806 refactors the Goal type used in grind. The new\n  representation allows multiple goals with different metavariables to\n  share the same GoalState. This is useful for automation such as\n  symbolic simulator, where applying theorems create multiple goals that\n  inherit the same E-graph, congruence closure and solvers state, and\n  other accumulated facts.* #11810 adds a new transparency mode .none in which no definitions are\n  unfolded.* #11813 introduces a fast pattern matching and unification module for\n  the symbolic simulation framework (Sym). The design prioritizes\n  performance by using a two-phase approach:Phase 1 (Syntactic Matching)* Patterns use de Bruijn indices for expression variables and renamed\n  level params (_uvar.0, _uvar.1, ...) for universe variables* Matching is purely structural after reducible definitions are unfolded\n  during preprocessing* Universe levels treat max and imax as uninterpreted functions (no\n  AC reasoning)* Binders and term metavariables are deferred to Phase 2Phase 2 (Pending Constraints)* Handles binders (Miller patterns) and metavariable unification* Converts remaining de Bruijn variables to metavariables* Falls back to isDefEq when necessary* #11814 implements instantiateRevBetaS, which is similar to\n  instantiateRevS but beta-reduces nested applications whose function\n  becomes a lambda after substitution.* #11815 optimizes pattern matching by skipping proof and instance\n  arguments during Phase 1 (syntactic matching).* #11819 adds some basic infrastructure for a structural (and cheaper)\n  isDefEq predicate for pattern matching and unification in Sym.* #11820 adds optimized abstractFVars and abstractFVarsRange for\n  converting free variables to de Bruijn indices during pattern\n  matching/unification.* #11824 implements isDefEqS, a lightweight structural definitional\n  equality for the symbolic simulation framework. Unlike the full\n  isDefEq, it avoids expensive operations while still supporting Miller\n  pattern unification.* #11825 completes the new pattern matching and unification procedures\n  for the symbolic simulation framework using a two-phase approach.* #11833 fixes a few typos, adds missing docstrings, and adds a (simple)\n  missing optimization.* #11837 adds BackwardRule for efficient goal transformation via\n  backward chaining in SymM.* #11847 adds a new solverMode field to bv_decide's configuration,\n  allowing users to configure\n  the SAT solver for different kinds of workloads.* #11849 fixes missing zetaDelta support at the pattern\n  matching/unification procedure in the new Sym framework.* #11850 fixes a bug in the new pattern matching procedure for the Sym\n  framework. It was not correctly handling assigned metavariables during\n  pattern matching.* #11851 fixes Sym/Intro.lean support for have-declarations.* #11856 adds the basic infrastructure for the structural simplifier used\n  by the symbolic simulation (Sym) framework.* #11857 adds an incremental variant of shareCommon for expressions\n  constructed from already-shared subterms. We use this when an expression\n  e was produced by a Lean API (e.g., inferType, mkApp4) that does\n  not preserve maximal sharing, but the inputs to that API were already\n  maximally shared. Unlike shareCommon, this function does not use a\n  local Std.HashMap ExprPtr Expr to track visited nodes. This is more\n  efficient when the number of new (unshared) nodes is small, which is the\n  common case when wrapping API calls that build a few constructor nodes\n  around shared inputs.* #11858 changes bv_decide's heuristic for what kinds of structures to\n  split on to also allow\n  splitting on structures where the fields have dependently typed widths.\n  For example:structure Byte (w : Nat) where\n  /-- A two's complement integer value of width `w`. -/\n  val : BitVec w\n  /-- A per-bit poison mask of width `w`. -/\n  poison : BitVec w\nThis is to allow handling situations such as (x : Byte 8) where the\n  width becomes concrete after\n  splitting is done.* #11860 adds CongrInfo analysis for function applications in the\n  symbolic simulator framework. CongrInfo determines how to build\n  congruence proofs for rewriting subterms efficiently, categorizing\n  functions into:* none: no arguments can be rewritten (e.g., proofs)* fixedPrefix: common case where implicit/instance arguments form a\n  fixed prefix and explicit arguments can be rewritten (e.g., HAdd.hAdd,\n  Eq)* interlaced: rewritable and non-rewritable arguments alternate (e.g.,\n  HEq)* congrTheorem: uses auto-generated congruence theorems for functions\n  with dependent proof arguments (e.g., Array.eraseIdx)* #11866 implements the core simplification loop for the Sym framework,\n  with efficient congruence-based argument rewriting.* #11868 implements Sym.Simp.Theorem.rewrite? for rewriting terms using\n  equational theorems in Sym.* #11869 adds configuration flag Meta.Context.cacheInferType. You can\n  use it to disable the inferType cache at MetaM. We use this flag to\n  implement SymM because it has its own cache based on pointer equality.* #11878 documents assumptions made by the symbolic simulation framework\n  regarding structural matching and definitional equality.* #11880 adds a with_unfolding_none tactic that sets the transparency\n  mode to .none, in which no definitions are unfolded. This complements\n  the existing with_unfolding_all tactic and provides tactic-level\n  access to the TransparencyMode.none added in\n  https://github.com/leanprover/lean4/pull/11810.* #11881 fixes an issue where grind failed to prove f ≠ 0 from f * r\n  ≠ 0 when using Lean.Grind.CommSemiring, but succeeded with\n  Lean.Grind.Semiring.* #11884 adds discrimination tree support for the symbolic simulation\n  framework.\n  The new DiscrTree.lean module converts Pattern values into\n  discrimination\n  tree keys, treating proof/instance arguments and pattern variables as\n  wildcards\n  (Key.star). Motivation: efficient pattern retrieval during rewriting.* #11886 adds getMatch and getMatchWithExtra for retrieving patterns\n  from\n  discrimination trees in the symbolic simulation framework. \n  The PR also adds uses DiscrTree to implement indexing in Sym.simp.* #11888 refactors Sym.simp to make it more general and customizable.\n  It also moves the code\n  to its own subdirectory Meta/Sym/Simp.* #11889 improves the discrimination tree retrieval performance used by\n  Sym.simp.* #11890 ensures that Sym.simp checks thresholds for maximum recursion\n  depth and maximum number of steps. It also invokes checkSystem.\n  Additionally, this PR simplifies the main loop. Assigned metavariables\n  and zetaDelta reduction are now handled by installing pre/post\n  methods.* #11892 optimizes the construction on congruence proofs in simp.\n  It uses some of the ideas used in Sym.simp.* #11898 adds support for simplifying lambda expressions in Sym.simp.\n  It is much more efficient than standard simp for very large lambda\n  expressions with many binders. The key idea is to generate a custom\n  function extensionality theorem for the type of the lambda being\n  simplified.* #11900 adds a done flag to the result returned by Simprocs in\n  Sym.simp.* #11906 tries to minimize the number of expressions created at\n  AlphaShareCommon.* #11909 reorganizes the monad hierarchy for symbolic computation in\n  Lean.* #11911 minimizes the number of expression allocations performed by\n  replaceS and instantiateRevBetaS.* #11914 factors out the have-telescope support used in simp, and\n  implements it using the MonadSimp interface. The goal is to\n  use this nice infrastructure for both Meta.simp and Sym.simp.* #11918 filters deprecated lemmas from exact? and rw? suggestions.* #11920 implements support for simplifying have telescopes in\n  Sym.simp.* #11923 adds a new option to the function simpHaveTelescope in which\n  the have telescope is simplified in two passes:* In the first pass, only the values and the body are simplified.* In the second pass, unused declarations are eliminated.* #11932 eliminates super-linear kernel type checking overhead when\n  simplifying lambda expressions. I improved the proof term produced by\n  mkFunext. This function is used in Sym.simp when simplifying lambda\n  expressions.* #11946 adds a +locals configuration option to the grind tactic that\n  automatically adds all definitions from the current file as e-match\n  theorems. This provides a convenient alternative to manually adding\n  [local grind] attributes to each definition. In the form grind?\n  +locals, it is also helpful for discovering which local declarations it\n  may be useful to add [local grind] attributes to.* #11947 adds a +locals configuration option to the simp, simp_all,\n  and dsimp tactics that automatically adds all definitions from the\n  current file to unfold.* #11949 adds a new first_par tactic combinator that runs multiple\n  tactics in parallel and returns the first successful result (cancelling\n  the others).* #11950 implements simpForall and simpArrow in Sym.simp.* #11962 fixes library suggestions to include private proof-valued\n  structure fields.* #11967 implements a new strategy for simplifying have-telescopes in\n  Sym.simp that achieves linear kernel type-checking time instead of\n  quadratic.* #11974 optimizes congruence proof construction in Sym.simp by\n  avoiding\n  inferType calls on expressions that are less likely to be cached.\n  Instead of\n  inferring types of expressions like @HAdd.hAdd Nat Nat Nat instAdd 5,\n  we infer\n  the type of the function prefix @HAdd.hAdd Nat Nat Nat instAdd and\n  traverse\n  the forall telescope.* #11976 adds missing type checking for pattern variables during pattern\n  matching/unification to prevent incorrect matches.* #11985 implements support for auto-generated congruence theorems in\n  Sym.simp, enabling simplification of functions with complex argument\n  dependencies such as proof arguments and Decidable instances.* #11999 adds support for simplifying the arguments of over-applied and\n  under-applied function application terms in Sym.simp, completing the\n  implementation for all three congruence strategies (fixed prefix,\n  interlaced, and congruence theorems).* #12006 fixes the pretty-printing of the extract_lets tactic.\n  Previously, the pretty-printer would expect a space after the\n  extract_lets tactic, when it was followed by another tactic on the\n  same line: for example,\n  extract_lets; exact foo\n  would be changed to\n  extract_lets ; exact foo.* #12012 implements support for rewrite on over-applied terms in\n  Sym.simp. Example: rewriting id f a using id_eq.* #12031 adds Sym.Simp.evalGround, a simplification procedure for\n  evaluating ground terms of builtin numeric types. It is designed for\n  Sym.simp.* #12032 adds Dischargers to Sym.simp, and ensures the cached results\n  are consistent.* #12033 adds support for conditional rewriting rules to Sym.simp.* #12035 adds simpControl, a simproc that handles control-flow\n  expressions such as if-then-else. It simplifies conditions while\n  avoiding unnecessary work on branches that won't be taken.* #12039 implements match-expression simplification for Sym.simp.* #12040 adds simprocs for simplifying cond and dependent\n  if-then-else in Sym.simp.* #12053 adds support for offset terms in SymM. This is essential for\n  handling equational theorems for functions that pattern match on natural\n  numbers in Sym.simp. Without this, it cannot handle simple examples\n  such as pw (a + 2) where pw pattern matches on n+1.* #12077 implements simprocs for String and Char. It also ensures\n  reducible definitions are unfolded in SymM* #12096 cleanups temporary metavariables generated when applying\n  rewriting rules in Sym.simp.* #12099 ensures Sym.simpGoal does not use mkAppM. It also increases\n  the default number of maximum steps in Sym.simp.* #12100 adds a comparison between MetaM and SymM for a benchmark was\n  proposed during the Lean@Google Hackathon.* #12101 improves the the Sym.simp APIs. It is now easier to reuse the\n  simplifier cache between different simplification steps. We use the APIs\n  to improve the benchmark at #12100.* #12134 adds a new benchmark shallow_add_sub_cancel.lean that\n  demonstrates symbolic simulation using a shallow embedding into monadic\n  do notation, as opposed to the deep embedding approach in\n  add_sub_cancel.lean.* #12143 adds an API for building symbolic simulation engines and\n  verification\n  condition generators that leverage grind. The API wraps Sym\n  operations to\n  work with grind's Goal type, enabling lightweight symbolic execution\n  while\n  carrying grind state for discharge steps.* #12145 moves the pre-shared commonly used expressions from GrindM to\n  SymM.* #12147 adds a new API for helping users write focused rewrites.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.28.0-rc1 (2026-01-26)","header":"Tactics","id":"/releases/v4.28.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___28___0-rc1-_LPAR_2026-01-26_RPAR_--Tactics"}});