{"99":
 "<code>Option.some.{u} {α : Type u} (val : α) : Option α</code><span class=\"sep\"></span><code class=\"docstring\">Some value of type `α`. </code>",
 "98":
 "<code>ForInStep.done.{u} {α : Type u} : α → ForInStep α</code><span class=\"sep\"></span><code class=\"docstring\">The loop should terminate early.\n\n`ForInStep.done` is produced by uses of `break` or `return` in the loop body.\n</code>",
 "97":
 "<code>Membership.mem.{u, v} {α : outParam (Type u)} {γ : Type v} [self : Membership α γ] : γ → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The membership relation `a ∈ s : Prop` where `a : α`, `s : γ`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `∈` in identifiers is `mem`.</code>",
 "96":
 "<code>ite.{u} {α : Sort u} (c : Prop) [h : Decidable c] (t e : α) : α</code><span class=\"sep\"></span><code class=\"docstring\">`if c then t else e` is notation for `ite c t e`, \"if-then-else\", which decides to\nreturn `t` or `e` depending on whether `c` is true or false. The explicit argument\n`c : Prop` does not have any actual computational content, but there is an additional\n`[Decidable c]` argument synthesized by typeclass inference which actually\ndetermines how to evaluate `c` to true or false. Write `if h : c then t else e`\ninstead for a \"dependent if-then-else\" `dite`, which allows `t`/`e` to use the fact\nthat `c` is true/false.\n</code>",
 "95": "<code>PUnit</code>",
 "94":
 "<code>Std.HashSet Int → PUnit → Id (ForInStep (MProd (Option Bool) (Std.HashSet Int)))</code>",
 "93":
 "<code>MProd.snd.{u} {α β : Type u} (self : MProd α β) : β</code><span class=\"sep\"></span><code class=\"docstring\">The second element of a pair. </code>",
 "92":
 "<code>Option.none.{u} {α : Type u} : Option α</code><span class=\"sep\"></span><code class=\"docstring\">No value. </code>",
 "91": "<code>MProd (Option Bool) (Std.HashSet Int)</code>",
 "90":
 "<code>EmptyCollection.emptyCollection.{u} {α : Type u} [self : EmptyCollection α] : α</code><span class=\"sep\"></span><code class=\"docstring\">`∅` or `{}` is the empty set or empty collection.\nIt is supported by the `EmptyCollection` typeclass. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `{}` in identifiers is `empty`.\n\n * The recommended spelling of `∅` in identifiers is `empty`.</code>",
 "9":
 "<code class=\"docstring\">`return e` inside of a `do` block makes the surrounding block evaluate to `pure e`,\nskipping any further statements.\nNote that uses of the `do` keyword in other syntax like in `for _ in _ do`\ndo not constitute a surrounding block in this sense;\nin supported editors, the corresponding `do` keyword of the surrounding block\nis highlighted when hovering over `return`.\n\n`return` not followed by a term starting on the same line is equivalent to `return ()`.\n</code>",
 "89": "<code>Bool</code>",
 "88": "<code>nodup l = r</code>",
 "87":
 "<code>Iff (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">If and only if, or logical bi-implication. `a ↔ b` means that `a` implies `b` and vice versa.\nBy `propext`, this implies that `a` and `b` are equal and hence any expression involving `a`\nis equivalent to the corresponding expression with `b` instead.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `↔` in identifiers is `iff`.\n\n * The recommended spelling of `&lt;-&gt;` in identifiers is `iff` (prefer `↔` over `&lt;-&gt;`).</code>",
 "86": "<code>nodup_correct (l : List Int) : nodup l = true ↔ l.Nodup</code>",
 "85":
 "<code>Bool.true : Bool</code><span class=\"sep\"></span><code class=\"docstring\">The Boolean value `true`, not to be confused with the proposition `True`. </code>",
 "84":
 "<code>Std.HashSet.insert.{u} {α : Type u} {x✝ : BEq α} {x✝¹ : Hashable α} (m : Std.HashSet α) (a : α) : Std.HashSet α</code><span class=\"sep\"></span><code class=\"docstring\">Inserts the given element into the set. If the hash set already contains an element that is\nequal (with regard to `==`) to the given element, then the hash set is returned unchanged.\n\nNote: this non-replacement behavior is true for `HashSet` and `HashSet.Raw`.\nThe `insert` function on `HashMap`, `DHashMap`, `HashMap.Raw` and `DHashMap.Raw` behaves\ndifferently: it will overwrite an existing mapping.\n</code>",
 "83":
 "<code>Bool.false : Bool</code><span class=\"sep\"></span><code class=\"docstring\">The Boolean value `false`, not to be confused with the proposition `False`. </code>",
 "82": "<code>Int</code>",
 "81":
 "<code>Std.HashSet.{u} (α : Type u) [BEq α] [Hashable α] : Type u</code><span class=\"sep\"></span><code class=\"docstring\">Hash sets.\n\nThis is a simple separate-chaining hash table. The data of the hash set consists of a cached size\nand an array of buckets, where each bucket is a linked list of keys. The number of buckets\nis always a power of two. The hash set doubles its size upon inserting an element such that the\nnumber of elements is more than 75% of the number of buckets.\n\nThe hash table is backed by an `Array`. Users should make sure that the hash set is used linearly to\navoid expensive copies.\n\nThe hash set uses `==` (provided by the `BEq` typeclass) to compare elements and `hash` (provided by\nthe `Hashable` typeclass) to hash them. To ensure that the operations behave as expected, `==`\nshould be an equivalence relation and `a == b` should imply `hash a = hash b` (see also the\n`EquivBEq` and `LawfulHashable` typeclasses). Both of these conditions are automatic if the BEq\ninstance is lawful, i.e., if `a == b` implies `a = b`.\n\nThese hash sets contain a bundled well-formedness invariant, which means that they cannot\nbe used in nested inductive types. For these use cases, `Std.Data.HashSet.Raw` and\n`Std.Data.HashSet.Raw.WF` unbundle the invariant from the hash set. When in doubt, prefer\n`HashSet` over `HashSet.Raw`.\n</code>",
 "80": "<code>Std.HashSet Int</code>",
 "8":
 "<code class=\"docstring\">`for x in e do s`  iterates over `e` assuming `e`'s type has an instance of the `ForIn` typeclass.\n`break` and `continue` are supported inside `for` loops.\n`for x in e, x2 in e2, ... do s` iterates of the given collections in parallel,\nuntil at least one of them is exhausted.\nThe types of `e2` etc. must implement the `Std.ToStream` typeclass.\n</code>",
 "79":
 "<code>Bool : Type</code><span class=\"sep\"></span><code class=\"docstring\">The Boolean values, `true` and `false`.\n\nLogically speaking, this is equivalent to `Prop` (the type of propositions). The distinction is\npublic important for programming: both propositions and their proofs are erased in the code generator,\nwhile `Bool` corresponds to the Boolean type in most programming languages and carries precisely one\nbit of run-time information.\n</code>",
 "78":
 "<code>Int : Type</code><span class=\"sep\"></span><code class=\"docstring\">The integers.\n\nThis type is special-cased by the compiler and overridden with an efficient implementation. The\nruntime has a special representation for `Int` that stores “small” signed numbers directly, while\nlarger numbers use a fast arbitrary-precision arithmetic library (usually\n[GMP](https://gmplib.org/)). A “small number” is an integer that can be encoded with one fewer bits\nthan the platform's pointer size (i.e. 63 bits on 64-bit architectures and 31 bits on 32-bit\narchitectures).\n</code>",
 "77": "<code>List Int</code>",
 "76": "<code>nodup (l : List Int) : Bool</code>",
 "75":
 "<code>List.Nodup.{u} {α : Type u} : List α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The list has no duplicates: it contains every element at most once.\n\nIt is defined as `Pairwise (· ≠ ·)`: each element is unequal to all other elements.\n</code>",
 "74":
 "<code>Array.foldlM.{u, v, w} {α : Type u} {β : Type v} {m : Type v → Type w} [Monad m] (f : β → α → m β) (init : β)\n  (as : Array α) (start : Nat := 0) (stop : Nat := as.size) : m β</code><span class=\"sep\"></span><code class=\"docstring\">Folds a monadic function over a list from the left, accumulating a value starting with `init`. The\naccumulated value is combined with the each element of the list in order, using `f`.\n\nThe optional parameters `start` and `stop` control the region of the array to be folded. Folding\nproceeds from `start` (inclusive) to `stop` (exclusive), so no folding occurs unless `start &lt; stop`.\nBy default, the entire array is folded.\n\nExamples:\n```lean example\nexample [Monad m] (f : α → β → m α) :\n    Array.foldlM (m := m) f x₀ #[a, b, c] = (do\n      let x₁ ← f x₀ a\n      let x₂ ← f x₁ b\n      let x₃ ← f x₂ c\n      pure x₃)\n  := by rfl\n```\n\n```lean example\nexample [Monad m] (f : α → β → m α) :\n    Array.foldlM (m := m) f x₀ #[a, b, c] (start := 1) = (do\n      let x₁ ← f x₀ b\n      let x₂ ← f x₁ c\n      pure x₂)\n  := by rfl\n```\n</code>",
 "73":
 "<code>Array.foldl.{u, v} {α : Type u} {β : Type v} (f : β → α → β) (init : β) (as : Array α) (start : Nat := 0)\n  (stop : Nat := as.size) : β</code><span class=\"sep\"></span><code class=\"docstring\">Folds a function over an array from the left, accumulating a value starting with `init`. The\naccumulated value is combined with the each element of the array in order, using `f`.\n\nThe optional parameters `start` and `stop` control the region of the array to be folded. Folding\nproceeds from `start` (inclusive) to `stop` (exclusive), so no folding occurs unless `start &lt; stop`.\nBy default, the entire array is used.\n\nExamples:\n * `#[a, b, c].foldl f z  = f (f (f z a) b) c`\n * `#[1, 2, 3].foldl (· ++ toString ·) \"\" = \"123\"`\n * `#[1, 2, 3].foldl (s!\"({·} {·})\") \"\" = \"((( 1) 2) 3)\"`\n</code>",
 "72":
 "<code class=\"docstring\">Assuming `x` is a variable in the local context with an inductive type,\n`induction x` applies induction on `x` to the main goal,\nproducing one goal for each constructor of the inductive type,\nin which the target is replaced by a general instance of that constructor\nand an inductive hypothesis is added for each recursive argument to the constructor.\nIf the type of an element in the local context depends on `x`,\nthat element is reverted and reintroduced afterward,\nso that the inductive hypothesis incorporates that hypothesis as well.\n\nFor example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,\n`induction n` produces one goal with hypothesis `h : P 0` and target `Q 0`,\nand one goal with hypotheses `h : P (Nat.succ a)` and `ih₁ : P a → Q a` and target `Q (Nat.succ a)`.\nHere the names `a` and `ih₁` are chosen automatically and are not accessible.\nYou can use `with` to provide the variables names for each constructor.\n- `induction e`, where `e` is an expression instead of a variable,\n  generalizes `e` in the goal, and then performs induction on the resulting variable.\n- `induction e using r` allows the user to specify the principle of induction that should be used.\n  Here `r` should be a term whose result type must be of the form `C t`,\n  where `C` is a bound variable and `t` is a (possibly empty) sequence of bound variables\n- `induction e generalizing z₁ ... zₙ`, where `z₁ ... zₙ` are variables in the local context,\n  generalizes over `z₁ ... zₙ` before applying the induction but then introduces them in each goal.\n  In other words, the net effect is that each inductive hypothesis is generalized.\n- Given `x : Nat`, `induction x with | zero =&gt; tac₁ | succ x' ih =&gt; tac₂`\n  uses tactic `tac₁` for the `zero` case, and `tac₂` for the `succ` case.\n</code>",
 "71":
 "<code>∀ (out : Nat), List.foldl (fun x1 x2 =&gt; x1 + x2) out l = out + l.sum</code>",
 "70":
 "<code class=\"docstring\">Given a main goal `ctx ⊢ t`, `suffices h : t' from e` replaces the main goal with `ctx ⊢ t'`,\n`e` must have type `t` in the context `ctx, h : t'`.\n\nThe variant `suffices h : t' by tac` is a shorthand for `suffices h : t' from by tac`.\nIf `h :` is omitted, the name `this` is used.\n </code>",
 "7": "<code>Nat</code>",
 "69":
 "<code>List.foldl.{u, v} {α : Type u} {β : Type v} (f : α → β → α) (init : α) : List β → α</code><span class=\"sep\"></span><code class=\"docstring\">Folds a function over a list from the left, accumulating a value starting with `init`. The\naccumulated value is combined with the each element of the list in order, using `f`.\n\nExamples:\n * `[a, b, c].foldl f z  = f (f (f z a) b) c`\n * `[1, 2, 3].foldl (· ++ toString ·) \"\" = \"123\"`\n * `[1, 2, 3].foldl (s!\"({·} {·})\") \"\" = \"((( 1) 2) 3)\"`\n</code>",
 "68":
 "<code class=\"docstring\">The `simp` tactic uses lemmas and hypotheses to simplify the main goal target or\nnon-dependent hypotheses. It has many variants:\n- `simp` simplifies the main goal target using lemmas tagged with the attribute `[simp]`.\n- `simp [h₁, h₂, ..., hₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]` and the given `hᵢ`'s, where the `hᵢ`'s are expressions.-\n- If an `hᵢ` is a defined constant `f`, then `f` is unfolded. If `f` has equational lemmas associated\n  with it (and is not a projection or a `reducible` definition), these are used to rewrite with `f`.\n- `simp [*]` simplifies the main goal target using the lemmas tagged with the\n  attribute `[simp]` and all hypotheses.\n- `simp only [h₁, h₂, ..., hₙ]` is like `simp [h₁, h₂, ..., hₙ]` but does not use `[simp]` lemmas.\n- `simp [-id₁, ..., -idₙ]` simplifies the main goal target using the lemmas tagged\n  with the attribute `[simp]`, but removes the ones named `idᵢ`.\n- `simp at h₁ h₂ ... hₙ` simplifies the hypotheses `h₁ : T₁` ... `hₙ : Tₙ`. If\n  the target or another hypothesis depends on `hᵢ`, a new simplified hypothesis\n  `hᵢ` is introduced, but the old one remains in the local context.\n- `simp at *` simplifies all the hypotheses and the target.\n- `simp [*] at *` simplifies target and all (propositional) hypotheses using the\n  other hypotheses.\n</code>",
 "67":
 "<code>List Nat</code><span class=\"sep\"></span><code class=\"docstring\">Converts an `Array α` into a `List α` that contains the same elements in the same order.\n\nAt runtime, this is implemented by `Array.toListImpl` and is `O(n)` in the length of the\narray.\n</code>",
 "66":
 "<code>Array.mk.{u} {α : Type u} (toList : List α) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Converts a `List α` into an `Array α`.\n\nThe function `List.toArray` is preferred.\n\nAt runtime, this constructor is overridden by `List.toArrayImpl` and is `O(n)` in the length of\nthe list.\n</code>",
 "65":
 "<code class=\"docstring\">Assuming `x` is a variable in the local context with an inductive type,\n`cases x` splits the main goal, producing one goal for each constructor of the\ninductive type, in which the target is replaced by a general instance of that constructor.\nIf the type of an element in the local context depends on `x`,\nthat element is reverted and reintroduced afterward,\nso that the case split affects that hypothesis as well.\n`cases` detects unreachable cases and closes them automatically.\n\nFor example, given `n : Nat` and a goal with a hypothesis `h : P n` and target `Q n`,\n`cases n` produces one goal with hypothesis `h : P 0` and target `Q 0`,\nand one goal with hypothesis `h : P (Nat.succ a)` and target `Q (Nat.succ a)`.\nHere the name `a` is chosen automatically and is not accessible.\nYou can use `with` to provide the variables names for each constructor.\n- `cases e`, where `e` is an expression instead of a variable, generalizes `e` in the goal,\n  and then cases on the resulting variable.\n- Given `as : List α`, `cases as with | nil =&gt; tac₁ | cons a as' =&gt; tac₂`,\n  uses tactic `tac₁` for the `nil` case, and `tac₂` for the `cons` case,\n  and `a` and `as'` are used as names for the new variables introduced.\n- `cases h : e`, where `e` is a variable or an expression,\n  performs cases on `e` as above, but also adds a hypothesis `h : e = ...` to each goal,\n  where `...` is the constructor instance for that particular case.\n</code>",
 "64": "<code>mySum_correct_vanilla (l : Array Nat) : mySum l = l.sum</code>",
 "63":
 "<code class=\"docstring\">After `with`, there is an optional tactic that runs on all branches, and\nthen a list of alternatives.\n</code>",
 "62": "<code>mySum_correct_shorter (l : Array Nat) : mySum l = l.sum</code>",
 "61": "<code>mySum_correct_short (l : Array Nat) : mySum l = l.sum</code>",
 "60":
 "<code class=\"docstring\">`grind` is a tactic inspired by modern SMT solvers. **Picture a virtual whiteboard**:\nevery time grind discovers a new equality, inequality, or logical fact,\nit writes it on the board, groups together terms known to be equal,\nand lets each reasoning engine read from and contribute to the shared workspace.\nThese engines work together to handle equality reasoning, apply known theorems,\npropagate new facts, perform case analysis, and run specialized solvers\nfor domains like linear arithmetic and commutative rings.\n\n`grind` is *not* designed for goals whose search space explodes combinatorially,\nthink large pigeonhole instances, graph‑coloring reductions, high‑order N‑queens boards,\nor a 200‑variable Sudoku encoded as Boolean constraints.  Such encodings require\n thousands (or millions) of case‑splits that overwhelm `grind`’s branching search.\n\nFor **bit‑level or combinatorial problems**, consider using **`bv_decide`**.\n`bv_decide` calls a state‑of‑the‑art SAT solver (CaDiCaL) and then returns a\n*compact, machine‑checkable certificate*.\n\n### Equality reasoning\n\n`grind` uses **congruence closure** to track equalities between terms.\nWhen two terms are known to be equal, congruence closure automatically deduces\nequalities between more complex expressions built from them.\nFor example, if `a = b`, then congruence closure will also conclude that `f a` = `f b`\nfor any function `f`. This forms the foundation for efficient equality reasoning in `grind`.\nHere is an example:\n```\nexample (f : Nat → Nat) (h : a = b) : f (f b) = f (f a) := by\n  grind\n```\n\n### Applying theorems using E-matching\n\nTo apply existing theorems, `grind` uses a technique called **E-matching**,\nwhich finds matches for known theorem patterns while taking equalities into account.\nCombined with congruence closure, E-matching helps `grind` discover\nnon-obvious consequences of theorems and equalities automatically.\n\nConsider the following functions and theorems:\n```\ndef f (a : Nat) : Nat :=\n  a + 1\n\ndef g (a : Nat) : Nat :=\n  a - 1\n\n@[grind =]\ntheorem gf (x : Nat) : g (f x) = x := by\n  simp [f, g]\n```\nThe theorem `gf` asserts that `g (f x) = x` for all natural numbers `x`.\nThe attribute `[grind =]` instructs `grind` to use the left-hand side of the equation,\n`g (f x)`, as a pattern for E-matching.\nSuppose we now have a goal involving:\n```\nexample {a b} (h : f b = a) : g a = b := by\n  grind\n```\nAlthough `g a` is not an instance of the pattern `g (f x)`,\nit becomes one modulo the equation `f b = a`. By substituting `a`\nwith `f b` in `g a`, we obtain the term `g (f b)`,\nwhich matches the pattern `g (f x)` with the assignment `x := b`.\nThus, the theorem `gf` is instantiated with `x := b`,\nand the new equality `g (f b) = b` is asserted.\n`grind` then uses congruence closure to derive the implied equality\n`g a = g (f b)` and completes the proof.\n\nThe pattern used to instantiate theorems affects the effectiveness of `grind`.\nFor example, the pattern `g (f x)` is too restrictive in the following case:\nthe theorem `gf` will not be instantiated because the goal does not even\ncontain the function symbol `g`.\n\n```\nexample (h₁ : f b = a) (h₂ : f c = a) : b = c := by\n  grind\n```\n\nYou can use the command `grind_pattern` to manually select a pattern for a given theorem.\nIn the following example, we instruct `grind` to use `f x` as the pattern,\nallowing it to solve the goal automatically:\n```\ngrind_pattern gf =&gt; f x\n\nexample {a b c} (h₁ : f b = a) (h₂ : f c = a) : b = c := by\n  grind\n```\nYou can enable the option `trace.grind.ematch.instance` to make `grind` print a\ntrace message for each theorem instance it generates.\n\nYou can also specify a **multi-pattern** to control when `grind` should apply a theorem.\nA multi-pattern requires that all specified patterns are matched in the current context\nbefore the theorem is applied. This is useful for theorems such as transitivity rules,\nwhere multiple premises must be simultaneously present for the rule to apply.\nThe following example demonstrates this feature using a transitivity axiom for a binary relation `R`:\n```\nopaque R : Int → Int → Prop\naxiom Rtrans {x y z : Int} : R x y → R y z → R x z\n\ngrind_pattern Rtrans =&gt; R x y, R y z\n\nexample {a b c d} : R a b → R b c → R c d → R a d := by\n  grind\n```\nBy specifying the multi-pattern `R x y, R y z`, we instruct `grind` to\ninstantiate `Rtrans` only when both `R x y` and `R y z` are available in the context.\nIn the example, `grind` applies `Rtrans` to derive `R a c` from `R a b` and `R b c`,\nand can then repeat the same reasoning to deduce `R a d` from `R a c` and `R c d`.\n\nInstead of using `grind_pattern` to explicitly specify a pattern,\nyou can use the `@[grind]` attribute or one of its variants, which will use a heuristic to\ngenerate a (multi-)pattern. The complete list is available in the reference manual. The main ones are:\n\n- `@[grind →]` will select a multi-pattern from the hypotheses of the theorem (i.e. it will use the theorem for forwards reasoning).\n  In more detail, it will traverse the hypotheses of the theorem from left-to-right, and each time it encounters a minimal indexable\n  (i.e. has a constant as its head) subexpression which \"covers\" (i.e. fixes the value of) an argument which was not\n  previously covered, it will add that subexpression as a pattern, until all arguments have been covered.\n- `@[grind ←]` will select a multi-pattern from the conclusion of theorem (i.e. it will use the theorem for backwards reasoning).\n  This may fail if not all the arguments to the theorem appear in the conclusion.\n- `@[grind]` will traverse the conclusion and then the hypotheses left-to-right, adding patterns as they increase the coverage,\n  stopping when all arguments are covered.\n- `@[grind =]` checks that the conclusion of the theorem is an equality, and then uses the left-hand-side of the equality as a pattern.\n  This may fail if not all of the arguments appear in the left-hand-side.\n\nHere is the previous example again but using the attribute `[grind →]`\n```\nopaque R : Int → Int → Prop\n@[grind →] axiom Rtrans {x y z : Int} : R x y → R y z → R x z\n\nexample {a b c d} : R a b → R b c → R c d → R a d := by\n  grind\n```\n\nTo control theorem instantiation and avoid generating an unbounded number of instances,\n`grind` uses a generation counter. Terms in the original goal are assigned generation zero.\nWhen `grind` applies a theorem using terms of generation `≤ n`, any new terms it creates\nare assigned generation `n + 1`. This limits how far the tactic explores when applying\ntheorems and helps prevent an excessive number of instantiations.\n\n#### Key options:\n- `grind (ematch := &lt;num&gt;)` controls the number of E-matching rounds.\n- `grind [&lt;name&gt;, ...]` instructs `grind` to use the declaration `name` during E-matching.\n- `grind only [&lt;name&gt;, ...]` is like `grind [&lt;name&gt;, ...]` but does not use theorems tagged with `@[grind]`.\n- `grind (gen := &lt;num&gt;)` sets the maximum generation.\n\n### Linear integer arithmetic (`lia`)\n\n`grind` can solve goals that reduce to **linear integer arithmetic (LIA)** using an\nintegrated decision procedure called **`lia`**.  It understands\n\n* equalities   `p = 0`\n* inequalities  `p ≤ 0`\n* disequalities `p ≠ 0`\n* divisibility  `d ∣ p`\n\nThe solver incrementally assigns integer values to variables; when a partial\nassignment violates a constraint it adds a new, implied constraint and retries.\nThis *model-based* search is **complete for LIA**.\n\n#### Key options:\n\n* `grind -lia` disable the solver (useful for debugging)\n* `grind +qlia` accept rational models (shrinks the search space but is incomplete for ℤ)\n\n#### Examples:\n\n```\n-- Even + even is never odd.\nexample {x y : Int} : 2 * x + 4 * y ≠ 5 := by\n  grind\n\n-- Mixing equalities and inequalities.\nexample {x y : Int} :\n    2 * x + 3 * y = 0 → 1 ≤ x → y &lt; 1 := by\n  grind\n\n-- Reasoning with divisibility.\nexample (a b : Int) :\n    2 ∣ a + 1 → 2 ∣ b + a → ¬ 2 ∣ b + 2 * a := by\n  grind\n\nexample (x y : Int) :\n    27 ≤ 11*x + 13*y →\n    11*x + 13*y ≤ 45 →\n    -10 ≤ 7*x - 9*y →\n    7*x - 9*y ≤ 4 → False := by\n  grind\n\n-- Types that implement the `ToInt` type-class.\nexample (a b c : UInt64)\n    : a ≤ 2 → b ≤ 3 → c - a - b = 0 → c ≤ 5 := by\n  grind\n```\n\n### Algebraic solver (`ring`)\n\n`grind` ships with an algebraic solver nick-named **`ring`** for goals that can\nbe phrased as polynomial equations (or disequations) over commutative rings,\nsemirings, or fields.\n\n*Works out of the box*\nAll core numeric types and relevant Mathlib types already provide the required\ntype-class instances, so the solver is ready to use in most developments.\n\nWhat it can decide:\n\n* equalities of the form `p = q`\n* disequalities `p ≠ q`\n* basic reasoning under field inverses (`a / b := a * b⁻¹`)\n* goals that mix ring facts with other `grind` engines\n\n#### Key options:\n\n* `grind -ring` turn the solver off (useful when debugging)\n* `grind (ringSteps := n)` cap the number of steps performed by this procedure.\n\n#### Examples\n\n```\nopen Lean Grind\n\nexample [CommRing α] (x : α) : (x + 1) * (x - 1) = x^2 - 1 := by\n  grind\n\n-- Characteristic 256 means 16 * 16 = 0.\nexample [CommRing α] [IsCharP α 256] (x : α) :\n    (x + 16) * (x - 16) = x^2 := by\n  grind\n\n-- Works on built-in rings such as `UInt8`.\nexample (x : UInt8) : (x + 16) * (x - 16) = x^2 := by\n  grind\n\nexample [CommRing α] (a b c : α) :\n    a + b + c = 3 →\n    a^2 + b^2 + c^2 = 5 →\n    a^3 + b^3 + c^3 = 7 →\n    a^4 + b^4 = 9 - c^4 := by\n  grind\n\nexample [Field α] [NoNatZeroDivisors α] (a : α) :\n    1 / a + 1 / (2 * a) = 3 / (2 * a) := by\n  grind\n```\n\n### Other options\n\n- `grind (splits := &lt;num&gt;)` caps the *depth* of the search tree.  Once a branch performs `num` splits\n  `grind` stops splitting further in that branch.\n- `grind -splitIte` disables case splitting on if-then-else expressions.\n- `grind -splitMatch` disables case splitting on `match` expressions.\n- `grind +splitImp` instructs `grind` to split on any hypothesis `A → B` whose antecedent `A` is **propositional**.\n- `grind -linarith` disables the linear arithmetic solver for (ordered) modules and rings.\n\n### Additional Examples\n\n```\nexample {a b} {as bs : List α} : (as ++ bs ++ [b]).getLastD a = b := by\n  grind\n\nexample (x : BitVec (w+1)) : (BitVec.cons x.msb (x.setWidth w)) = x := by\n  grind\n\nexample (as : Array α) (lo hi i j : Nat) :\n    lo ≤ i → i &lt; j → j ≤ hi → j &lt; as.size → min lo (as.size - 1) ≤ i := by\n  grind\n```\n</code>",
 "6":
 "<code>Id.run.{u_1} {α : Type u_1} (x : Id α) : α</code><span class=\"sep\"></span><code class=\"docstring\">Runs a computation in the identity monad.\n\nThis function is the identity function. Because its parameter has type `Id α`, it causes\n`do`-notation in its arguments to use the `Monad Id` instance.\n</code>",
 "59": "<code>pref✝.sum = b✝</code>",
 "58": "<code>l.toList.sum = r✝</code>",
 "57":
 "<code class=\"docstring\">Leaves the stateful proof mode of `Std.Do.SPred`, tries to eta-expand through all definitions\nrelated to the logic of the `Std.Do.SPred` and gently simplifies the resulting pure Lean\nproposition. This is often the right thing to do after `mvcgen` in order for automation to prove\nthe goal.\n</code>",
 "56":
 "<code class=\"docstring\">`all_goals tac` runs `tac` on each goal, concatenating the resulting goals.\nIf the tactic fails on any goal, the entire `all_goals` tactic fails.\n\nSee also `any_goals tac`.\n</code>",
 "55":
 "<code>List.sum.{u_1} {α : Type u_1} [Add α] [Zero α] : List α → α</code><span class=\"sep\"></span><code class=\"docstring\">Computes the sum of the elements of a list.\n\nExamples:\n* `[a, b, c].sum = a + (b + (c + 0))`\n* `[1, 2, 5].sum = 8`\n</code>",
 "54":
 "<code>List.Cursor.prefix.{u} {α : Type u} {l : List α} (self : l.Cursor) : List α</code><span class=\"sep\"></span><code class=\"docstring\">The elements before to the current position in the list.\n</code>",
 "53": "<code>l.toList.Cursor</code>",
 "52":
 "<code class=\"docstring\">`exact e` closes the main goal if its target type matches that of `e`.\n</code>",
 "514": "<code>autoParam (a ∈ m) findIdx._auto_1</code>",
 "513":
 "<code>IndexMap.findIdx_insert_self.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) (b : β) : (m.insert a b).findIdx a ⋯ = if h : a ∈ m then m.findIdx a h else m.size</code>",
 "512":
 "<code>IndexMap.getElem_insert.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a a' : α) (b : β) (h : a' ∈ m.insert a b) :\n  (m.insert a b)[a'] = if h' : (a' == a) = true then b else m[a']</code>",
 "511":
 "<code>IndexMap.mem_insert.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a a' : α) (b : β) : a' ∈ m.insert a b ↔ a' = a ∨ a' ∈ m</code>",
 "510":
 "<code>IndexMap.getIdx_findIdx.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) (h : a ∈ m) : m.getIdx (m.findIdx a h) ⋯ = m[a]</code>",
 "51":
 "<code class=\"docstring\">* `case tag =&gt; tac` focuses on the goal with case name `tag` and solves it using `tac`,\n  or else fails.\n* `case tag x₁ ... xₙ =&gt; tac` additionally renames the `n` most recent hypotheses\n  with inaccessible names to the given names.\n* `case tag₁ | tag₂ =&gt; tac` is equivalent to `(case tag₁ =&gt; tac); (case tag₂ =&gt; tac)`.\n</code>",
 "509":
 "<code>IndexMap.findIdx.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α)\n  (h : a ∈ m := by get_elem_tactic) : Nat</code>",
 "508": "<code>m.keys[i]? = some a ↔ m.indices[a]? = some i</code>",
 "507": "<code>i &lt; m.keys.size</code>",
 "506":
 "<code>IndexMap.WF'.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] {m : IndexMap α β} [LawfulBEq α] [LawfulHashable α]\n  (i : Nat) (a : α) (h₁ : i &lt; m.keys.size) (h₂ : a ∈ m) : m.keys[i] = a ↔ m.indices[a] = i</code>",
 "505":
 "<code>Lean.Grind.Ring.OfSemiring.Q.{u} (α : Type u) [Lean.Grind.Semiring α] : Type u</code>",
 "504":
 "<code>Std.HashMap.contains_insert.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  [EquivBEq α] [LawfulHashable α] {k a : α} {v : β} : (m.insert k v).contains a = (k == a || m.contains a)</code>",
 "503":
 "<code>Std.HashMap.contains_erase.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  [EquivBEq α] [LawfulHashable α] {k a : α} : (m.erase k).contains a = (!k == a && m.contains a)</code>",
 "502":
 "<code>Option.none_beq_none.{u_1} {α : Type u_1} [BEq α] : (none == none) = true</code>",
 "501":
 "<code>Option.none_beq_some.{u_1} {α : Type u_1} [BEq α] (a : α) : (none == some a) = false</code>",
 "500":
 "<code>Option.some_beq_none.{u_1} {α : Type u_1} [BEq α] (a : α) : (some a == none) = false</code>",
 "50":
 "<code>l.toList ++ [] = l.toList</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "5":
 "<code>Nat : Type</code><span class=\"sep\"></span><code class=\"docstring\">The natural numbers, starting at zero.\n\nThis type is special-cased by both the kernel and the compiler, and overridden with an efficient\nimplementation. Both use a fast arbitrary-precision arithmetic library (usually\n[GMP](https://gmplib.org/)); at runtime, `Nat` values that are sufficiently small are unboxed.\n</code>",
 "499":
 "<code>Option.some_beq_some.{u_1} {α : Type u_1} [BEq α] {a b : α} : (some a == some b) = (a == b)</code>",
 "498":
 "<code>Array.getElem_pop.{u_1} {α : Type u_1} {xs : Array α} {i : Nat} (h : i &lt; xs.pop.size) : xs.pop[i] = xs[i]</code>",
 "497":
 "<code>Array.getElem_set.{u_1} {α : Type u_1} {xs : Array α} {i : Nat} (h' : i &lt; xs.size) {v : α} {j : Nat}\n  (h : j &lt; (xs.set i v h').size) : (xs.set i v h')[j] = if i = j then v else xs[j]</code>",
 "496":
 "<code>Std.HashMap.getElem_insert.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  [EquivBEq α] [LawfulHashable α] {k a : α} {v : β} {h₁ : a ∈ m.insert k v} :\n  (m.insert k v)[a] = if h₂ : (k == a) = true then v else m[a]</code>",
 "495":
 "<code>Std.HashMap.getElem_erase.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  [EquivBEq α] [LawfulHashable α] {k a : α} {h' : a ∈ m.erase k} : (m.erase k)[a] = m[a]</code>",
 "494":
 "<code>Array.getElem_mem.{u} {α : Type u} {xs : Array α} {i : Nat} (h : i &lt; xs.size) : xs[i] ∈ xs</code>",
 "493":
 "<code>Option.none_le.{u_1} {α : Type u_1} [LE α] {a : Option α} : none ≤ a</code>",
 "492":
 "<code>Option.not_some_le_none.{u_1} {α : Type u_1} [LE α] {a : α} : ¬some a ≤ none</code>",
 "491":
 "<code>Option.not_mem_none.{u_1} {α : Type u_1} (a : α) : ¬a ∈ none</code>",
 "490":
 "<code>Option.none_lt_some.{u_1} {α : Type u_1} [LT α] {a : α} : none &lt; some a</code>",
 "49":
 "<code>(Prod.fst ?inv1 ({ «prefix» := l.toList, suffix := [], property := ⋯ }, r✝)).down</code>",
 "489":
 "<code>Option.not_lt_none.{u_1} {α : Type u_1} [LT α] {a : Option α} : ¬a &lt; none</code>",
 "488":
 "<code>Std.HashMap.getElem?_erase.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  [EquivBEq α] [LawfulHashable α] {k a : α} : (m.erase k)[a]? = if (k == a) = true then none else m[a]?</code>",
 "487":
 "<code>Std.HashMap.mem_insert.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β} [EquivBEq α]\n  [LawfulHashable α] {k a : α} {v : β} : a ∈ m.insert k v ↔ (k == a) = true ∨ a ∈ m</code>",
 "486":
 "<code>Array.size_set.{u} {α : Type u} {xs : Array α} {i : Nat} {v : α} (h : i &lt; xs.size) : (xs.set i v h).size = xs.size</code>",
 "485":
 "<code>Array.size_pop.{u} {α : Type u} {xs : Array α} : xs.pop.size = xs.size - 1</code>",
 "484":
 "<code>Array.getElem?_eq_none.{u_1} {α : Type u_1} {i : Nat} {xs : Array α} (h : xs.size ≤ i) : xs[i]? = none</code>",
 "483":
 "<code>Array.size_pos_of_mem.{u_1} {α : Type u_1} {a : α} {xs : Array α} (h : a ∈ xs) : 0 &lt; xs.size</code>",
 "482":
 "<code>Option.some_lt_some.{u_1} {α : Type u_1} [LT α] {a b : α} : some a &lt; some b ↔ a &lt; b</code>",
 "481":
 "<code>Array.back_eq_getElem.{u_1} {α : Type u_1} {xs : Array α} (h : 0 &lt; xs.size) : xs.back h = xs[xs.size - 1]</code>",
 "480":
 "<code>Array.mem_or_eq_of_mem_set.{u_1} {α : Type u_1} {xs : Array α} {i : Nat} {a b : α} {w : i &lt; xs.size}\n  (h : a ∈ xs.set i b w) : a ∈ xs ∨ a = b</code>",
 "48":
 "<code>[] ++ l.toList = [] ++ l.toList</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "479":
 "<code>Option.mem_some.{u_1} {α : Type u_1} {a b : α} : a ∈ some b ↔ b = a</code>",
 "478":
 "<code>Option.some_le_some.{u_1} {α : Type u_1} [LE α] {a b : α} : some a ≤ some b ↔ a ≤ b</code>",
 "477":
 "<code>IndexMap.size.eq_1.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) : m.size = m.values.size</code>",
 "476":
 "<code>getElem?_pos.{u_1, u_2, u_3} {cont : Type u_1} {idx : Type u_2} {elem : Type u_3} {dom : cont → idx → Prop}\n  [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom] (c : cont) (i : idx) (h : dom c i) : c[i]? = some c[i]</code>",
 "475":
 "<code>getElem?_neg.{u_1, u_2, u_3} {cont : Type u_1} {idx : Type u_2} {elem : Type u_3} {dom : cont → idx → Prop}\n  [GetElem? cont idx elem dom] [LawfulGetElem cont idx elem dom] (c : cont) (i : idx) (h : ¬dom c i) : c[i]? = none</code>",
 "474":
 "<code>Std.HashMap.mem_erase.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β} [EquivBEq α]\n  [LawfulHashable α] {k a : α} : a ∈ m.erase k ↔ (k == a) = false ∧ a ∈ m</code>",
 "473":
 "<code>Array.set_pop.{u_1} {α : Type u_1} {xs : Array α} {x : α} {i : Nat} (h : i &lt; xs.pop.size) :\n  xs.pop.set i x h = (xs.set i x ⋯).pop</code>",
 "472":
 "<code>Std.HashMap.getElem?_insert.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  [EquivBEq α] [LawfulHashable α] {k a : α} {v : β} : (m.insert k v)[a]? = if (k == a) = true then some v else m[a]?</code>",
 "471":
 "<code>Array.getElem?_set.{u_1} {α : Type u_1} {xs : Array α} {i : Nat} (h : i &lt; xs.size) {v : α} {j : Nat} :\n  (xs.set i v h)[j]? = if i = j then some v else xs[j]?</code>",
 "470":
 "<code>Array.getElem?_pop.{u_1} {α : Type u_1} {xs : Array α} {i : Nat} : xs.pop[i]? = if i &lt; xs.size - 1 then xs[i]? else none</code>",
 "47":
 "<code>List.nil.{u} {α : Type u} : List α</code><span class=\"sep\"></span><code class=\"docstring\">The empty list, usually written `[]`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `[]` in identifiers is `nil`.</code>",
 "469":
 "<code>Lean.Grind.Ring.OfSemiring.toQ.{u} {α : Type u} [Lean.Grind.Semiring α] (a : α) : Lean.Grind.Ring.OfSemiring.Q α</code>",
 "468": "<code>i_2 + 1 ≤ m.keys.pop.size</code>",
 "467": "<code>m.keys[i_2] ∈ m</code>",
 "466": "<code>m.keys[i_2] ∈ m.indices</code>",
 "465": "<code>i_2 + 1 ≤ (m.keys.set i (m.keys.back ⋯) ⋯).size</code>",
 "464":
 "<code>Bool.not : Bool → Bool</code><span class=\"sep\"></span><code class=\"docstring\">Boolean negation, also known as Boolean complement. `not x` can be written `!x`.\n\nThis is a function that maps the value `true` to `false` and the value `false` to `true`. The\npropositional connective is `Not : Prop → Prop`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `!` in identifiers is `not`.</code>",
 "463": "<code>i + 1 ≤ m.keys.size</code>",
 "462": "<code>i_2 + 1 ≤ m.keys.size</code>",
 "461": "<code>a ∈ m.indices</code>",
 "460": "<code>i_2 + 1 ≤ (m.keys.pop.set i (m.keys.back ⋯) ⋯).size</code>",
 "46":
 "<code>pref✝ ++ [cur✝] ++ suff✝ = l.toList</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "459": "<code>a_2 ∈ (m.indices.erase a).insert (m.keys.back ⋯) i</code>",
 "458": "<code>a_2 ∈ m.indices</code>",
 "457": "<code>(a == a_2) = false</code>",
 "456": "<code>a_2 ∈ m.indices.erase a</code>",
 "455": "<code>i + 1 ≤ m.keys.pop.size</code>",
 "454": "<code>(m.keys.back ⋯ == a_2) = true</code>",
 "453": "<code>¬m.indices[a]? = some i_2</code>",
 "452": "<code>¬m.keys[i_2]? = some a</code>",
 "451": "<code>¬i = i_2</code>",
 "450":
 "<code>¬((m.indices.erase a).insert (m.keys.back ⋯) i)[a_2]? = some i_2</code>",
 "45":
 "<code>ULift.down.{r, s} {α : Type s} (self : ULift α) : α</code><span class=\"sep\"></span><code class=\"docstring\">Extracts a wrapped value from a universe-lifted type. </code>",
 "449": "<code>(m.keys.pop.set i (m.keys.back ⋯) ⋯)[i_2]? = some a_2</code>",
 "448":
 "<code>NatCast.natCast.{u} {R : Type u} [self : NatCast R] : Nat → R</code><span class=\"sep\"></span><code class=\"docstring\">The canonical map `Nat → R`. </code>",
 "447":
 "<code>HMul.hMul.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HMul α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a * b` computes the product of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `*` in identifiers is `mul`.</code>",
 "446": "<code>-1 * ↑(m.keys.set i (m.keys.back ⋯) ⋯).size + 1 ≤ 0</code>",
 "445":
 "<code>((m.keys.pop.set i (m.keys.back ⋯) ⋯)[i_2]? = some a_2) =\n  ¬((m.indices.erase a).insert (m.keys.back ⋯) i)[a_2]? = some i_2</code>",
 "444":
 "<code>HSub.hSub.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HSub α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a - b` computes the difference of `a` and `b`.\nThe meaning of this notation is type-dependent.\n* For natural numbers, this operator saturates at 0: `a - b = 0` when `a ≤ b`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `-` in identifiers is `sub` (when used as a binary operator).</code>",
 "443": "<code>¬i = m.size - 1</code>",
 "442":
 "<code>GetElem?.getElem!.{u, v, w} {coll : Type u} {idx : Type v} {elem : outParam (Type w)}\n  {valid : outParam (coll → idx → Prop)} [self : GetElem? coll idx elem valid] [Inhabited elem] (xs : coll) (i : idx) :\n  elem</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]!` gets the `i`'th element of the collection `arr`,\nif it is present, and otherwise panics at runtime and returns the `default` term\nfrom `Inhabited elem`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `xs[i]!` in identifiers is `getElem!`.</code>",
 "441": "<code>Inhabited β</code>",
 "440":
 "<code>GetElem?.getElem?.{u, v, w} {coll : Type u} {idx : Type v} {elem : outParam (Type w)}\n  {valid : outParam (coll → idx → Prop)} [self : GetElem? coll idx elem valid] : coll → idx → Option elem</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]?` gets the `i`'th element of the collection `arr`,\nif it is present (and wraps it in `some`), and otherwise returns `none`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `xs[i]?` in identifiers is `getElem?`.</code>",
 "44":
 "<code>pref✝ ++ cur✝ :: suff✝ = l.toList</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "439": "<code>Decidable (i ∈ c)</code>",
 "438":
 "<code>IndexMap.getElem!_def.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  [Inhabited β] (m : IndexMap α β) (a : α) : m[a]! = (m.indices[a]?.bind fun x =&gt; m.values[x]?).getD default</code>",
 "437":
 "<code>IndexMap.getElem?_def.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) : m[a]? = m.indices[a]?.bind fun i =&gt; m.values[i]?</code>",
 "436":
 "<code>IndexMap.getElem_def.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) (h : a ∈ m) : m[a] = m.values[m.indices[a]]</code>",
 "435":
 "<code class=\"docstring\">`get_elem_tactic_extensible` is an extensible tactic automatically called\nby the notation `arr[i]` to prove any side conditions that arise when\nconstructing the term (e.g. the index is in bounds of the array).\nThe default behavior is to try `simp +arith` and `omega`\n(for doing linear arithmetic in the index).\n\n(Note that the core tactic `get_elem_tactic` has already tried\n`done` and `assumption` before the extensible tactic is called.)\n</code>",
 "434":
 "<code class=\"docstring\">The `grind_pattern` command can be used to manually select a pattern for theorem instantiation.\nEnabling the option `trace.grind.ematch.instance` causes `grind` to print a trace message for each\ntheorem instance it generates, which can be helpful when determining patterns.\n\nWhen multiple patterns are specified together, all of them must match in the current context before\n`grind` attempts to instantiate the theorem. This is referred to as a *multi-pattern*.\nThis is useful for theorems such as transitivity rules, where multiple premises must be simultaneously\npresent for the rule to apply.\n\nIn the following example, `R` is a transitive binary relation over `Int`.\n```\nopaque R : Int → Int → Prop\naxiom Rtrans {x y z : Int} : R x y → R y z → R x z\n```\nTo use the fact that `R` is transitive, `grind` must already be able to satisfy both premises.\nThis is represented using a multi-pattern:\n```\ngrind_pattern Rtrans =&gt; R x y, R y z\n\nexample {a b c d} : R a b → R b c → R c d → R a d := by\n  grind\n```\nThe multi-pattern `R x y`, `R y z` instructs `grind` to instantiate `Rtrans` only when both `R x y`\nand `R y z` are available in the context. In the example, `grind` applies `Rtrans` to derive `R a c`\nfrom `R a b` and `R b c`, and can then repeat the same reasoning to deduce `R a d` from `R a c` and\n`R c d`.\n\nYou can add constraints to restrict theorem instantiation. For example:\n```\ngrind_pattern extract_extract =&gt; (as.extract i j).extract k l where\n  as =/= #[]\n```\nThe constraint instructs `grind` to instantiate the theorem only if `as` is **not** definitionally equal\nto `#[]`.\n\n## Constraints\n\n- `x =/= term`: The term bound to `x` (one of the theorem parameters) is **not** definitionally equal to `term`.\n  The term may contain holes (i.e., `_`).\n\n- `x =?= term`: The term bound to `x` is definitionally equal to `term`.\n  The term may contain holes (i.e., `_`).\n\n- `size x &lt; n`: The term bound to `x` has size less than `n`. Implicit arguments\nand binder types are ignored when computing the size.\n\n- `depth x &lt; n`: The term bound to `x` has depth less than `n`.\n\n- `is_ground x`: The term bound to `x` does not contain local variables or meta-variables.\n\n- `is_value x`: The term bound to `x` is a value. That is, it is a constructor fully applied to value arguments,\na literal (`Nat`, `Int`, `String`, etc.), or a lambda `fun x =&gt; t`.\n\n- `is_strict_value x`: Similar to `is_value`, but without lambdas.\n\n- `not_value x`: The term bound to `x` is a **not** value (see `is_value`).\n\n- `not_strict_value x`: Similar to `not_value`, but without lambdas.\n\n- `gen &lt; n`: The theorem instance has generation less than `n`. Recall that each term is assigned a\ngeneration, and terms produced by theorem instantiation have a generation that is one greater than\nthe maximal generation of all the terms used to instantiate the theorem. This constraint complements\nthe `gen` option available in `grind`.\n\n- `max_insts &lt; n`: A new instance is generated only if less than `n` instances have been generated so far.\n\n- `guard e`: The instantiation is delayed until `grind` learns that `e` is `true` in this state.\n\n- `check e`: Similar to `guard e`, but `grind` checks whether `e` is implied by its current state by\nassuming `¬ e` and trying to deduce an inconsistency.\n\n## Example\n\nConsider the following example where `f` is a monotonic function\n```\nopaque f : Nat → Nat\naxiom fMono : x ≤ y → f x ≤ f y\n```\nand you want to instruct `grind` to instantiate `fMono` for every pair of terms `f x` and `f y` when\n`x ≤ y` and `x` is **not** definitionally equal to `y`. You can use\n```\ngrind_pattern fMono =&gt; f x, f y where\n  guard x ≤ y\n  x =/= y\n```\nThen, in the following example, only three instances are generated.\n```\n/--\ntrace: [grind.ematch.instance] fMono: a ≤ f a → f a ≤ f (f a)\n[grind.ematch.instance] fMono: f a ≤ f (f a) → f (f a) ≤ f (f (f a))\n[grind.ematch.instance] fMono: a ≤ f (f a) → f a ≤ f (f (f a))\n-/\n#guard_msgs in\nexample : f b = f c → a ≤ f a → f (f a) ≤ f (f (f a)) := by\n  set_option trace.grind.ematch.instance true in\n  grind\n```\n</code>",
 "433":
 "<code class=\"docstring\">The `have` tactic is for adding opaque definitions and hypotheses to the local context of the main goal.\nThe definitions forget their associated value and cannot be unfolded, unlike definitions added by the `let` tactic.\n\n* `have h : t := e` adds the hypothesis `h : t` if `e` is a term of type `t`.\n* `have h := e` uses the type of `e` for `t`.\n* `have : t := e` and `have := e` use `this` for the name of the hypothesis.\n* `have pat := e` for a pattern `pat` is equivalent to `match e with | pat =&gt; _`,\n  where `_` stands for the tactics that follow this one.\n  It is convenient for types that have only one applicable constructor.\n  For example, given `h : p ∧ q ∧ r`, `have ⟨h₁, h₂, h₃⟩ := h` produces the\n  hypotheses `h₁ : p`, `h₂ : q`, and `h₃ : r`.\n* The syntax `have (eq := h) pat := e` is equivalent to `match h : e with | pat =&gt; _`,\n  which adds the equation `h : e = pat` to the local context.\n\nThe tactic supports all the same syntax variants and options as the `have` term.\n\n## Properties and relations\n\n* It is not possible to unfold a variable introduced using `have`, since the definition's value is forgotten.\n  The `let` tactic introduces definitions that can be unfolded.\n* The `have h : t := e` is like doing `let h : t := e; clear_value h`.\n* The `have` tactic is preferred for propositions, and `let` is preferred for non-propositions.\n* Sometimes `have` is used for non-propositions to ensure that the variable is never unfolded,\n  which may be important for performance reasons.\n    Consider using the equivalent `let +nondep` to indicate the intent.\n\n</code>",
 "432":
 "<code>IndexMap.getElem_indices_lt.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] {m : IndexMap α β} {a : α}\n  [LawfulBEq α] [LawfulHashable α] {h : a ∈ m} : m.indices[a] &lt; m.size</code>",
 "431": "<code>Iff.rfl {a : Prop} : a ↔ a</code>",
 "430":
 "<code>IndexMap.mem_indices_of_mem.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] {m : IndexMap α β} {a : α} :\n  a ∈ m ↔ a ∈ m.indices</code>",
 "43":
 "<code>List Nat</code><span class=\"sep\"></span><code class=\"docstring\">The elements starting at the current position. If the position is after the last element of the\nlist, then the suffix is empty; otherwise, the first element of the suffix is the current element\nthat the cursor points to.\n</code>",
 "429":
 "<code>Std.HashMap.contains_iff_mem.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} {m : HashMap α β}\n  {a : α} : m.contains a = true ↔ a ∈ m</code>",
 "428": "<code>m.size ≤ m.indices[a]</code>",
 "427":
 "<code>IndexMap.getElem_indices_lt.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α)\n  (h : a ∈ m) : m.indices[a] &lt; m.size</code>",
 "426":
 "<code>IndexMap.size_keys.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] {m : IndexMap α β} : m.keys.size = m.size</code>",
 "425":
 "<code class=\"docstring\">Marks a theorem or definition for use by the `grind` tactic.\n\nAn optional modifier (e.g. `=`, `→`, `←`, `cases`, `intro`, `ext`, `inj`, etc.)\ncontrols how `grind` uses the declaration:\n* whether it is applied forwards, backwards, or both,\n* whether equalities are used on the left, right, or both sides,\n* whether case-splits, constructors, extensionality, or injectivity are applied,\n* or whether custom instantiation patterns are used.\n\nSee the individual modifier docstrings for details.\n</code>",
 "424":
 "<code>IndexMap.size_keys'.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (self : IndexMap α β) :\n  self.keys.size = self.values.size</code>",
 "423":
 "<code class=\"docstring\">`end` closes a `section` or `namespace` scope. If the scope is named `&lt;id&gt;`, it has to be closed\nwith `end &lt;id&gt;`. The `end` command is optional at the end of a file.\n</code>",
 "422":
 "<code>IndexMap.findIdx_insert_self.{u, v} {α : Type u} {β : Type v} [BEq α] [LawfulBEq α] [Hashable α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) (b : β) : (m.insert a b).findIdx a ⋯ = if h : a ∈ m then m.findIdx a h else m.size</code>",
 "421":
 "<code>BEq.beq.{u} {α : Type u} [self : BEq α] : α → α → Bool</code><span class=\"sep\"></span><code class=\"docstring\">Boolean equality, notated as `a == b`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `==` in identifiers is `beq`.</code>",
 "420": "<code>(a' == a) = true</code>",
 "42":
 "<code>List Nat</code><span class=\"sep\"></span><code class=\"docstring\">The elements before to the current position in the list.\n</code>",
 "419": "<code>a' ∈ m.insert a b</code>",
 "418":
 "<code>IndexMap.getElem_insert.{u, v} {α : Type u} {β : Type v} [BEq α] [LawfulBEq α] [Hashable α] [LawfulHashable α]\n  (m : IndexMap α β) (a a' : α) (b : β) (h : a' ∈ m.insert a b) :\n  (m.insert a b)[a'] = if h' : (a' == a) = true then b else m[a']</code>",
 "417":
 "<code>Or (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Or a b`, or `a ∨ b`, is the disjunction of propositions. There are two\nconstructors for `Or`, called `Or.inl : a → a ∨ b` and `Or.inr : b → a ∨ b`,\nand you can use `match` or `cases` to destruct an `Or` assumption into the\ntwo cases.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `∨` in identifiers is `or`.\n\n * The recommended spelling of `\\/` in identifiers is `or` (prefer `∨` over `\\/`).</code>",
 "416":
 "<code>IndexMap.mem_insert.{u, v} {α : Type u} {β : Type v} [BEq α] [LawfulBEq α] [Hashable α] [LawfulHashable α]\n  (m : IndexMap α β) (a a' : α) (b : β) : a' ∈ m.insert a b ↔ a' = a ∨ a' ∈ m</code>",
 "415":
 "<code>IndexMap.getIdx_findIdx.{u, v} {α : Type u} {β : Type v} [BEq α] [LawfulBEq α] [Hashable α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) (h : a ∈ m) : m.getIdx (m.findIdx a h) ⋯ = m[a]</code>",
 "414":
 "<code>∀ (i_1 : Nat) (a_1 : α),\n  (m.keys.pop.set i lastKey ⋯)[i_1]? = some a_1 ↔ ((m.indices.erase a).insert lastKey i)[a_1]? = some i_1</code>",
 "413":
 "<code>(m.keys.pop.set i lastKey ⋯).size = (m.values.pop.set i lastValue ⋯).size</code>",
 "412":
 "<code>Array.back.{u} {α : Type u} (xs : Array α) (h : 0 &lt; xs.size := by get_elem_tactic) : α</code><span class=\"sep\"></span><code class=\"docstring\">Returns the last element of an array, given a proof that the array is not empty.\n\nSee `Array.back!` for the version that panics if the array is empty, or `Array.back?` for the\nversion that returns an option.\n</code>",
 "411":
 "<code>∀ (i : Nat) (a_1 : α), m.keys.pop[i]? = some a_1 ↔ (m.indices.erase a)[a_1]? = some i</code>",
 "410": "<code>m.keys.pop.size = m.values.pop.size</code>",
 "41":
 "<code>List.Cursor.mk.{u} {α : Type u} {l : List α} («prefix» suffix : List α) (property : «prefix» ++ suffix = l) : l.Cursor</code>",
 "409":
 "<code>Array.pop.{u} {α : Type u} (xs : Array α) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Removes the last element of an array. If the array is empty, then it is returned unmodified. The\nmodification is performed in-place when the reference to the array is unique.\n\nExamples:\n* `#[1, 2, 3].pop = #[1, 2]`\n* `#[\"orange\", \"yellow\"].pop = #[\"orange\"]`\n* `(#[] : Array String).pop = #[]`\n</code>",
 "408":
 "<code>Std.HashMap.erase.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} (m : HashMap α β) (a : α) :\n  HashMap α β</code><span class=\"sep\"></span><code class=\"docstring\">Removes the mapping for the given key if it exists. </code>",
 "407": "<code>i = m.size - 1</code>",
 "406":
 "<code class=\"docstring\">\"Dependent\" if-then-else, normally written via the notation `if h : c then t(h) else e(h)`,\nis sugar for `dite c (fun h =&gt; t(h)) (fun h =&gt; e(h))`, and it is the same as\n`if c then t else e` except that `t` is allowed to depend on a proof `h : c`,\nand `e` can depend on `h : ¬c`. (Both branches use the same name for the hypothesis,\neven though it has different types in the two cases.)\n\nWe use this to be able to communicate the if-then-else condition to the branches.\nFor example, `Array.get arr i h` expects a proof `h : i &lt; arr.size` in order to\navoid a bounds check, so you can write `if h : i &lt; arr.size then arr.get i h else ...`\nto avoid the bounds check inside the if branch. (Of course in this case we have only\nlifted the check into an explicit `if`, but we could also use this proof multiple times\nor derive `i &lt; arr.size` from some other proposition that we are checking in the `if`.)\n</code>",
 "405":
 "<code>IndexMap.eraseSwap.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α) : IndexMap α β</code><span class=\"sep\"></span><code class=\"docstring\">Erase the key-value pair with the given key,\nmoving the last pair into its place in the order.\nIf the key is not present, the map is unchanged.\n</code>",
 "404":
 "<code>rfl.{u} {α : Sort u} {a : α} : a = a</code><span class=\"sep\"></span><code class=\"docstring\">`rfl : a = a` is the unique constructor of the equality type. This is the\nsame as `Eq.refl` except that it takes `a` implicitly instead of explicitly.\n\nThis is a more powerful theorem than it may appear at first, because although\nthe statement of the theorem is `a = a`, Lean will allow anything that is\ndefinitionally equal to that type. So, for instance, `2 + 2 = 4` is proven in\nLean by `rfl`, because both sides are the same up to definitional equality.\n</code>",
 "403":
 "<code>LawfulSingleton.mk.{u, v} {α : Type u} {β : Type v} [EmptyCollection β] [Insert α β] [Singleton α β]\n  (insert_empty_eq : ∀ (x : α), Insert.insert x ∅ = {x}) : LawfulSingleton α β</code>",
 "402":
 "<code>LawfulSingleton.{u, v} (α : Type u) (β : Type v) [EmptyCollection β] [Insert α β] [Singleton α β] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`insert x ∅ = {x}` </code>",
 "401":
 "<code>Insert.mk.{u, v} {α : outParam (Type u)} {γ : Type v} (insert : α → γ → γ) : Insert α γ</code>",
 "400":
 "<code>Insert.{u, v} (α : outParam (Type u)) (γ : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Type class for the `insert` operation.\nUsed to implement the `{ a, b, c }` syntax.\n</code>",
 "40":
 "<code>Prod.mk.{u, v} {α : Type u} {β : Type v} (fst : α) (snd : β) : α × β</code><span class=\"sep\"></span><code class=\"docstring\">Constructs a pair. This is usually written `(x, y)` instead of `Prod.mk x y`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `(a, b)` in identifiers is `mk`.</code>",
 "4":
 "<code>Array.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`Array α` is the type of [dynamic arrays](https://en.wikipedia.org/wiki/Dynamic_array) with elements\nfrom `α`. This type has special support in the runtime.\n\nArrays perform best when unshared. As long as there is never more than one reference to an array,\nall updates will be performed _destructively_. This results in performance comparable to mutable\narrays in imperative programming languages.\n\nAn array has a size and a capacity. The size is the number of elements present in the array, while\nthe capacity is the amount of memory currently allocated for elements. The size is accessible via\n`Array.size`, but the capacity is not observable from Lean code. `Array.emptyWithCapacity n` creates\nan array which is equal to `#[]`, but internally allocates an array of capacity `n`. When the size\nexceeds the capacity, allocation is required to grow the array.\n\nFrom the point of view of proofs, `Array α` is just a wrapper around `List α`.\n</code>",
 "399":
 "<code>Singleton.mk.{u, v} {α : outParam (Type u)} {β : Type v} (singleton : α → β) : Singleton α β</code>",
 "398":
 "<code>Singleton.{u, v} (α : outParam (Type u)) (β : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Type class for the `singleton` operation.\nUsed to implement the `{ a, b, c }` syntax.\n</code>",
 "397":
 "<code>∀ (i : Nat) (a_1 : α), (m.keys.push a)[i]? = some a_1 ↔ (m.indices.insert a m.size)[a_1]? = some i</code>",
 "396": "<code>(m.keys.push a).size = (m.values.push b).size</code>",
 "395":
 "<code>Std.HashMap.insert.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} (m : HashMap α β) (a : α) (b : β) :\n  HashMap α β</code><span class=\"sep\"></span><code class=\"docstring\">Inserts the given mapping into the map. If there is already a mapping for the given key, then both\nkey and value will be replaced.\n\nNote: this replacement behavior is true for `HashMap`, `DHashMap`, `HashMap.Raw` and `DHashMap.Raw`.\nThe `insert` function on `HashSet` and `HashSet.Raw` behaves differently: it will return the set\nunchanged if a matching key is already present.\n</code>",
 "394":
 "<code>∀ (i_1 : Nat) (a_1 : α), (m.keys.set i a ⋯)[i_1]? = some a_1 ↔ m.indices[a_1]? = some i_1</code>",
 "393": "<code>(m.keys.set i a ⋯).size = (m.values.set i b ⋯).size</code>",
 "392":
 "<code>Array.set.{u_1} {α : Type u_1} (xs : Array α) (i : Nat) (v : α) (h : i &lt; xs.size := by get_elem_tactic) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Replaces the element at a given index in an array.\n\nNo bounds check is performed, but the function requires a proof that the index is in bounds. This\nproof can usually be omitted, and will be synthesized automatically.\n\nThe array is modified in-place if there are no other references to it.\n\nExamples:\n* `#[0, 1, 2].set 1 5 = #[0, 5, 2]`\n* `#[\"orange\", \"apple\"].set 1 \"grape\" = #[\"orange\", \"grape\"]`\n</code>",
 "391": "<code>m.indices[a]? = some i</code>",
 "390":
 "<code>IndexMap.insert.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α) (b : β) : IndexMap α β</code>",
 "39":
 "<code>Prod.fst.{u, v} {α : Type u} {β : Type v} (self : α × β) : α</code><span class=\"sep\"></span><code class=\"docstring\">The first element of a pair. </code>",
 "389":
 "<code>∀ [inst : Inhabited β] (c : IndexMap α β) (i : α),\n  c[i]! =\n    match c[i]? with\n    | some e =&gt; e\n    | none =&gt; default</code><span class=\"sep\"></span><code class=\"docstring\">`GetElem?.getElem!` succeeds and fails when `GetElem.getElem?` succeeds and fails. </code>",
 "388":
 "<code>∀ (c : IndexMap α β) (i : α) [inst : Decidable (i ∈ c)], c[i]? = if h : i ∈ c then some c[i] else none</code><span class=\"sep\"></span><code class=\"docstring\">`GetElem?.getElem?` succeeds when the validity predicate is satisfied and fails otherwise. </code>",
 "387":
 "<code>LawfulGetElem.{u, v, w} (cont : Type u) (idx : Type v) (elem : outParam (Type w)) (dom : outParam (cont → idx → Prop))\n  [ge : GetElem? cont idx elem dom] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Lawful `GetElem?` instances (which extend `GetElem`) are those for which the potentially-failing\n`GetElem?.getElem?` and `GetElem?.getElem!` operators succeed when the validity predicate is\nsatisfied, and fail when it is not.\n</code>",
 "386":
 "<code>Inhabited.default.{u} {α : Sort u} [self : Inhabited α] : α</code><span class=\"sep\"></span><code class=\"docstring\">`default` is a function that produces a \"default\" element of any\n`Inhabited` type. This element does not have any particular specified\nproperties, but it is often an all-zeroes value. </code>",
 "385":
 "<code>Option.getD.{u_1} {α : Type u_1} (opt : Option α) (dflt : α) : α</code><span class=\"sep\"></span><code class=\"docstring\">Gets an optional value, returning a given default on `none`.\n\nThis function is `@[macro_inline]`, so `dflt` will not be evaluated unless `opt` turns out to be\n`none`.\n\nExamples:\n * `(some \"hello\").getD \"goodbye\" = \"hello\"`\n * `none.getD \"goodbye\" = \"goodbye\"`\n</code>",
 "384":
 "<code>[Inhabited β] → IndexMap α β → α → β</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]!` gets the `i`'th element of the collection `arr`,\nif it is present, and otherwise panics at runtime and returns the `default` term\nfrom `Inhabited elem`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `xs[i]!` in identifiers is `getElem!`.</code>",
 "383":
 "<code>Option.bind.{u_1, u_2} {α : Type u_1} {β : Type u_2} : Option α → (α → Option β) → Option β</code><span class=\"sep\"></span><code class=\"docstring\">Sequencing of `Option` computations.\n\nFrom the perspective of `Option` as computations that might fail, this function sequences\npotentially-failing computations, failing if either fails. From the perspective of `Option` as a\ncollection with at most one element, the function is applied to the element if present, and the\nfinal result is empty if either the initial or the resulting collections are empty.\n\nThis function is often accessed via the `&gt;&gt;=` operator from the `Bind (Option α)` instance, or\nimplicitly via `do`-notation, but it is also idiomatic to call it using [generalized field\nnotation](https://lean-lang.org/doc/reference/4.27.0-rc1/find/?domain=Verso.Genre.Manual.section&name=generalized-field-notation).\n\nExamples:\n * `none.bind (fun x =&gt; some x) = none`\n * `(some 4).bind (fun x =&gt; some x) = some 4`\n * `none.bind (Option.guard (· &gt; 2)) = none`\n * `(some 2).bind (Option.guard (· &gt; 2)) = none`\n * `(some 4).bind (Option.guard (· &gt; 2)) = some 4`\n</code>",
 "382":
 "<code>IndexMap α β → α → Option β</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]?` gets the `i`'th element of the collection `arr`,\nif it is present (and wraps it in `some`), and otherwise returns `none`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `xs[i]?` in identifiers is `getElem?`.</code>",
 "381":
 "<code>GetElem.getElem.{u, v, w} {coll : Type u} {idx : Type v} {elem : outParam (Type w)}\n  {valid : outParam (coll → idx → Prop)} [self : GetElem coll idx elem valid] (xs : coll) (i : idx) (h : valid xs i) :\n  elem</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]` gets the `i`'th element of the collection `arr`. If there\nare proof side conditions to the application, they will be automatically\ninferred by the `get_elem_tactic` tactic.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `xs[i]` in identifiers is `getElem`.\n\n * The recommended spelling of `xs[i]'h` in identifiers is `getElem`.</code>",
 "380": "<code>LawfulHashable α</code>",
 "38":
 "<code>(Prod.fst ?inv1 ({ «prefix» := pref✝, suffix := cur✝ :: suff✝, property := ⋯ }, b✝)).down</code>",
 "379": "<code>Hashable α</code>",
 "378": "<code>LawfulBEq α</code>",
 "377": "<code>BEq α</code>",
 "376":
 "<code>(m : IndexMap α β) → (a : α) → a ∈ m → β</code><span class=\"sep\"></span><code class=\"docstring\">The syntax `arr[i]` gets the `i`'th element of the collection `arr`. If there\nare proof side conditions to the application, they will be automatically\ninferred by the `get_elem_tactic` tactic.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `xs[i]` in identifiers is `getElem`.\n\n * The recommended spelling of `xs[i]'h` in identifiers is `getElem`.</code>",
 "375":
 "<code>GetElem?.{u, v, w} (coll : Type u) (idx : Type v) (elem : outParam (Type w)) (valid : outParam (coll → idx → Prop)) :\n  Type (max (max u v) w)</code><span class=\"sep\"></span><code class=\"docstring\">The classes `GetElem` and `GetElem?` implement lookup notation,\nspecifically `xs[i]`, `xs[i]?`, `xs[i]!`, and `xs[i]'p`.\n\nBoth classes are indexed by types `coll`, `idx`, and `elem` which are\nthe collection, the index, and the element types.\nA single collection may support lookups with multiple index\ntypes. The relation `valid` determines when the index is guaranteed to be\nvalid; lookups of valid indices are guaranteed not to fail.\n\nFor example, an instance for arrays looks like\n`GetElem (Array α) Nat α (fun xs i =&gt; i &lt; xs.size)`. In other words, given an\narray `xs` and a natural number `i`, `xs[i]` will return an `α` when `valid xs i`\nholds, which is true when `i` is less than the size of the array. `Array`\nadditionally supports indexing with `USize` instead of `Nat`.\nIn either case, because the bounds are checked at compile time,\nno runtime check is required.\n\nGiven `xs[i]` with `xs : coll` and `i : idx`, Lean looks for an instance of\n`GetElem coll idx elem valid` and uses this to infer the type of the return\nvalue `elem` and side condition `valid` required to ensure `xs[i]` yields\na valid value of type `elem`. The tactic `get_elem_tactic` is\ninvoked to prove validity automatically. The `xs[i]'p` notation uses the\nproof `p` to satisfy the validity condition.\nIf the proof `p` is long, it is often easier to place the\nproof in the context using `have`, because `get_elem_tactic` tries\n`assumption`.\n\n\nThe proof side-condition `valid xs i` is automatically dispatched by the\n`get_elem_tactic` tactic; this tactic can be extended by adding more clauses to\n`get_elem_tactic_extensible` using `macro_rules`.\n\n`xs[i]?` and `xs[i]!` do not impose a proof obligation; the former returns\nan `Option elem`, with `none` signalling that the value isn't present, and\nthe latter returns `elem` but panics if the value isn't there, returning\n`default : elem` based on the `Inhabited elem` instance.\nThese are provided by the `GetElem?` class, for which there is a default instance\ngenerated from a `GetElem` class as long as `valid xs i` is always decidable.\n\nImportant instances include:\n  * `arr[i] : α` where `arr : Array α` and `i : Nat` or `i : USize`: does array\n    indexing with no runtime bounds check and a proof side goal `i &lt; arr.size`.\n  * `l[i] : α` where `l : List α` and `i : Nat`: index into a list, with proof\n    side goal `i &lt; l.length`.\n\n</code>",
 "374":
 "<code class=\"docstring\">`get_elem_tactic` is the tactic automatically called by the notation `arr[i]`\nto prove any side conditions that arise when constructing the term\n(e.g. the index is in bounds of the array). It just delegates to\n`get_elem_tactic_extensible` and gives a diagnostic error message otherwise;\nusers are encouraged to extend `get_elem_tactic_extensible` instead of this tactic.\n</code>",
 "373": "<code>autoParam (i &lt; m.size) getIdx._auto_1</code>",
 "372":
 "<code>IndexMap.getIdx.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (i : Nat)\n  (h : i &lt; m.size := by get_elem_tactic) : β</code>",
 "371":
 "<code>IndexMap.getIdx?.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (i : Nat) : Option β</code>",
 "370": "<code>a ∈ m</code>",
 "37":
 "<code>List.cons.{u} {α : Type u} (head : α) (tail : List α) : List α</code><span class=\"sep\"></span><code class=\"docstring\">The list whose first element is `head`, where `tail` is the rest of the list.\nUsually written `head :: tail`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `::` in identifiers is `cons`.\n\n * The recommended spelling of `[a]` in identifiers is `singleton`.</code>",
 "369":
 "<code>IndexMap.findIdx.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α) (h : a ∈ m) : Nat</code>",
 "368":
 "<code>IndexMap.findIdx?.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α) : Option Nat</code>",
 "367":
 "<code>inferInstanceAs.{u} (α : Sort u) [i : α] : α</code><span class=\"sep\"></span><code class=\"docstring\">`inferInstanceAs α` synthesizes a value of any target type by typeclass\ninference. This is just like `inferInstance` except that `α` is given\nexplicitly instead of being inferred from the target type. It is especially\nuseful when the target type is some `α'` which is definitionally equal to `α`,\nbut the instance we are looking for is only registered for `α` (because\ntypeclass search does not unfold most definitions, but definitional equality\ndoes.) Example:\n```\n#check inferInstanceAs (Inhabited Nat) -- Inhabited Nat\n```\n</code>",
 "366":
 "<code>Decidable (p : Prop) : Type</code><span class=\"sep\"></span><code class=\"docstring\">Either a proof that `p` is true or a proof that `p` is false. This is equivalent to a `Bool` paired\nwith a proof that the `Bool` is `true` if and only if `p` is true.\n\n`Decidable` instances are primarily used via `if`-expressions and the tactic `decide`. In\nconditional expressions, the `Decidable` instance for the proposition is used to select a branch. At\nrun time, this case distinction code is identical to that which would be generated for a\n`Bool`-based conditional. In proofs, the tactic `decide` synthesizes an instance of `Decidable p`,\nattempts to reduce it to `isTrue h`, and then succeeds with the proof `h` if it can.\n\nBecause `Decidable` carries data, when writing `@[simp]` lemmas which include a `Decidable` instance\non the LHS, it is best to use `{_ : Decidable p}` rather than `[Decidable p]` so that non-canonical\ninstances can be found via unification rather than instance synthesis.\n</code>",
 "365":
 "<code>IndexMap α β → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The membership relation `a ∈ s : Prop` where `a : α`, `s : γ`. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `∈` in identifiers is `mem`.</code>",
 "364":
 "<code>Membership.{u, v} (α : outParam (Type u)) (γ : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">The typeclass behind the notation `a ∈ s : Prop` where `a : α`, `s : γ`.\nBecause `α` is an `outParam`, the \"container type\" `γ` determines the type\nof the elements of the container.\n</code>",
 "363":
 "<code>Std.HashMap.contains.{u, v} {α : Type u} {β : Type v} {x✝ : BEq α} {x✝¹ : Hashable α} (m : HashMap α β) (a : α) : Bool</code><span class=\"sep\"></span><code class=\"docstring\">Returns `true` if there is a mapping for the given key. There is also a `Prop`-valued version\nof this: `a ∈ m` is equivalent to `m.contains a = true`.\n\nObserve that this is different behavior than for lists: for lists, `∈` uses `=` and `contains` uses\n`==` for comparisons, while for hash maps, both use `==`.\n</code>",
 "362":
 "<code>IndexMap.contains.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) (a : α) : Bool</code>",
 "361":
 "<code>IndexMap α β</code><span class=\"sep\"></span><code class=\"docstring\">`default` is a function that produces a \"default\" element of any\n`Inhabited` type. This element does not have any particular specified\nproperties, but it is often an all-zeroes value. </code>",
 "360":
 "<code>Inhabited.{u} (α : Sort u) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">`Inhabited α` is a typeclass that says that `α` has a designated element,\ncalled `(default : α)`. This is sometimes referred to as a \"pointed type\".\n\nThis class is used by functions that need to return a value of the type\nwhen called \"out of domain\". For example, `Array.get! arr i : α` returns\na value of type `α` when `arr : Array α`, but if `i` is not in range of\nthe array, it reports a panic message, but this does not halt the program,\nso it must still return a value of type `α` (and in fact this is required\nfor logical consistency), so in this case it returns `default`.\n</code>",
 "36":
 "<code>HAppend.hAppend.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAppend α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a ++ b` is the result of concatenation of `a` and `b`, usually read \"append\".\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `++` in identifiers is `append`.</code>",
 "359":
 "<code>IndexMap α β</code><span class=\"sep\"></span><code class=\"docstring\">`∅` or `{}` is the empty set or empty collection.\nIt is supported by the `EmptyCollection` typeclass. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `{}` in identifiers is `empty`.\n\n * The recommended spelling of `∅` in identifiers is `empty`.</code>",
 "358":
 "<code>EmptyCollection.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`EmptyCollection α` is the typeclass which supports the notation `∅`, also written as `{}`. </code>",
 "357":
 "<code>∀ (i : Nat) (a : α), (Array.emptyWithCapacity capacity)[i]? = some a ↔ (HashMap.emptyWithCapacity capacity)[a]? = some i</code>",
 "356":
 "<code>(Array.emptyWithCapacity capacity).size = (Array.emptyWithCapacity capacity).size</code>",
 "355": "<code>Array β</code>",
 "354":
 "<code>Array.emptyWithCapacity.{u} {α : Type u} (c : Nat) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Constructs a new empty array with initial capacity `c`.\n</code>",
 "353": "<code>Array α</code>",
 "352":
 "<code>Std.HashMap.emptyWithCapacity.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (capacity : Nat := 8) : HashMap α β</code><span class=\"sep\"></span><code class=\"docstring\">Creates a new empty hash map. The optional parameter `capacity` can be supplied to presize the\nmap so that it can hold the given number of mappings without reallocating. It is also possible to\nuse the empty collection notations `∅` and `{}` to create an empty hash map with the default\ncapacity.\n</code>",
 "351": "<code>HashMap α Nat</code>",
 "350": "<code>optParam Nat 8</code>",
 "35": "<code>l.toList = pref✝ ++ cur✝ :: suff✝</code>",
 "349":
 "<code>IndexMap.emptyWithCapacity.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (capacity : Nat := 8) : IndexMap α β</code>",
 "348":
 "<code>IndexMap.size.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (m : IndexMap α β) : Nat</code>",
 "347": "<code>β</code>",
 "346": "<code>IndexMap α β</code>",
 "345":
 "<code>LawfulHashable.{u} (α : Type u) [BEq α] [Hashable α] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">The `BEq α` and `Hashable α` instances on `α` are compatible. This means that that `a == b` implies\n`hash a = hash b`.\n\nThis is automatic if the `BEq` instance is lawful.\n</code>",
 "344":
 "<code>LawfulBEq.{u} (α : Type u) [BEq α] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A Boolean equality test coincides with propositional equality.\n\nIn other words:\n* `a == b` implies `a = b`.\n* `a == a` is true.\n</code>",
 "343":
 "<code class=\"docstring\">Declares one or more typed variables, or modifies whether already-declared variables are\n  implicit.\n\nIntroduces variables that can be used in definitions within the same `namespace` or `section` block.\nWhen a definition mentions a variable, Lean will add it as an argument of the definition. This is\nuseful in particular when writing many definitions that have parameters in common (see below for an\nexample).\n\nVariable declarations have the same flexibility as regular function parameters. In particular they\ncan be [explicit, implicit][binder docs], or [instance implicit][tpil classes] (in which case they\ncan be anonymous). This can be changed, for instance one can turn explicit variable `x` into an\nimplicit one with `variable {x}`. Note that currently, you should avoid changing how variables are\nbound and declare new variables at the same time; see [issue 2789] for more on this topic.\n\nIn *theorem bodies* (i.e. proofs), variables are not included based on usage in order to ensure that\nchanges to the proof cannot change the statement of the overall theorem. Instead, variables are only\navailable to the proof if they have been mentioned in the theorem header or in an `include` command\nor are instance implicit and depend only on such variables.\n\nSee [*Variables and Sections* from Theorem Proving in Lean][tpil vars] for a more detailed\ndiscussion.\n\n[tpil vars]:\nhttps://lean-lang.org/theorem_proving_in_lean4/dependent_type_theory.html#variables-and-sections\n(Variables and Sections on Theorem Proving in Lean) [tpil classes]:\nhttps://lean-lang.org/theorem_proving_in_lean4/type_classes.html (Type classes on Theorem Proving in\nLean) [binder docs]:\nhttps://leanprover-community.github.io/mathlib4_docs/Lean/Expr.html#Lean.BinderInfo (Documentation\nfor the BinderInfo type) [issue 2789]: https://github.com/leanprover/lean4/issues/2789 (Issue 2789\non github)\n\n## Examples\n\n```lean\nsection\n  variable\n    {α : Type u}      -- implicit\n    (a : α)           -- explicit\n    [instBEq : BEq α] -- instance implicit, named\n    [Hashable α]      -- instance implicit, anonymous\n\n  def isEqual (b : α) : Bool :=\n    a == b\n\n  #check isEqual\n  -- isEqual.{u} {α : Type u} (a : α) [instBEq : BEq α] (b : α) : Bool\n\n  variable\n    {a} -- `a` is implicit now\n\n  def eqComm {b : α} := a == b ↔ b == a\n\n  #check eqComm\n  -- eqComm.{u} {α : Type u} {a : α} [instBEq : BEq α] {b : α} : Prop\nend\n```\n\nThe following shows a typical use of `variable` to factor out definition arguments:\n\n```lean\nvariable (Src : Type)\n\nstructure Logger where\n  trace : List (Src × String)\n#check Logger\n-- Logger (Src : Type) : Type\n\nnamespace Logger\n  -- switch `Src : Type` to be implicit until the `end Logger`\n  variable {Src}\n\n  def empty : Logger Src where\n    trace := []\n  #check empty\n  -- Logger.empty {Src : Type} : Logger Src\n\n  variable (log : Logger Src)\n\n  def len :=\n    log.trace.length\n  #check len\n  -- Logger.len {Src : Type} (log : Logger Src) : Nat\n\n  variable (src : Src) [BEq Src]\n\n  -- at this point all of `log`, `src`, `Src` and the `BEq` instance can all become arguments\n\n  def filterSrc :=\n    log.trace.filterMap\n      fun (src', str') =&gt; if src' == src then some str' else none\n  #check filterSrc\n  -- Logger.filterSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : List String\n\n  def lenSrc :=\n    log.filterSrc src |&gt;.length\n  #check lenSrc\n  -- Logger.lenSrc {Src : Type} (log : Logger Src) (src : Src) [inst✝ : BEq Src] : Nat\nend Logger\n```\n\nThe following example demonstrates availability of variables in proofs:\n```lean\nvariable\n  {α : Type}    -- available in the proof as indirectly mentioned through `a`\n  [ToString α]  -- available in the proof as `α` is included\n  (a : α)       -- available in the proof as mentioned in the header\n  {β : Type}    -- not available in the proof\n  [ToString β]  -- not available in the proof\n\ntheorem ex : a = a := rfl\n```\nAfter elaboration of the proof, the following warning will be generated to highlight the unused\nhypothesis:\n```\nincluded section variable '[ToString α]' is not used in 'ex', consider excluding it\n```\nIn such cases, the offending variable declaration should be moved down or into a section so that\nonly theorems that do depend on it follow it until the end of the section.\n</code>",
 "342":
 "<code class=\"docstring\">`namespace &lt;id&gt;` opens a section with label `&lt;id&gt;` that influences naming and name resolution inside\nthe section:\n* Declarations names are prefixed: `def seventeen : ℕ := 17` inside a namespace `Nat` is given the\n  full name `Nat.seventeen`.\n* Names introduced by `export` declarations are also prefixed by the identifier.\n* All names starting with `&lt;id&gt;.` become available in the namespace without the prefix. These names\n  are preferred over names introduced by outer namespaces or `open`.\n* Within a namespace, declarations can be `protected`, which excludes them from the effects of\n  opening the namespace.\n\nAs with `section`, namespaces can be nested and the scope of a namespace is terminated by a\ncorresponding `end &lt;id&gt;` or the end of the file.\n\n`namespace` also acts like `section` in delimiting the scope of `variable`, `open`, and other scoped commands.\n</code>",
 "341": "<code>HashMap α Nat</code>",
 "340":
 "<code>IndexMap.WF.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (self : IndexMap α β) (i : Nat) (a : α) :\n  self.keys[i]? = some a ↔ self.indices[a]? = some i</code>",
 "34":
 "<code>List.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">Linked lists: ordered lists, in which each element has a reference to the next element.\n\nMost operations on linked lists take time proportional to the length of the list, because each\nelement must be traversed to find the next element.\n\n`List α` is isomorphic to `Array α`, but they are useful for different things:\n* `List α` is easier for reasoning, and `Array α` is modeled as a wrapper around `List α`.\n* `List α` works well as a persistent data structure, when many copies of the tail are shared. When\n  the value is not shared, `Array α` will have better performance because it can do destructive\n  updates.\n</code>",
 "339": "<code>Array β</code>",
 "338":
 "<code>Array.size.{u} {α : Type u} (a : Array α) : Nat</code><span class=\"sep\"></span><code class=\"docstring\">Gets the number of elements stored in an array.\n\nThis is a cached value, so it is `O(1)` to access. The space allocated for an array, referred to as\nits _capacity_, is at least as large as its size, but may be larger. The capacity of an array is an\ninternal detail that's not observable by Lean code.\n</code>",
 "337": "<code>Array α</code>",
 "336":
 "<code>IndexMap.size_keys.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (self : IndexMap α β) :\n  self.keys.size = self.values.size</code>",
 "335":
 "<code>IndexMap.values.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (self : IndexMap α β) : Array β</code>",
 "334":
 "<code>IndexMap.keys.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (self : IndexMap α β) : Array α</code>",
 "333":
 "<code>IndexMap.indices.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] (self : IndexMap α β) : HashMap α Nat</code>",
 "332":
 "<code>Hashable.{u} (α : Sort u) : Sort (max 1 u)</code><span class=\"sep\"></span><code class=\"docstring\">Types that can be hashed into a `UInt64`. </code>",
 "331":
 "<code>BEq.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">`BEq α` is a typeclass for supplying a boolean-valued equality relation on\n`α`, notated as `a == b`. Unlike `DecidableEq α` (which uses `a = b`), this\nis `Bool` valued instead of `Prop` valued, and it also does not have any\naxioms like being reflexive or agreeing with `=`. It is mainly intended for\nprogramming applications. See `LawfulBEq` for a version that requires that\n`==` and `=` coincide.\n\nTypically we prefer to put the \"more variable\" term on the left,\nand the \"more constant\" term on the right.\n</code>",
 "330": "<code class=\"docstring\">The universe parameter v</code>",
 "33": "<code>List Nat</code>",
 "329": "<code>Type v</code>",
 "328":
 "<code class=\"docstring\">The `sorry` term is a temporary placeholder for a missing proof or value.\n\nThe syntax is intended for stubbing-out incomplete parts of a value or proof while still having a syntactically correct skeleton.\nLean will give a warning whenever a declaration uses `sorry`, so you aren't likely to miss it,\nbut you can double check if a declaration depends on `sorry` by looking for `sorryAx` in the output\nof the `#print axioms my_thm` command, the axiom used by the implementation of `sorry`.\n\n\"Go to definition\" on `sorry` in the Infoview will go to the source position where it was introduced, if such information is available.\n\nEach `sorry` is guaranteed to be unique, so for example the following fails:\n```lean\nexample : (sorry : Nat) = sorry := rfl -- fails\n```\n\nSee also the `sorry` tactic, which is short for `exact sorry`.\n</code>",
 "327":
 "<code class=\"docstring\">The `[grind]` attribute is used to annotate declarations.When applied to an equational theorem, `[grind =]`, `[grind =_]`, or `[grind _=_]`will mark the theorem for use in heuristic instantiations by the `grind` tactic,\n      using respectively the left-hand side, the right-hand side, or both sides of the theorem.When applied to a function, `[grind =]` automatically annotates the equational theorems associated with that function.When applied to a theorem `[grind ←]` will instantiate the theorem whenever it encounters the conclusion of the theorem\n      (that is, it will use the theorem for backwards reasoning).When applied to a theorem `[grind →]` will instantiate the theorem whenever it encounters sufficiently many of the propositional hypotheses\n      (that is, it will use the theorem for forwards reasoning).The attribute `[grind]` by itself will effectively try `[grind ←]` (if the conclusion is sufficient for instantiation) and then `[grind →]`.The `grind` tactic utilizes annotated theorems to add instances of matching patterns into the local context during proof search.For example, if a theorem `@[grind =] theorem foo_idempotent : foo (foo x) = foo x` is annotated,`grind` will add an instance of this theorem to the local context whenever it encounters the pattern `foo (foo x)`.</code>",
 "326":
 "<code>IndexMap.eraseSwap.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulBEq α] [LawfulHashable α]\n  (m : IndexMap α β) (a : α) : IndexMap α β</code><span class=\"sep\"></span><code class=\"docstring\">Erase the key-value pair with the given key,\nmoving the last pair into its place in the order.\nIf the key is not present, the map is unchanged.\n</code>",
 "325":
 "<code>IndexMap.insert.{u, v} {α : Type u} {β : Type v} [BEq α] [Hashable α] [LawfulHashable α] [LawfulBEq α]\n  (m : IndexMap α β) (a : α) (b : β) : IndexMap α β</code>",
 "324":
 "<code>Std.HashMap.{u, v} (α : Type u) (β : Type v) [BEq α] [Hashable α] : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Hash maps.\n\nThis is a simple separate-chaining hash table. The data of the hash map consists of a cached size\nand an array of buckets, where each bucket is a linked list of key-value pairs. The number of buckets\nis always a power of two. The hash map doubles its size upon inserting an element such that the\nnumber of elements is more than 75% of the number of buckets.\n\nThe hash table is backed by an `Array`. Users should make sure that the hash map is used linearly to\navoid expensive copies.\n\nThe hash map uses `==` (provided by the `BEq` typeclass) to compare keys and `hash` (provided by\nthe `Hashable` typeclass) to hash them. To ensure that the operations behave as expected, `==`\nshould be an equivalence relation and `a == b` should imply `hash a = hash b` (see also the\n`EquivBEq` and `LawfulHashable` typeclasses). Both of these conditions are automatic if the BEq\ninstance is lawful, i.e., if `a == b` implies `a = b`.\n\nThese hash maps contain a bundled well-formedness invariant, which means that they cannot\nbe used in nested inductive types. For these use cases, `Std.Data.HashMap.Raw` and\n`Std.Data.HashMap.Raw.WF` unbundle the invariant from the hash map. When in doubt, prefer\n`HashMap` over `HashMap.Raw`.\n\nDependent hash maps, in which keys may occur in their values' types, are available as\n`Std.Data.DHashMap`.\n</code>",
 "323":
 "<code>IndexMap.{u, v} (α : Type u) (β : Type v) [BEq α] [Hashable α] : Type (max u v)</code>",
 "322": "<code>_root_.Assertion.{u} (ps : PostShape) : Type u</code>",
 "321": "<code>PostShape.args.{u} : PostShape → List (Type u)</code>",
 "320": "<code>SPred σs</code>",
 "32":
 "<code>Std.Do.PostShape.pure.{u} : PostShape</code><span class=\"sep\"></span><code class=\"docstring\">The assertions and postconditions in this monad use neither state nor exceptions. </code>",
 "319":
 "<code>Std.Do.SPred.{u} (σs : List (Type u)) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A predicate over states, where each state is defined by a list of component state types.\n\nExample:\n```lean example\nSPred [Nat, Bool] = (Nat → Bool → ULift Prop)\n```\n</code>",
 "318":
 "<code>List.length.{u_1} {α : Type u_1} : List α → Nat</code><span class=\"sep\"></span><code class=\"docstring\">The length of a list.\n\nThis function is overridden in the compiler to `lengthTR`, which uses constant stack space.\n\nExamples:\n* `([] : List String).length = 0`\n* `[\"green\", \"brown\"].length = 2`\n</code>",
 "317": "<code>[:4].toList.Cursor</code>",
 "316":
 "<code class=\"docstring\">`try tac` runs `tac` and succeeds even if `tac` failed. </code>",
 "315": "<code>x.toNat + y.toNat &lt; UInt32.size</code>",
 "314":
 "<code>addOp_ok_spec {x y : UInt32} (h : x.toNat + y.toNat &lt; UInt32.size) :\n  ⦃⌜True⌝⦄ addOp x y ⦃PostCond.noThrow fun r =&gt; ⌜r = x + y ∧ (x + y).toNat = x.toNat + y.toNat⌝⦄</code>",
 "313":
 "<code>id.{u} {α : Sort u} (a : α) : α</code><span class=\"sep\"></span><code class=\"docstring\">The identity function. `id` takes an implicit argument `α : Sort u`\n(a type in any universe), and an argument `a : α`, and returns `a`.\n\nAlthough this may look like a useless function, one application of the identity\nfunction is to explicitly put a type on an expression. If `e` has type `T`,\nand `T'` is definitionally equal to `T`, then `@id T' e` typechecks, and Lean\nknows that this expression has type `T'` rather than `T`. This can make a\ndifference for typeclass inference, since `T` and `T'` may have different\ntypeclass instances on them. `show T' from e` is sugar for an `@id T' e`\nexpression.\n</code>",
 "312": "<code>PostCond α (PostShape.except Error PostShape.pure)</code>",
 "311":
 "<code>Result.throw_spec {α : Type} {Q : PostCond α (PostShape.except Error PostShape.pure)} (e : Error) :\n  ⦃Q.snd.fst e⦄ throw e ⦃Q⦄</code>",
 "310":
 "<code>UInt32.size : Nat</code><span class=\"sep\"></span><code class=\"docstring\">The number of distinct values representable by `UInt32`, that is, `2^32 = 4294967296`. </code>",
 "31":
 "<code>Array.toList.{u} {α : Type u} (self : Array α) : List α</code><span class=\"sep\"></span><code class=\"docstring\">Converts an `Array α` into a `List α` that contains the same elements in the same order.\n\nAt runtime, this is implemented by `Array.toListImpl` and is `O(n)` in the length of the\narray.\n</code>",
 "309":
 "<code>UInt32.toNat (n : UInt32) : Nat</code><span class=\"sep\"></span><code class=\"docstring\">Converts a 32-bit unsigned integer to an arbitrary-precision natural number.\n\nThis function is overridden at runtime with an efficient implementation.\n</code>",
 "308":
 "<code class=\"docstring\">`if c then t else e` is notation for `ite c t e`, \"if-then-else\", which decides to\nreturn `t` or `e` depending on whether `c` is true or false. The explicit argument\n`c : Prop` does not have any actual computational content, but there is an additional\n`[Decidable c]` argument synthesized by typeclass inference which actually\ndetermines how to evaluate `c` to true or false. Write `if h : c then t else e`\ninstead for a \"dependent if-then-else\" `dite`, which allows `t`/`e` to use the fact\nthat `c` is true/false.\n</code>",
 "307": "<code>UInt32</code>",
 "306": "<code>addOp (x y : UInt32) : Result UInt32</code>",
 "305": "<code>Error → Result α✝</code>",
 "304":
 "<code>{α : Type u_1} → Result α → (Error → Result α) → Result α</code><span class=\"sep\"></span><code class=\"docstring\">Catches errors thrown in `body`, passing them to `handler`. Errors in `handler` are not caught.\n</code>",
 "303":
 "<code>{α : Type u_1} → Error → Result α</code><span class=\"sep\"></span><code class=\"docstring\">Throws an exception of type `ε` to the nearest enclosing handler.\n</code>",
 "302":
 "<code>MonadExcept.{u, v, w} (ε : outParam (Type u)) (m : Type v → Type w) : Type (max (max u (v + 1)) w)</code><span class=\"sep\"></span><code class=\"docstring\">Exception monads provide the ability to throw errors and handle errors.\n\nIn this class, `ε` is an `outParam`, which means that it is inferred from `m`. `MonadExceptOf ε`\nprovides the same operations, but allows `ε` to influence instance synthesis.\n\n`MonadExcept.tryCatch` is used to desugar `try ... catch ...` steps inside `do`-blocks when the\nhandlers do not have exception type annotations.\n</code>",
 "301":
 "<code>UInt32 : Type</code><span class=\"sep\"></span><code class=\"docstring\">Unsigned 32-bit integers.\n\nThis type has special support in the compiler so it can be represented by an unboxed 32-bit value\nrather than wrapping a `BitVec 32`.\n</code>",
 "300":
 "<code>Result.of_wp {α : Type} {x : Result α} (P : Result α → Prop) :\n  (⊢ₛ wp⟦x⟧ (fun a =&gt; ⌜P (Result.ok a)⌝, fun e =&gt; ⌜P (Result.fail e)⌝, ())) → P x</code>",
 "30":
 "<code>Std.Do.Invariant.{u₁, u₂} {α : Type u₁} (xs : List α) (β : Type u₂) (ps : PostShape) : Type (max u₂ u₁)</code><span class=\"sep\"></span><code class=\"docstring\">The type of loop invariants used by the specifications of `for ... in ...` loops.\nA loop invariant is a `PostCond` that takes as parameters\n\n* A `List.Cursor xs` representing the iteration state of the loop. It is parameterized by the list\n  of elements `xs` that the `for` loop iterates over.\n* A state tuple of type `β`, which will be a nesting of `MProd`s representing the elaboration of\n  `let mut` variables and early return.\n\nThe loop specification lemmas will use this in the following way:\nBefore entering the loop, the cursor's prefix is empty and the suffix is `xs`.\nAfter leaving the loop, the cursor's prefix is `xs` and the suffix is empty.\nDuring the induction step, the invariant holds for a suffix with head element `x`.\nAfter running the loop body, the invariant then holds after shifting `x` to the prefix.\n</code>",
 "3": "<code>Array Nat</code>",
 "299":
 "<code class=\"docstring\">`simp_all` is a stronger version of `simp [*] at *` where the hypotheses and target\nare simplified multiple times until no simplification is applicable.\nOnly non-dependent propositional hypotheses are considered.\n</code>",
 "298":
 "<code>⊢ₛ (PredTrans.const ⌜False⌝).apply (fun a =&gt; ⌜P (ok a)⌝, fun e =&gt; ⌜P (fail e)⌝, ())</code>",
 "297":
 "<code>⊢ₛ wp⟦throw e✝⟧ (fun a =&gt; ⌜P (ok a)⌝, fun e =&gt; ⌜P (fail e)⌝, ())</code>",
 "296":
 "<code>⊢ₛ wp⟦pure v✝⟧ (fun a =&gt; ⌜P (ok a)⌝, fun e =&gt; ⌜P (fail e)⌝, ())</code>",
 "295":
 "<code class=\"docstring\">The `split` tactic is useful for breaking nested if-then-else and `match` expressions into separate cases.\nFor a `match` expression with `n` cases, the `split` tactic generates at most `n` subgoals.\n\nFor example, given `n : Nat`, and a target `if n = 0 then Q else R`, `split` will generate\none goal with hypothesis `n = 0` and target `Q`, and a second goal with hypothesis\n`¬n = 0` and target `R`.  Note that the introduced hypothesis is unnamed, and is commonly\nrenamed using the `case` or `next` tactics.\n\n- `split` will split the goal (target).\n- `split at h` will split the hypothesis `h`.\n</code>",
 "294":
 "<code>⊢ₛ\n  (match x with\n      | ok v =&gt; wp (pure v)\n      | fail e =&gt; wp (throw e)\n      | div =&gt; PredTrans.const ⌜False⌝).apply\n    (fun a =&gt; ⌜P (ok a)⌝, fun e =&gt; ⌜P (fail e)⌝, ())</code>",
 "293":
 "<code class=\"docstring\">Location specifications are used by many tactics that can operate on either the\nhypotheses or the goal. It can have one of the forms:\n* 'empty' is not actually present in this syntax, but most tactics use\n  `(location)?` matchers. It means to target the goal only.\n* `at h₁ ... hₙ`: target the hypotheses `h₁`, ..., `hₙ`\n* `at h₁ h₂ ⊢`: target the hypotheses `h₁` and `h₂`, and the goal\n* `at *`: target all hypotheses and the goal\n</code>",
 "292":
 "<code>⊢ₛ wp⟦x⟧ (fun a =&gt; ⌜P (ok a)⌝, fun e =&gt; ⌜P (fail e)⌝, ())</code>",
 "291":
 "<code class=\"docstring\">Introduces one or more hypotheses, optionally naming and/or pattern-matching them.\nFor each hypothesis to be introduced, the remaining main goal's target type must\nbe a `let` or function type.\n\n* `intro` by itself introduces one anonymous hypothesis, which can be accessed\n  by e.g. `assumption`. It is equivalent to `intro _`.\n* `intro x y` introduces two hypotheses and names them. Individual hypotheses\n  can be anonymized via `_`, given a type ascription, or matched against a pattern:\n  ```lean\n  -- ... ⊢ α × β → ...\n  intro (a, b)\n  -- ..., a : α, b : β ⊢ ...\n  ```\n* `intro rfl` is short for `intro h; subst h`, if `h` is an equality where the left-hand or right-hand side\n  is a variable.\n* Alternatively, `intro` can be combined with pattern matching much like `fun`:\n  ```lean\n  intro\n  | n + 1, 0 =&gt; tac\n  | ...\n  ```\n</code>",
 "290": "<code>Result α → Prop</code>",
 "29":
 "<code>Prop</code><span class=\"sep\"></span><code class=\"docstring\">Extracts a wrapped value from a universe-lifted type. </code>",
 "289": "<code>Result α</code>",
 "288":
 "<code>Result.of_wp {α : Type} {x : Result α} (P : Result α → Prop) :\n  (⊢ₛ wp⟦x⟧ (fun a =&gt; ⌜P (ok a)⌝, fun e =&gt; ⌜P (fail e)⌝, ())) → P x</code>",
 "287": "<code>PostCond β✝ (PostShape.except Error PostShape.pure)</code>",
 "286":
 "<code>Std.Do.PredTrans.bind.{u} {ps : PostShape} {α β : Type u} (x : PredTrans ps α) (f : α → PredTrans ps β) : PredTrans ps β</code><span class=\"sep\"></span><code class=\"docstring\">Sequences two predicate transformers by composing them.\n</code>",
 "285": "<code>β✝</code>",
 "284":
 "<code>Bind.bind.{u, v} {m : Type u → Type v} [self : Bind m] {α β : Type u} : m α → (α → m β) → m β</code><span class=\"sep\"></span><code class=\"docstring\">Sequences two computations, allowing the second to depend on the value computed by the first.\n\nIf `x : m α` and `f : α → m β`, then `x &gt;&gt;= f : m β` represents the result of executing `x` to get\na value of type `α` and then passing it to `f`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `&gt;&gt;=` in identifiers is `bind`.</code>",
 "283": "<code>α✝ → Result β✝</code>",
 "282": "<code>Result α✝</code>",
 "281":
 "<code>∀ {α β : Type} (x : Result α) (f : α → Result β),\n  (wp do\n      let a ← x\n      f a) =\n    do\n    let a ← wp x\n    wp (f a)</code><span class=\"sep\"></span><code class=\"docstring\">`WP.wp` preserves `bind`. </code>",
 "280":
 "<code>Except.pure.{u, u_1} {ε : Type u} {α : Type u_1} (a : α) : Except ε α</code><span class=\"sep\"></span><code class=\"docstring\">A successful computation in the `Except ε` monad: `a` is returned, and no exception is thrown.\n</code>",
 "28":
 "<code>ULift.up.{r, s} {α : Type s} (down : α) : ULift α</code><span class=\"sep\"></span><code class=\"docstring\">Wraps a value to increase its type's universe level. </code>",
 "279":
 "<code>Std.Do.PredTrans.pure.{u} {ps : PostShape} {α : Type u} (a : α) : PredTrans ps α</code><span class=\"sep\"></span><code class=\"docstring\">The identity predicate transformer that transforms the postcondition's assertion about the return\nvalue into an assertion about `a`.\n</code>",
 "278": "<code>PostCond α✝ (PostShape.except Error PostShape.pure)</code>",
 "277":
 "<code class=\"docstring\">Applies extensionality lemmas that are registered with the `@[ext]` attribute.\n* `ext pat*` applies extensionality theorems as much as possible,\n  using the patterns `pat*` to introduce the variables in extensionality theorems using `rintro`.\n  For example, the patterns are used to name the variables introduced by lemmas such as `funext`.\n* Without patterns,`ext` applies extensionality lemmas as much\n  as possible but introduces anonymous hypotheses whenever needed.\n* `ext pat* : n` applies ext theorems only up to depth `n`.\n\nThe `ext1 pat*` tactic is like `ext pat*` except that it only applies a single extensionality theorem.\n\nUnused patterns will generate warning.\nPatterns that don't match the variables will typically result in the introduction of anonymous hypotheses.\n</code>",
 "276":
 "<code class=\"docstring\">`intros` repeatedly applies `intro` to introduce zero or more hypotheses\nuntil the goal is no longer a *binding expression*\n(i.e., a universal quantifier, function type, implication, or `have`/`let`),\nwithout performing any definitional reductions (no unfolding, beta, eta, etc.).\nThe introduced hypotheses receive inaccessible (hygienic) names.\n\n`intros x y z` is equivalent to `intro x y z` and exists only for historical reasons.\nThe `intro` tactic should be preferred in this case.\n\n## Properties and relations\n\n- `intros` succeeds even when it introduces no hypotheses.\n\n- `repeat intro` is like `intros`, but it performs definitional reductions\n  to expose binders, and as such it may introduce more hypotheses than `intros`.\n\n- `intros` is equivalent to `intro _ _ … _`,\n  with the fewest trailing `_` placeholders needed so that the goal is no longer a binding expression.\n  The trailing introductions do not perform any definitional reductions.\n\n## Examples\n\nImplications:\n```lean\nexample (p q : Prop) : p → q → p := by\n  intros\n  /- Tactic state\n     a✝¹ : p\n     a✝ : q\n     ⊢ p      -/\n  assumption\n```\n\nLet-bindings:\n```lean\nexample : let n := 1; let k := 2; n + k = 3 := by\n  intros\n  /- n✝ : Nat := 1\n     k✝ : Nat := 2\n     ⊢ n✝ + k✝ = 3 -/\n  rfl\n```\n\nDoes not unfold definitions:\n```lean\ndef AllEven (f : Nat → Nat) := ∀ n, f n % 2 = 0\n\nexample : ∀ (f : Nat → Nat), AllEven f → AllEven (fun k =&gt; f (k + 1)) := by\n  intros\n  /- Tactic state\n     f✝ : Nat → Nat\n     a✝ : AllEven f✝\n     ⊢ AllEven fun k =&gt; f✝ (k + 1) -/\n  sorry\n```\n</code>",
 "275": "<code>Type</code>",
 "274":
 "<code>∀ {α : Type} (a : α), wp (pure a) = pure a</code><span class=\"sep\"></span><code class=\"docstring\">`WP.wp` preserves `pure`. </code>",
 "273":
 "<code>Std.Do.WPMonad.{u, v} (m : Type u → Type v) (ps : outParam PostShape) [Monad m] : Type (max (u + 1) v)</code><span class=\"sep\"></span><code class=\"docstring\">A monad with weakest preconditions (`WP`) that is also a monad morphism, preserving `pure` and\n`bind`.\n\nIn practice, `mvcgen` is not useful for reasoning about programs in a monad that is without a\n`WPMonad` instance. The specification lemmas for `Pure.pure` and `Bind.bind`, as well as those for\noperators like `Functor.map`, require that their monad have a `WPMonad` instance.\n</code>",
 "272":
 "<code>Std.Do.PredTrans.const.{u} {ps : PostShape} {α : Type u} (P : Assertion ps) : PredTrans ps α</code><span class=\"sep\"></span><code class=\"docstring\">The predicate transformer that always returns the same precondition `P`; `(const P).apply Q = P`.\n</code>",
 "271":
 "<code>Std.Do.WP.wp.{u, v} {m : Type u → Type v} {ps : outParam PostShape} [self : WP m ps] {α : Type u} (x : m α) :\n  PredTrans ps α</code><span class=\"sep\"></span><code class=\"docstring\">Interpret a monadic program `x : m α` in terms of a predicate transformer `PredTrans ps α`. </code>",
 "270": "<code>α✝</code>",
 "27":
 "<code>Std.Do.PostCond.noThrow.{u} {ps : PostShape} {α : Type u} (p : α → Assertion ps) : PostCond α ps</code><span class=\"sep\"></span><code class=\"docstring\">A postcondition expressing total correctness.\nThat is, it expresses that the asserted computation finishes without throwing an exception\n*and* the result satisfies the given predicate `p`.\n</code>",
 "269":
 "<code>{α : Type} → Result α → PredTrans (PostShape.except Error PostShape.pure) α</code><span class=\"sep\"></span><code class=\"docstring\">Interpret a monadic program `x : m α` in terms of a predicate transformer `PredTrans ps α`. </code>",
 "268":
 "<code>Result.instWP : WP Result (PostShape.except Error PostShape.pure)</code>",
 "267":
 "<code>False : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`False` is the empty proposition. Thus, it has no introduction rules.\nIt represents a contradiction. `False` elimination rule, `False.rec`,\nexpresses the fact that anything follows from a contradiction.\nThis rule is sometimes called ex falso (short for ex falso sequitur quodlibet),\nor the principle of explosion.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "266":
 "<code>Except.{u, v} (ε : Type u) (α : Type v) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">`Except ε α` is a type which represents either an error of type `ε` or a successful result with a\nvalue of type `α`.\n\n`Except ε : Type u → Type v` is a `Monad` that represents computations that may throw exceptions:\nthe `pure` operation is `Except.ok` and the `bind` operation returns the first encountered\n`Except.error`.\n</code>",
 "265":
 "<code>Std.Do.WP.wp.{u, v} {m : Type u → Type v} {ps : outParam Std.Do.PostShape} [self : Std.Do.WP m ps] {α : Type u}\n  (x : m α) : Std.Do.PredTrans ps α</code><span class=\"sep\"></span><code class=\"docstring\">Interpret a monadic program `x : m α` in terms of a predicate transformer `PredTrans ps α`. </code>",
 "264":
 "<code>LawfulMonad.{u, v} (m : Type u → Type v) [Monad m] : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Lawful monads are those that satisfy a certain behavioral specification. While all instances of\n`Monad` should satisfy these laws, not all implementations are required to prove this.\n\n`LawfulMonad.mk'` is an alternative constructor that contains useful defaults for many fields.\n</code>",
 "263": "<code>Result.div.{u} {α : Type u} : Result α</code>",
 "262": "<code>Error</code>",
 "261": "<code>Result.fail.{u} {α : Type u} (e : Error) : Result α</code>",
 "260": "<code>Result.ok.{u} {α : Type u} (v : α) : Result α</code>",
 "26":
 "<code>ForInStep.yield.{u} {α : Type u} : α → ForInStep α</code><span class=\"sep\"></span><code class=\"docstring\">The loop should continue with the next iteration, using the returned state.\n\n`ForInStep.yield` is produced by `continue` and by reaching the bottom of the loop body.\n</code>",
 "259": "<code>Error.integerOverflow : Error</code>",
 "258": "<code>Error : Type</code>",
 "257":
 "<code class=\"docstring\">In Lean, every concrete type other than the universes\nand every type constructor other than dependent arrows\nis an instance of a general family of type constructions known as inductive types.\nIt is remarkable that it is possible to construct a substantial edifice of mathematics\nbased on nothing more than the type universes, dependent arrow types, and inductive types;\neverything else follows from those.\nIntuitively, an inductive type is built up from a specified list of constructors.\nFor example, `List α` is the list of elements of type `α`, and is defined as follows:\n```\ninductive List (α : Type u) where\n| nil\n| cons (head : α) (tail : List α)\n```\nA list of elements of type `α` is either the empty list, `nil`,\nor an element `head : α` followed by a list `tail : List α`.\nSee [Inductive types](https://lean-lang.org/theorem_proving_in_lean4/inductive_types.html)\nfor more information.\n</code>",
 "256": "<code>Result.{u} (α : Type u) : Type u</code>",
 "255":
 "<code>Std.Do.PredTrans.{u} (ps : PostShape) (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">The type of predicate transformers for a given `ps : PostShape` and return type `α : Type`. A\npredicate transformer `x : PredTrans ps α` is a function that takes a postcondition `Q : PostCond α\nps` and returns a precondition `x.apply Q : Assertion ps`.\n </code>",
 "254":
 "<code>Std.Do.PostShape.except.{u} (ε : Type u) : PostShape → PostShape</code><span class=\"sep\"></span><code class=\"docstring\">The postconditions in this monad include assertions about exceptional values of type `ε` that\nresult from premature termination.\n</code>",
 "253":
 "<code>Std.Do.PostShape.arg.{u} (σ : Type u) : PostShape → PostShape</code><span class=\"sep\"></span><code class=\"docstring\">The assertions in this monad may mention the current value of a state of type `σ`, and\npostconditions may mention the state's final value.\n</code>",
 "252":
 "<code>Std.Do.EStateM.of_wp_run_eq {ε σ : Type} {s : σ} {α : Type} {x : EStateM.Result ε σ α} {prog : EStateM ε σ α}\n  (h : prog.run s = x) (P : EStateM.Result ε σ α → Prop) :\n  (⊢ₛ wp⟦prog⟧ (fun a s' =&gt; ⌜P (EStateM.Result.ok a s')⌝, fun e s' =&gt; ⌜P (EStateM.Result.error e s')⌝, ()) s) → P x</code><span class=\"sep\"></span><code class=\"docstring\">Adequacy lemma for `EStateM.run`.\nUseful if you want to prove a property about an expression `x` defined as `EStateM.run prog s` and\nyou want to use `mvcgen` to reason about `prog`.\n</code>",
 "251":
 "<code>EStateM.Result.{u} (ε σ α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">The value returned from a combined state and exception monad in which exceptions do not\nautomatically roll back the state.\n\n`Result ε σ α` is equivalent to `Except ε α × σ`, but using a single combined inductive type yields\na more efficient data representation.\n</code>",
 "250": "<code>EStateM.Result String Supply (List Nat)</code>",
 "25":
 "<code>PUnit.unit.{u} : PUnit</code><span class=\"sep\"></span><code class=\"docstring\">The only element of the universe-polymorphic unit type. </code>",
 "249": "<code>(mkFreshN n).run s = x</code>",
 "248":
 "<code>EStateM.Result.error.{u} {ε σ α : Type u} : ε → σ → EStateM.Result ε σ α</code><span class=\"sep\"></span><code class=\"docstring\">An exception of type `ε` and a new state `σ`. </code>",
 "247":
 "<code>EStateM.Result.ok.{u} {ε σ α : Type u} : α → σ → EStateM.Result ε σ α</code><span class=\"sep\"></span><code class=\"docstring\">A success value of type `α` and a new state `σ`. </code>",
 "246":
 "<code>EStateM.run.{u} {ε σ α : Type u} (x : EStateM ε σ α) (s : σ) : EStateM.Result ε σ α</code><span class=\"sep\"></span><code class=\"docstring\">Executes an `EStateM` action with the initial state `s`. The returned value includes the final state\nand indicates whether an exception was thrown or a value was returned.\n</code>",
 "245":
 "<code class=\"docstring\">Pattern matching. `match e, ... with | p, ... =&gt; f | ...` matches each given\nterm `e` against each pattern `p` of a match alternative. When all patterns\nof an alternative match, the `match` term evaluates to the value of the\ncorresponding right-hand side `f` with the pattern variables bound to the\nrespective matched values.\nIf used as `match h : e, ... with | p, ... =&gt; f | ...`, `h : e = p` is available\nwithin `f`.\n\nWhen not constructing a proof, `match` does not automatically substitute variables\nmatched on in dependent variables' types. Use `match (generalizing := true) ...` to\nenforce this.\n\nSyntax quotations can also be used in a pattern match.\nThis matches a `Syntax` value against quotations, pattern variables, or `_`.\n\nQuoted identifiers only match identical identifiers - custom matching such as by the preresolved\nnames only should be done explicitly.\n\n`Syntax.atom`s are ignored during matching by default except when part of a built-in literal.\nFor users introducing new atoms, we recommend wrapping them in dedicated syntax kinds if they\nshould participate in matching.\nFor example, in\n```lean\nsyntax \"c\" (\"foo\" &lt;|&gt; \"bar\") ...\n```\n`foo` and `bar` are indistinguishable during matching, but in\n```lean\nsyntax foo := \"foo\"\nsyntax \"c\" (foo &lt;|&gt; \"bar\") ...\n```\nthey are not.\n</code>",
 "244":
 "<code>Exceptions.mkFreshN_correct {s : Supply} (n : Nat) :\n  match (mkFreshN n).run s with\n  | EStateM.Result.ok l a =&gt; l.Nodup\n  | EStateM.Result.error a s' =&gt; s'.counter = s'.limit</code>",
 "243":
 "<code>Exceptions.mkFreshN_spec (n : Nat) :\n  ⦃⌜True⌝⦄ mkFreshN n ⦃(fun r =&gt; ⌜r.Nodup⌝, fun _msg state =&gt; ⌜state.counter = state.limit⌝, ())⦄</code>",
 "242":
 "<code>Exceptions.mkFreshN (n : Nat) : EStateM String Supply (List Nat)</code>",
 "241":
 "<code>Exceptions.mkFreshN (n : Nat) : EStateM String Exceptions.Supply (List Nat)</code>",
 "240":
 "<code>Unit.unit : Unit</code><span class=\"sep\"></span><code class=\"docstring\">The only element of the unit type.\n\nIt can be written as an empty tuple: `()`.\n</code>",
 "24":
 "<code>Pure.pure.{u, v} {f : Type u → Type v} [self : Pure f] {α : Type u} : α → f α</code><span class=\"sep\"></span><code class=\"docstring\">Given `a : α`, then `pure a : f α` represents an action that does nothing and returns `a`.\n\nExamples:\n* `(pure \"hello\" : Option String) = some \"hello\"`\n* `(pure \"hello\" : Except (Array String) String) = Except.ok \"hello\"`\n* `(pure \"hello\" : StateM Nat String).run 105 = (\"hello\", 105)`\n</code>",
 "239": "<code>String</code>",
 "238":
 "<code class=\"docstring\">A postcondition for the given predicate shape, with one `Assertion` for the terminating case and\none `Assertion` for each `.except` layer in the predicate shape.\n```\nvariable (α σ ε : Type)\nexample : PostCond α (.arg σ .pure) = ((α → σ → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.except ε .pure) = ((α → ULift Prop) × (ε → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.arg σ (.except ε .pure)) = ((α → σ → ULift Prop) × (ε → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.except ε (.arg σ .pure)) = ((α → σ → ULift Prop) × (ε → σ → ULift Prop) × PUnit) := rfl\n```\n</code>",
 "237":
 "<code>Exceptions.mkFresh_spec (c : Nat) :\n  ⦃fun state =&gt; ⌜state.counter = c⌝⦄\n    mkFresh ⦃(fun r state =&gt; ⌜r = c ∧ c &lt; state.counter⌝, fun x state =&gt; ⌜c = state.counter ∧ c = state.limit⌝, ())⦄</code>",
 "236":
 "<code>LE.le.{u} {α : Type u} [self : LE α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-equal relation: `x ≤ y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `≤` in identifiers is `le`.\n\n * The recommended spelling of `&lt;=` in identifiers is `le` (prefer `≤` over `&lt;=`).</code>",
 "235": "<code>supply.counter ≤ supply.limit</code>",
 "234": "<code>¬supply.counter = supply.limit</code>",
 "233": "<code>n + 1 ≤ supply.limit</code>",
 "232":
 "<code>MonadStateOf.set.{u, v} {σ : semiOutParam (Type u)} {m : Type u → Type v} [self : MonadStateOf σ m] : σ → m PUnit</code><span class=\"sep\"></span><code class=\"docstring\">Replaces the current value of the mutable state with a new one.\n</code>",
 "231":
 "<code>MonadExcept.throw.{u, v, w} {ε : outParam (Type u)} {m : Type v → Type w} [self : MonadExcept ε m] {α : Type v} :\n  ε → m α</code><span class=\"sep\"></span><code class=\"docstring\">Throws an exception of type `ε` to the nearest enclosing handler.\n</code>",
 "230": "<code>supply.counter = supply.limit</code>",
 "23":
 "<code>HAdd.hAdd.{u, v, w} {α : Type u} {β : Type v} {γ : outParam (Type w)} [self : HAdd α β γ] : α → β → γ</code><span class=\"sep\"></span><code class=\"docstring\">`a + b` computes the sum of `a` and `b`.\nThe meaning of this notation is type-dependent. \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `+` in identifiers is `add`.</code>",
 "229":
 "<code>EStateM.{u} (ε σ α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A combined state and exception monad in which exceptions do not automatically roll back the state.\n\nInstances of `EStateM.Backtrackable` provide a way to roll back some part of the state if needed.\n\n`EStateM ε σ` is equivalent to `ExceptT ε (StateM σ)`, but it is more efficient.\n</code>",
 "228": "<code>Exceptions.mkFresh : EStateM String Supply Nat</code>",
 "227":
 "<code>Exceptions.Supply.property (self : Supply) : self.counter ≤ self.limit</code>",
 "226": "<code>Exceptions.Supply.limit (self : Supply) : Nat</code>",
 "225": "<code>Exceptions.Supply.counter (self : Supply) : Nat</code>",
 "224": "<code>Exceptions.Supply : Type</code>",
 "223":
 "<code>Std.Do.PostCond.{u} (α : Type u) (ps : Std.Do.PostShape) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A postcondition for the given predicate shape, with one `Assertion` for the terminating case and\none `Assertion` for each `.except` layer in the predicate shape.\n```\nvariable (α σ ε : Type)\nexample : PostCond α (.arg σ .pure) = ((α → σ → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.except ε .pure) = ((α → ULift Prop) × (ε → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.arg σ (.except ε .pure)) = ((α → σ → ULift Prop) × (ε → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.except ε (.arg σ .pure)) = ((α → σ → ULift Prop) × (ε → σ → ULift Prop) × PUnit) := rfl\n```\n</code>",
 "222": "<code>α → Assertion ps</code>",
 "221":
 "<code>MonadLift.{u, v, w} (m : semiOutParam (Type u → Type v)) (n : Type u → Type w) : Type (max (max (u + 1) v) w)</code><span class=\"sep\"></span><code class=\"docstring\">Computations in the monad `m` can be run in the monad `n`. These translations are inserted\nautomatically by the compiler.\n\nUsually, `n` consists of some number of monad transformers applied to `m`, but this is not\nmandatory.\n\nNew instances should use this class, `MonadLift`. Clients that require one monad to be liftable into\nanother should instead request `MonadLiftT`, which is the reflexive, transitive closure of\n`MonadLift`.\n</code>",
 "220":
 "<code>Monad.{u, v} (m : Type u → Type v) : Type (max (u + 1) v)</code><span class=\"sep\"></span><code class=\"docstring\">[Monads](https://en.wikipedia.org/wiki/Monad_(functional_programming)) are an abstraction of\nsequential control flow and side effects used in functional programming. Monads allow both\nsequencing of effects and data-dependent effects: the values that result from an early step may\ninfluence the effects carried out in a later step.\n\nThe `Monad` API may be used directly. However, it is most commonly accessed through\n[`do`-notation](https://lean-lang.org/doc/reference/4.27.0-rc1/find/?domain=Verso.Genre.Manual.section&name=do-notation).\n\nMost `Monad` instances provide implementations of `pure` and `bind`, and use default implementations\nfor the other methods inherited from `Applicative`. Monads should satisfy certain laws, but\ninstances are not required to prove this. An instance of `LawfulMonad` expresses that a given\nmonad's operations are lawful.\n</code>",
 "22":
 "<code>ForIn.forIn.{u, v, u₁, u₂} {m : Type u₁ → Type u₂} {ρ : Type u} {α : outParam (Type v)} [self : ForIn m ρ α]\n  {β : Type u₁} (xs : ρ) (b : β) (f : α → β → m (ForInStep β)) : m β</code><span class=\"sep\"></span><code class=\"docstring\">Monadically iterates over the contents of a collection `xs`, with a local state `b` and the\npossibility of early termination.\n\nBecause a `do` block supports local mutable bindings along with `return`, and `break`, the monadic\naction passed to `ForIn.forIn` takes a starting state in addition to the current element of the\ncollection and returns an updated state together with an indication of whether iteration should\ncontinue or terminate. If the action returns `ForInStep.done`, then `ForIn.forIn` should stop\niteration and return the updated state. If the action returns `ForInStep.yield`, then\n`ForIn.forIn` should continue iterating if there are further elements, passing the updated state\nto the action.\n\nMore information about the translation of `for` loops into `ForIn.forIn` is available in [the Lean\nreference manual](https://lean-lang.org/doc/reference/4.27.0-rc1/find/?domain=Verso.Genre.Manual.section&name=monad-iteration-syntax).\n</code>",
 "219":
 "<code>Std.Do.WPMonad.{u, v} (m : Type u → Type v) (ps : outParam Std.Do.PostShape) [Monad m] : Type (max (u + 1) v)</code><span class=\"sep\"></span><code class=\"docstring\">A monad with weakest preconditions (`WP`) that is also a monad morphism, preserving `pure` and\n`bind`.\n\nIn practice, `mvcgen` is not useful for reasoning about programs in a monad that is without a\n`WPMonad` instance. The specification lemmas for `Pure.pure` and `Bind.bind`, as well as those for\noperators like `Functor.map`, require that their monad have a `WPMonad` instance.\n</code>",
 "218":
 "<code>Transformers.mkFreshN_spec (n : Nat) : ⦃⌜True⌝⦄ mkFreshN n ⦃PostCond.noThrow fun r =&gt; ⌜r.Nodup⌝⦄</code>",
 "217":
 "<code>Transformers.mkFresh_spec (c : Nat) :\n  ⦃fun state =&gt; ⌜state.counter = c⌝⦄ mkFresh ⦃PostCond.noThrow fun r state =&gt; ⌜r = c ∧ c &lt; state.counter⌝⦄</code>",
 "216": "<code>Transformers.mkFreshN (n : Nat) : AppM (List Nat)</code>",
 "215":
 "<code>Transformers.mkFreshN (n : Nat) : Transformers.AppM (List Nat)</code>",
 "214": "<code>Transformers.mkFresh : CounterM Nat</code>",
 "213": "<code>Transformers.mkFresh : Transformers.CounterM Nat</code>",
 "212": "<code>Transformers.AppM (α : Type) : Type</code>",
 "211":
 "<code>String : Type</code><span class=\"sep\"></span><code class=\"docstring\">A string is a sequence of Unicode scalar values.\n\nAt runtime, strings are represented by [dynamic arrays](https://en.wikipedia.org/wiki/Dynamic_array)\nof bytes using the UTF-8 encoding. Both the size in bytes (`String.utf8ByteSize`) and in characters\n(`String.length`) are cached and take constant time. Many operations on strings perform in-place\nmodifications when the reference to the string is unique.\n</code>",
 "210":
 "<code>ReaderM.{u} (ρ α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A monad with access to a read-only value of type `ρ`. The value can be locally overridden by\n`withReader`, but it cannot be mutated.\n</code>",
 "21":
 "<code>Std.Do.PredTrans.apply.{u} {ps : PostShape} {α : Type u} (self : PredTrans ps α) : PostCond α ps → Assertion ps</code><span class=\"sep\"></span><code class=\"docstring\">Apply the predicate transformer to a postcondition. </code>",
 "209": "<code>Transformers.CounterM (α : Type) : Type</code>",
 "208":
 "<code class=\"docstring\">`mframe` infers which hypotheses from the stateful context can be moved into the pure context.\nThis is useful because pure hypotheses \"survive\" the next application of modus ponens\n(`Std.Do.SPred.mp`) and transitivity (`Std.Do.SPred.entails.trans`).\n\nIt is used as part of the `mspec` tactic.\n\n```lean\nexample (P Q : SPred σs) : ⊢ₛ ⌜p⌝ ∧ Q ∧ ⌜q⌝ ∧ ⌜r⌝ ∧ P ∧ ⌜s⌝ ∧ ⌜t⌝ → Q := by\n  mintro _\n  mframe\n  /- `h : p ∧ q ∧ r ∧ s ∧ t` in the pure context -/\n  mcases h with hP\n  mexact h\n```\n</code>",
 "207":
 "<code>add_spec_pre [Monad M] [WP M PostShape.pure] (x y : UInt8) :\n  ⦃⌜x.toNat + y.toNat ≤ UInt8.size⌝⦄ x +? y ⦃PostCond.noThrow fun r =&gt; ⌜r.toNat = x.toNat + y.toNat⌝⦄</code>",
 "206":
 "<code>UInt8.size : Nat</code><span class=\"sep\"></span><code class=\"docstring\">The number of distinct values representable by `UInt8`, that is, `2^8 = 256`. </code>",
 "205":
 "<code>UInt8.toNat (n : UInt8) : Nat</code><span class=\"sep\"></span><code class=\"docstring\">Converts an 8-bit unsigned integer to an arbitrary-precision natural number.\n\nThis function is overridden at runtime with an efficient implementation.\n</code>",
 "204": "<code>x.toNat + y.toNat ≤ UInt8.size</code>",
 "203":
 "<code>add_spec_hyp [Monad M] [WP M PostShape.pure] (x y : UInt8) (h : x.toNat + y.toNat ≤ UInt8.size) :\n  ⦃⌜True⌝⦄ x +? y ⦃PostCond.noThrow fun r =&gt; ⌜r.toNat = x.toNat + y.toNat⌝⦄</code>",
 "202":
 "<code>UInt8 : Type</code><span class=\"sep\"></span><code class=\"docstring\">Unsigned 8-bit integers.\n\nThis type has special support in the compiler so it can be represented by an unboxed 8-bit value\nrather than wrapping a `BitVec 8`.\n</code>",
 "201": "<code>M : Type → Type</code>",
 "200": "<code>UInt8</code>",
 "20":
 "<code>Std.Do.SPred.entails.{u} {σs : List (Type u)} (P Q : SPred σs) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">Entailment in `SPred`.\n\nOne predicate `P` entails another predicate `Q` if `Q` is true in every state in which `P` is true.\nUnlike implication (`SPred.imp`), entailment is not itself an `SPred`, but is instead an ordinary\nproposition.\n</code>",
 "2": "<code>mySum (l : Array Nat) : Nat</code>",
 "199":
 "<code>mkFreshN_spec (n : Nat) : ⦃⌜True⌝⦄ mkFreshN n ⦃Std.Do.PostCond.noThrow fun r =&gt; ⌜r.Nodup⌝⦄</code>",
 "198":
 "<code>mkFreshN_correct_compositional {s : Supply} (n : Nat) : List.Nodup (StateT.run' (mkFreshN n) s)</code>",
 "197":
 "<code>mkFreshN_spec (n : Nat) : ⦃⌜True⌝⦄ mkFreshN n ⦃PostCond.noThrow fun r =&gt; ⌜r.Nodup⌝⦄</code>",
 "196":
 "<code>LT.lt.{u} {α : Type u} [self : LT α] : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The less-than relation: `x &lt; y` \n\nConventions for notations in identifiers:\n\n * The recommended spelling of `&lt;` in identifiers is `lt`.</code>",
 "195":
 "<code>Std.Do.Triple.{u, v} {m : Type u → Type v} {ps : PostShape} [WP m ps] {α : Type u} (x : m α) (P : Assertion ps)\n  (Q : PostCond α ps) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A Hoare triple for reasoning about monadic programs. A Hoare triple `Triple x P Q` is a\n*specification* for `x`: if assertion `P` holds before `x`, then postcondition `Q` holds after\nrunning `x`.\n\n`⦃P⦄ x ⦃Q⦄` is convenient syntax for `Triple x P Q`.\n</code>",
 "194":
 "<code>mkFresh_spec (c : Nat) :\n  ⦃fun state =&gt; ⌜state.counter = c⌝⦄ mkFresh ⦃PostCond.noThrow fun r state =&gt; ⌜r = c ∧ c &lt; state.counter⌝⦄</code>",
 "193":
 "<code class=\"docstring\">Theorems tagged with the `spec` attribute are used by the `mspec` and `mvcgen` tactics.\n\n* When used on a theorem `foo_spec : Triple (foo a b c) P Q`, then `mspec` and `mvcgen` will use\n  `foo_spec` as a specification for calls to `foo`.\n* Otherwise, when used on a definition that `@[simp]` would work on, it is added to the internal\n  simp set of `mvcgen` that is used within `wp⟦·⟧` contexts to simplify match discriminants and\n  applications of constants.\n</code>",
 "192":
 "<code class=\"docstring\">`mpure` moves a pure hypothesis from the stateful context into the pure context.\n```lean\nexample (Q : SPred σs) (ψ : φ → ⊢ₛ Q): ⌜φ⌝ ⊢ₛ Q := by\n  mintro Hφ\n  mpure Hφ\n  mexact (ψ Hφ)\n```\n</code>",
 "191":
 "<code>StateT.run.{u, v} {σ : Type u} {m : Type u → Type v} {α : Type u} (x : StateT σ m α) (s : σ) : m (α × σ)</code><span class=\"sep\"></span><code class=\"docstring\">Executes an action from a monad with added state in the underlying monad `m`. Given an initial\nstate, it returns a value paired with the final state.\n</code>",
 "190": "<code>α</code>",
 "19":
 "<code>Std.Do.Id.of_wp_run_eq.{u} {α : Type u} {x : α} {prog : Id α} (h : prog.run = x) (P : α → Prop) :\n  (⊢ₛ wp⟦prog⟧ (PostCond.noThrow fun a =&gt; { down := P a })) → P x</code><span class=\"sep\"></span><code class=\"docstring\">Adequacy lemma for `Id.run`.\nUseful if you want to prove a property about an expression `x` defined as `Id.run prog` and you\nwant to use `mvcgen` to reason about `prog`.\n</code>",
 "189":
 "<code class=\"docstring\">`let` is used to declare a local definition. Example:\n```\nlet x := 1\nlet y := x + 1\nx + y\n```\nSince functions are first class citizens in Lean, you can use `let` to declare\nlocal functions too.\n```\nlet double := fun x =&gt; 2*x\ndouble (double 3)\n```\nFor recursive definitions, you should use `let rec`.\nYou can also perform pattern matching using `let`. For example,\nassume `p` has type `Nat × Nat`, then you can write\n```\nlet (x, y) := p\nx + y\n```\n\nThe *anaphoric let* `let := v` defines a variable called `this`.\n</code>",
 "188": "<code>σ</code>",
 "187": "<code>(α → σ → ULift Prop) × PUnit</code>",
 "186":
 "<code>ULift.{r, s} (α : Type s) : Type (max s r)</code><span class=\"sep\"></span><code class=\"docstring\">Lifts a type to a higher universe level.\n\n`ULift α` wraps a value of type `α`. Instead of occupying the same universe as `α`, which would be\nthe minimal level, it takes a further level parameter and occupies their maximum. The resulting type\nmay occupy any universe that's at least as large as that of `α`.\n\nThe resulting universe of the lifting operator is the first parameter, and may be written explicitly\nwhile allowing `α`'s level to be inferred.\n\nThe related type `PLift` can be used to lift a proposition or type by one level.\n\nExamples:\n * `(Nat : Type 0)`\n * `(ULift Nat : Type 0)`\n * `(ULift Nat : Type 1)`\n * `(ULift Nat : Type 5)`\n * `(ULift.{7} (PUnit : Type 3) : Type 7)`\n</code>",
 "185": "<code>σ → ULift Prop</code>",
 "184": "<code>StateM σ α</code>",
 "183":
 "<code>StateMTriple.{u, u_1, u_2, u_3} {α σ : Type u} (prog : StateM σ α) (P : σ → ULift Prop)\n  (Q : (α → σ → ULift Prop) × PUnit) : Prop</code>",
 "182":
 "<code>Std.Do.Assertion.{u} (ps : Std.Do.PostShape) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">An assertion about the state fields for a monad whose postcondition shape is `ps`.\n\nConcretely, this is an abbreviation for `SPred` applied to the `.arg`s in the given predicate shape, so all theorems about `SPred` apply.\n\nExamples:\n```lean example\nexample : Assertion (.arg ρ .pure) = (ρ → ULift Prop) := rfl\nexample : Assertion (.except ε .pure) = ULift Prop := rfl\nexample : Assertion (.arg σ (.except ε .pure)) = (σ → ULift Prop) := rfl\nexample : Assertion (.except ε (.arg σ .pure)) = (σ → ULift Prop) := rfl\n```\n</code>",
 "181":
 "<code>ExceptT.{u, v} (ε : Type u) (m : Type u → Type v) (α : Type u) : Type v</code><span class=\"sep\"></span><code class=\"docstring\">Adds exceptions of type `ε` to a monad `m`.\n</code>",
 "180":
 "<code>ReaderT.{u, v} (ρ : Type u) (m : Type u → Type v) (α : Type u) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Adds the ability to access a read-only value of type `ρ` to a monad. The value can be locally\noverridden by `withReader`, but it cannot be mutated.\n\nActions in the resulting monad are functions that take the local value as a parameter, returning\nordinary actions in `m`.\n</code>",
 "18":
 "<code class=\"docstring\">`apply e` tries to match the current goal against the conclusion of `e`'s type.\nIf it succeeds, then the tactic returns as many subgoals as the number of premises that\nhave not been fixed by type inference or type class resolution.\nNon-dependent premises are added before dependent ones.\n\nThe `apply` tactic uses higher-order pattern matching, type class resolution,\nand first-order unification with dependent types.\n</code>",
 "179":
 "<code>StateT.{u, v} (σ : Type u) (m : Type u → Type v) (α : Type u) : Type (max u v)</code><span class=\"sep\"></span><code class=\"docstring\">Adds a mutable state of type `σ` to a monad.\n\nActions in the resulting monad are functions that take an initial state and return, in `m`, a tuple\nof a value and a state.\n</code>",
 "178":
 "<code>Std.Do.PostShape.{u} : Type (u + 1)</code><span class=\"sep\"></span><code class=\"docstring\">The “shape” of the postconditions that are used to reason about a monad.\n\nA postcondition shape is an abstraction of many possible monadic effects, based on the structure of pure functions that can simulate them. The postcondition shape of a monad is given by its `WP` instance. This shape is used to determine both its `Assertion`s and its `PostCond`s.\n</code>",
 "177":
 "<code class=\"docstring\">The universe of propositions. `Prop ≡ Sort 0`.\n\nEvery proposition is propositionally equal to either `True` or `False`. </code>",
 "176":
 "<code>Std.Do.PostCond.{u} (α : Type u) (ps : PostShape) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A postcondition for the given predicate shape, with one `Assertion` for the terminating case and\none `Assertion` for each `.except` layer in the predicate shape.\n```\nvariable (α σ ε : Type)\nexample : PostCond α (.arg σ .pure) = ((α → σ → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.except ε .pure) = ((α → ULift Prop) × (ε → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.arg σ (.except ε .pure)) = ((α → σ → ULift Prop) × (ε → ULift Prop) × PUnit) := rfl\nexample : PostCond α (.except ε (.arg σ .pure)) = ((α → σ → ULift Prop) × (ε → σ → ULift Prop) × PUnit) := rfl\n```\n</code>",
 "175":
 "<code>Std.Do.Assertion.{u} (ps : PostShape) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">An assertion about the state fields for a monad whose postcondition shape is `ps`.\n\nConcretely, this is an abbreviation for `SPred` applied to the `.arg`s in the given predicate shape, so all theorems about `SPred` apply.\n\nExamples:\n```lean example\nexample : Assertion (.arg ρ .pure) = (ρ → ULift Prop) := rfl\nexample : Assertion (.except ε .pure) = ULift Prop := rfl\nexample : Assertion (.arg σ (.except ε .pure)) = (σ → ULift Prop) := rfl\nexample : Assertion (.except ε (.arg σ .pure)) = (σ → ULift Prop) := rfl\n```\n</code>",
 "174": "<code class=\"docstring\">The universe parameter u</code>",
 "173":
 "<code class=\"docstring\">A type universe. `Type ≡ Type 0`, `Type u ≡ Sort (u + 1)`. </code>",
 "172": "<code>PostShape</code>",
 "171":
 "<code>Std.Do.WP.{u, v} (m : Type u → Type v) (ps : outParam PostShape) : Type (max (u + 1) v)</code><span class=\"sep\"></span><code class=\"docstring\">A weakest precondition interpretation of a monadic program `x : m α` in terms of a predicate\ntransformer `PredTrans ps α`. The monad `m` determines `ps : PostShape`.\n\nFor practical reasoning, an instance of `WPMonad m ps` is typically needed in addition to `WP m ps`.\n</code>",
 "170":
 "<code>_root_.Triple.{u, v} {m : Type u → Type v} {ps : PostShape} [WP m ps] {α : Type u} (prog : m α) (P : Assertion ps)\n  (Q : PostCond α ps) : Prop</code>",
 "17": "<code>mySum l = x</code>",
 "169":
 "<code>Std.Do.Triple.{u, v} {m : Type u → Type v} {ps : Std.Do.PostShape} [Std.Do.WP m ps] {α : Type u} (x : m α)\n  (P : Std.Do.Assertion ps) (Q : Std.Do.PostCond α ps) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">A Hoare triple for reasoning about monadic programs. A Hoare triple `Triple x P Q` is a\n*specification* for `x`: if assertion `P` holds before `x`, then postcondition `Q` holds after\nrunning `x`.\n\n`⦃P⦄ x ⦃Q⦄` is convenient syntax for `Triple x P Q`.\n</code>",
 "168":
 "<code class=\"docstring\">`wp⟦x⟧ Q` is defined as `(WP.wp x).apply Q`. </code>",
 "167": "<code>Prop</code>",
 "166": "<code>PostCond Unit ps</code>",
 "165": "<code>m PUnit</code>",
 "164":
 "<code>Std.Do.WP.{u, v} (m : Type u → Type v) (ps : outParam Std.Do.PostShape) : Type (max (u + 1) v)</code><span class=\"sep\"></span><code class=\"docstring\">A weakest precondition interpretation of a monadic program `x : m α` in terms of a predicate\ntransformer `PredTrans ps α`. The monad `m` determines `ps : PostShape`.\n\nFor practical reasoning, an instance of `WPMonad m ps` is typically needed in addition to `WP m ps`.\n</code>",
 "163": "<code>PostCond α ps</code>",
 "162": "<code>m α</code>",
 "161": "<code>Assertion ps</code>",
 "160": "<code>[:n].toList.Cursor</code>",
 "16":
 "<code class=\"docstring\">* `generalize ([h :] e = x),+` replaces all occurrences `e`s in the main goal\n  with a fresh hypothesis `x`s. If `h` is given, `h : e = x` is introduced as well.\n* `generalize e = x at h₁ ... hₙ` also generalizes occurrences of `e`\n  inside `h₁`, ..., `hₙ`.\n* `generalize e = x at *` will generalize occurrences of `e` everywhere.\n</code>",
 "159":
 "<code>Std.Do.SPred.pure.{u} {σs : List (Type u)} (P : Prop) : SPred σs</code><span class=\"sep\"></span><code class=\"docstring\">A pure proposition `P : Prop` embedded into `SPred`.\nPrefer to use notation `⌜P⌝`.\n</code>",
 "158":
 "<code>Std.Do.StateM.of_wp_run'_eq.{u_1} {σ : Type u_1} {s : σ} {α : Type u_1} {x : α} {prog : StateM σ α}\n  (h : StateT.run' prog s = x) (P : α → Prop) : (⊢ₛ wp⟦prog⟧ (PostCond.noThrow fun a =&gt; ⌜P a⌝) s) → P x</code><span class=\"sep\"></span><code class=\"docstring\">Adequacy lemma for `StateM.run'`.\nUseful if you want to prove a property about an expression `x` defined as `StateM.run' prog s` and\nyou want to use `mvcgen` to reason about `prog`.\n</code>",
 "157": "<code>Id (List Nat)</code>",
 "156": "<code>StateT.run' (mkFreshN n) s = x</code>",
 "155":
 "<code>StateT.run'.{u, v} {σ : Type u} {m : Type u → Type v} [Functor m] {α : Type u} (x : StateT σ m α) (s : σ) : m α</code><span class=\"sep\"></span><code class=\"docstring\">Executes an action from a monad with added state in the underlying monad `m`. Given an initial\nstate, it returns a value, discarding the final state.\n</code>",
 "154":
 "<code>Std.Do.StateM.of_wp_run'_eq.{u_1} {σ : Type u_1} {s : σ} {α : Type u_1} {x : α} {prog : StateM σ α}\n  (h : StateT.run' prog s = x) (P : α → Prop) :\n  (⊢ₛ (Std.Do.wp prog).apply (Std.Do.PostCond.noThrow fun a =&gt; ⌜P a⌝) s) → P x</code><span class=\"sep\"></span><code class=\"docstring\">Adequacy lemma for `StateM.run'`.\nUseful if you want to prove a property about an expression `x` defined as `StateM.run' prog s` and\nyou want to use `mvcgen` to reason about `prog`.\n</code>",
 "153":
 "<code>mkFreshN_correct {s : Supply} (n : Nat) : List.Nodup (StateT.run' (mkFreshN n) s)</code>",
 "152":
 "<code>Array.push.{u} {α : Type u} (a : Array α) (v : α) : Array α</code><span class=\"sep\"></span><code class=\"docstring\">Adds an element to the end of an array. The resulting array's size is one greater than the input\narray. If there are no other references to the array, then it is modified in-place.\n\nThis takes amortized `O(1)` time because `Array α` is represented by a dynamic array.\n\nExamples:\n* `#[].push \"apple\" = #[\"apple\"]`\n* `#[\"apple\"].push \"orange\" = #[\"apple\", \"orange\"]`\n</code>",
 "151": "<code>mkFreshN (n : Nat) : StateM Supply (List Nat)</code>",
 "150": "<code>Nat</code>",
 "15":
 "<code>Eq.{u_1} {α : Sort u_1} : α → α → Prop</code><span class=\"sep\"></span><code class=\"docstring\">The equality relation. It has one introduction rule, `Eq.refl`.\nWe use `a = b` as notation for `Eq a b`.\nA fundamental property of equality is that it is an equivalence relation.\n```\nvariable (α : Type) (a b c d : α)\nvariable (hab : a = b) (hcb : c = b) (hcd : c = d)\n\nexample : a = d :=\n  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd\n```\nEquality is much more than an equivalence relation, however. It has the important property that every assertion\nrespects the equivalence, in the sense that we can substitute equal expressions without changing the truth value.\nThat is, given `h1 : a = b` and `h2 : p a`, we can construct a proof for `p b` using substitution: `Eq.subst h1 h2`.\nExample:\n```\nexample (α : Type) (a b : α) (p : α → Prop)\n        (h1 : a = b) (h2 : p a) : p b :=\n  Eq.subst h1 h2\n\nexample (α : Type) (a b : α) (p : α → Prop)\n    (h1 : a = b) (h2 : p a) : p b :=\n  h1 ▸ h2\n```\nThe triangle in the second presentation is a macro built on top of `Eq.subst` and `Eq.symm`, and you can enter it by typing `\\t`.\nFor more information: [Equality](https://lean-lang.org/theorem_proving_in_lean4/quantifiers_and_equality.html#equality)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `=` in identifiers is `eq`.</code>",
 "149": "<code>Supply</code>",
 "148":
 "<code>modify.{u, v} {σ : Type u} {m : Type u → Type v} [MonadState σ m] (f : σ → σ) : m PUnit</code><span class=\"sep\"></span><code class=\"docstring\">Mutates the current state, replacing its value with the result of applying `f` to it.\n\nUse `modifyThe` to explicitly select a state type to modify.\n\nIt is equivalent to `do set (f (← get))`. However, using `modify` may lead to higher performance\nbecause it doesn't add a new reference to the state value. Additional references can inhibit\nin-place updates of data.\n</code>",
 "147":
 "<code>MonadState.get.{u, v} {σ : outParam (Type u)} {m : Type u → Type v} [self : MonadState σ m] : m σ</code><span class=\"sep\"></span><code class=\"docstring\">Retrieves the current value of the monad's mutable state.\n</code>",
 "146":
 "<code>StateM.{u} (σ α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A tuple-based state monad.\n\nActions in `StateM σ` are functions that take an initial state and return a value paired with a\nfinal state.\n</code>",
 "145": "<code>Supply.counter (self : Supply) : Nat</code>",
 "144": "<code>Supply : Type</code>",
 "143": "<code>mkFresh : StateM Supply Nat</code>",
 "142": "<code>Type u</code>",
 "141":
 "<code>M.run.{u, v, u_1} (M : Type u → Type v) (α : Type u) {β : Sort u_1} : M α → β → α</code>",
 "140": "<code>Type u → Type v</code>",
 "14":
 "<code class=\"docstring\">`by tac` constructs a term of the expected type by running the tactic(s) `tac`. </code>",
 "139":
 "<code class=\"docstring\">Marks Hoare triple specifications and simp theorems to use with the `mspec` and `mvcgen` tactics</code>",
 "138":
 "<code class=\"docstring\">The `fun_induction` tactic is a convenience wrapper around the `induction` tactic to use the\nfunctional induction principle.\n\nThe tactic invocation\n```\nfun_induction f x₁ ... xₙ y₁ ... yₘ\n```\nwhere `f` is a function defined by non-mutual structural or well-founded recursion, is equivalent to\n```\ninduction y₁, ... yₘ using f.induct_unfolding x₁ ... xₙ\n```\nwhere the arguments of `f` are used as arguments to `f.induct_unfolding` or targets of the\ninduction, as appropriate.\n\nThe form\n```\nfun_induction f\n```\n(with no arguments to `f`) searches the goal for a unique eligible application of `f`, and uses\nthese arguments. An application of `f` is eligible if it is saturated and the arguments that will\nbecome targets are free variables.\n\nThe forms `fun_induction f x y generalizing z₁ ... zₙ` and\n`fun_induction f x y with | case1 =&gt; tac₁ | case2 x' ih =&gt; tac₂` work like with `induction.`\n\nUnder `set_option tactic.fun_induction.unfolding true` (the default), `fun_induction` uses the\n`f.induct_unfolding` induction principle, which will try to automatically unfold the call to `f` in\nthe goal. With `set_option tactic.fun_induction.unfolding false`, it uses `f.induct` instead.\n</code>",
 "137":
 "<code class=\"docstring\">The `fun_cases` tactic is a convenience wrapper of the `cases` tactic when using a functional\ncases principle.\n\nThe tactic invocation\n```\nfun_cases f x ... y ...`\n```\nis equivalent to\n```\ncases y, ... using f.fun_cases_unfolding x ...\n```\nwhere the arguments of `f` are used as arguments to `f.fun_cases_unfolding` or targets of the case\nanalysis, as appropriate.\n\nThe form\n```\nfun_cases f\n```\n(with no arguments to `f`) searches the goal for a unique eligible application of `f`, and uses\nthese arguments. An application of `f` is eligible if it is saturated and the arguments that will\nbecome targets are free variables.\n\nThe form `fun_cases f x y with | case1 =&gt; tac₁ | case2 x' ih =&gt; tac₂` works like with `cases`.\n\nUnder `set_option tactic.fun_induction.unfolding true` (the default), `fun_induction` uses the\n`f.fun_cases_unfolding` theorem, which will try to automatically unfold the call to `f` in\nthe goal. With `set_option tactic.fun_induction.unfolding false`, it uses `f.fun_cases` instead.\n</code>",
 "136":
 "<code>Id.run_seq.{u_1} {α β : Type u_1} (f : Id (α → β)) (x : Id α) : (f &lt;*&gt; x).run = f.run x.run</code>",
 "135":
 "<code>Id.run_bind.{u_1} {α β : Type u_1} (x : Id α) (f : α → Id β) : (x &gt;&gt;= f).run = (f x.run).run</code>",
 "134":
 "<code>Id.run_pure.{u_1} {α : Type u_1} (a : α) : (pure a).run = a</code>",
 "133":
 "<code class=\"docstring\">`clear x...` removes the given hypotheses, or fails if there are remaining\nreferences to a hypothesis.\n</code>",
 "132":
 "<code>And (a b : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`And a b`, or `a ∧ b`, is the conjunction of propositions. It can be\nconstructed and destructed like a pair: if `ha : a` and `hb : b` then\n`⟨ha, hb⟩ : a ∧ b`, and if `h : a ∧ b` then `h.left : a` and `h.right : b`.\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `∧` in identifiers is `and`.\n\n * The recommended spelling of `/\\` in identifiers is `and` (prefer `∧` over `/\\`).</code>",
 "131":
 "<code>(have seen := seen;\n      do\n      let r ←\n        forIn l ⟨none, seen⟩ fun x r =&gt;\n            have r := r.snd;\n            have seen := r;\n            have __do_jp := fun seen y =&gt;\n              have seen := seen.insert x;\n              do\n              pure PUnit.unit\n              pure (ForInStep.yield ⟨none, seen⟩);\n            if x ∈ seen then pure (ForInStep.done ⟨some false, seen⟩)\n            else do\n              let y ← pure PUnit.unit\n              __do_jp seen y\n      have seen : Std.HashSet Int := r.snd\n      have __do_jp : PUnit → Id Bool := fun y =&gt; pure true\n      match r.fst with\n        | none =&gt; do\n          let y ← pure PUnit.unit\n          __do_jp y\n        | some a =&gt; pure a).run =\n    true ↔\n  l.Nodup ∧ ∀ (x : Int), x ∈ l → ¬x ∈ seen</code>",
 "130":
 "<code class=\"docstring\">* `change tgt'` will change the goal from `tgt` to `tgt'`,\n  assuming these are definitionally equal.\n* `change t' at h` will change hypothesis `h : t` to have type `t'`, assuming\n  assuming `t` and `t'` are definitionally equal.\n</code>",
 "13": "<code>mySum_correct (l : Array Nat) : mySum l = l.sum</code>",
 "129": "<code>∅ = seen</code>",
 "128":
 "<code class=\"docstring\">`rw` is like `rewrite`, but also tries to close the goal by \"cheap\" (reducible) `rfl` afterwards.\n</code>",
 "127":
 "<code>nodup_correct_directly (l : List Int) : nodup l = true ↔ l.Nodup</code>",
 "126":
 "<code class=\"docstring\">The `sorry` tactic is a temporary placeholder for an incomplete tactic proof,\nclosing the main goal using `exact sorry`.\n\nThis is intended for stubbing-out incomplete parts of a proof while still having a syntactically correct proof skeleton.\nLean will give a warning whenever a proof uses `sorry`, so you aren't likely to miss it,\nbut you can double check if a theorem depends on `sorry` by looking for `sorryAx` in the output\nof the `#print axioms my_thm` command, the axiom used by the implementation of `sorry`.\n</code>",
 "125": "<code>r✝.fst = some a✝</code>",
 "124":
 "<code>True : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`True` is a proposition and has only an introduction rule, `True.intro : True`.\nIn other words, `True` is simply true, and has a canonical proof, `True.intro`\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n</code>",
 "123":
 "<code>(Prod.fst ?inv1 ({ «prefix» := l, suffix := [], property := ⋯ }, r✝)).down</code>",
 "122": "<code>r✝.fst = none</code>",
 "121":
 "<code>[] ++ l = [] ++ l</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "120":
 "<code>pref✝ ++ [cur✝] ++ suff✝ = l</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "12":
 "<code>Id.{u} (type : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">The identity function on types, used primarily for its `Monad` instance.\n\nThe identity monad is useful together with monad transformers to construct monads for particular\npurposes. Additionally, it can be used with `do`-notation in order to use control structures such as\nlocal mutability, `for`-loops, and early returns in code that does not otherwise use monads.\n\nExamples:\n```lean example\ndef containsFive (xs : List Nat) : Bool := Id.run do\n  for x in xs do\n    if x == 5 then return true\n  return false\n```\n\n```lean example\n#eval containsFive [1, 3, 5, 7]\n```\n```output\ntrue\n```\n</code>",
 "119":
 "<code>Not (a : Prop) : Prop</code><span class=\"sep\"></span><code class=\"docstring\">`Not p`, or `¬p`, is the negation of `p`. It is defined to be `p → False`,\nso if your goal is `¬p` you can use `intro h` to turn the goal into\n`h : p ⊢ False`, and if you have `hn : ¬p` and `h : p` then `hn h : False`\nand `(hn h).elim` will prove anything.\nFor more information: [Propositional Logic](https://lean-lang.org/theorem_proving_in_lean4/propositions_and_proofs.html#propositional-logic)\n\n\nConventions for notations in identifiers:\n\n * The recommended spelling of `¬` in identifiers is `not`.</code>",
 "118": "<code>¬cur✝ ∈ seen✝</code>",
 "117":
 "<code>l ++ [] = l</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "116":
 "<code>pref✝ ++ cur✝ :: suff✝ = l</code><span class=\"sep\"></span><code class=\"docstring\">Appending the prefix to the suffix yields the original list. </code>",
 "115":
 "<code>List Int</code><span class=\"sep\"></span><code class=\"docstring\">The elements starting at the current position. If the position is after the last element of the\nlist, then the suffix is empty; otherwise, the first element of the suffix is the current element\nthat the cursor points to.\n</code>",
 "114":
 "<code>List Int</code><span class=\"sep\"></span><code class=\"docstring\">The elements before to the current position in the list.\n</code>",
 "113": "<code>cur✝ ∈ seen✝</code>",
 "112":
 "<code>ForInStep.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">An indication of whether a loop's body terminated early that's used to compile the `for x in xs`\nnotation.\n\nA collection's `ForIn` or `ForIn'` instance describe's how to iterate over its elements. The monadic\naction that represents the body of the loop returns a `ForInStep α`, where `α` is the local state\nused to implement features such as `let mut`.\n</code>",
 "111": "<code>l = pref✝ ++ cur✝ :: suff✝</code>",
 "110":
 "<code>Option.{u} (α : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">Optional values, which are either `some` around a value from the underlying type or `none`.\n\n`Option` can represent nullable types or computations that might fail. In the codomain of a function\ntype, it can also represent partiality.\n</code>",
 "11":
 "<code>Std.Do.Id.of_wp_run_eq.{u} {α : Type u} {x : α} {prog : Id α} (h : prog.run = x) (P : α → Prop) :\n  (⊢ₛ (Std.Do.wp prog).apply (Std.Do.PostCond.noThrow fun a =&gt; { down := P a })) → P x</code><span class=\"sep\"></span><code class=\"docstring\">Adequacy lemma for `Id.run`.\nUseful if you want to prove a property about an expression `x` defined as `Id.run prog` and you\nwant to use `mvcgen` to reason about `prog`.\n</code>",
 "109":
 "<code>MProd.{u} (α β : Type u) : Type u</code><span class=\"sep\"></span><code class=\"docstring\">A product type in which both `α` and `β` are in the same universe.\n\nIt is called `MProd` is because it is the *universe-monomorphic* product type.\n</code>",
 "108":
 "<code>Std.Do.Invariant.withEarlyReturn.{u₁, u₂} {β : Type (max u₁ u₂)} {ps : Std.Do.PostShape} {α✝ : Type (max u₁ u₂)}\n  {xs : List α✝} {γ : Type (max u₁ u₂)} (onContinue : xs.Cursor → β → Std.Do.Assertion ps)\n  (onReturn : γ → β → Std.Do.Assertion ps) (onExcept : Std.Do.ExceptConds ps := Std.Do.ExceptConds.false) :\n  Std.Do.Invariant xs (MProd (Option γ) β) ps</code><span class=\"sep\"></span><code class=\"docstring\">Helper definition for specifying loop invariants for loops with early return.\n\n`for ... in ...` loops with early return of type `γ` elaborate to a call like this:\n```lean\nforIn (β := MProd (Option γ) ...) (b := ⟨none, ...⟩) collection loopBody\n```\nNote that the first component of the `MProd` state tuple is the optional early return value.\nIt is `none` as long as there was no early return and `some r` if the loop returned early with `r`.\n\nThis function allows to specify different invariants for the loop body depending on whether the loop\nterminated early or not. When there was an early return, the loop has effectively finished, which is\nencoded by the additional `⌜xs.suffix = []⌝` assertion in the invariant. This assertion is vital for\nsuccessfully proving the induction step, as it contradicts with the assumption that\n`xs.suffix = x::rest` of the inductive hypothesis at the start of the loop body, meaning that users\nwon't need to prove anything about the bogus case where the loop has returned early yet takes\nanother iteration of the loop body.\n</code>",
 "107": "<code>onExcept.{u_1} : ExceptConds PostShape.pure</code>",
 "106":
 "<code>onContinue.{u_1} {l : List Int} : l.Cursor → Std.HashSet Int → SPred PostShape.pure.args</code>",
 "105":
 "<code>onReturn.{u_1} : Bool → Std.HashSet Int → SPred PostShape.pure.args</code>",
 "104": "<code>l.Cursor</code>",
 "103":
 "<code>Std.Do.Invariant.withEarlyReturn.{u₁, u₂} {β : Type (max u₁ u₂)} {ps : PostShape} {α✝ : Type (max u₁ u₂)} {xs : List α✝}\n  {γ : Type (max u₁ u₂)} (onContinue : xs.Cursor → β → Assertion ps) (onReturn : γ → β → Assertion ps)\n  (onExcept : ExceptConds ps := ExceptConds.false) : Invariant xs (MProd (Option γ) β) ps</code><span class=\"sep\"></span><code class=\"docstring\">Helper definition for specifying loop invariants for loops with early return.\n\n`for ... in ...` loops with early return of type `γ` elaborate to a call like this:\n```lean\nforIn (β := MProd (Option γ) ...) (b := ⟨none, ...⟩) collection loopBody\n```\nNote that the first component of the `MProd` state tuple is the optional early return value.\nIt is `none` as long as there was no early return and `some r` if the loop returned early with `r`.\n\nThis function allows to specify different invariants for the loop body depending on whether the loop\nterminated early or not. When there was an early return, the loop has effectively finished, which is\nencoded by the additional `⌜xs.suffix = []⌝` assertion in the invariant. This assertion is vital for\nsuccessfully proving the induction step, as it contradicts with the assumption that\n`xs.suffix = x::rest` of the inductive hypothesis at the start of the loop body, meaning that users\nwon't need to prove anything about the bogus case where the loop has returned early yet takes\nanother iteration of the loop body.\n</code>",
 "102": "<code>PUnit → Id Bool</code>",
 "101":
 "<code>MProd.fst.{u} {α β : Type u} (self : MProd α β) : α</code><span class=\"sep\"></span><code class=\"docstring\">The first element of a pair. </code>",
 "100":
 "<code>PUnit.{u} : Sort u</code><span class=\"sep\"></span><code class=\"docstring\">The canonical universe-polymorphic type with just one element.\n\nIt should be used in contexts that require a type to be universe polymorphic, thus disallowing\n`Unit`.\n</code>",
 "10":
 "<code>Array.sum.{u_1} {α : Type u_1} [Add α] [Zero α] : Array α → α</code><span class=\"sep\"></span><code class=\"docstring\">Computes the sum of the elements of an array.\n\nExamples:\n* `#[a, b, c].sum = a + (b + (c + 0))`\n* `#[1, 2, 5].sum = 8`\n</code>",
 "1":
 "<code class=\"docstring\">Makes names from other namespaces visible without writing the namespace prefix.\n\nNames that are made available with `open` are visible within the current `section` or `namespace`\nblock. This makes referring to (type) definitions and theorems easier, but note that it can also\nmake [scoped instances], notations, and attributes from a different namespace available.\n\nThe `open` command can be used in a few different ways:\n\n* `open Some.Namespace.Path1 Some.Namespace.Path2` makes all non-protected names in\n  `Some.Namespace.Path1` and `Some.Namespace.Path2` available without the prefix, so that\n  `Some.Namespace.Path1.x` and `Some.Namespace.Path2.y` can be referred to by writing only `x` and\n  `y`.\n\n* `open Some.Namespace.Path hiding def1 def2` opens all non-protected names in `Some.Namespace.Path`\n  except `def1` and `def2`.\n\n* `open Some.Namespace.Path (def1 def2)` only makes `Some.Namespace.Path.def1` and\n  `Some.Namespace.Path.def2` available without the full prefix, so `Some.Namespace.Path.def3` would\n  be unaffected.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open Some.Namespace.Path renaming def1 → def1', def2 → def2'` same as `open Some.Namespace.Path\n  (def1 def2)` but `def1`/`def2`'s names are changed to `def1'`/`def2'`.\n\n  This works even if `def1` and `def2` are `protected`.\n\n* `open scoped Some.Namespace.Path1 Some.Namespace.Path2` **only** opens [scoped instances],\n  notations, and attributes from `Namespace1` and `Namespace2`; it does **not** make any other name\n  available.\n\n* `open &lt;any of the open shapes above&gt; in` makes the names `open`-ed visible only in the next\n  command or expression.\n\n[scoped instance]: https://lean-lang.org/theorem_proving_in_lean4/type_classes.html#scoped-instances\n(Scoped instances in Theorem Proving in Lean)\n\n\n## Examples\n\n```lean\n/-- SKI combinators https://en.wikipedia.org/wiki/SKI_combinator_calculus -/\nnamespace Combinator.Calculus\n  def I (a : α) : α := a\n  def K (a : α) : β → α := fun _ =&gt; a\n  def S (x : α → β → γ) (y : α → β) (z : α) : γ := x z (y z)\nend Combinator.Calculus\n\nsection\n  -- open everything under `Combinator.Calculus`, *i.e.* `I`, `K` and `S`,\n  -- until the section ends\n  open Combinator.Calculus\n\n  theorem SKx_eq_K : S K x = I := rfl\nend\n\n-- open everything under `Combinator.Calculus` only for the next command (the next `theorem`, here)\nopen Combinator.Calculus in\ntheorem SKx_eq_K' : S K x = I := rfl\n\nsection\n  -- open only `S` and `K` under `Combinator.Calculus`\n  open Combinator.Calculus (S K)\n\n  theorem SKxy_eq_y : S K x y = y := rfl\n\n  -- `I` is not in scope, we have to use its full path\n  theorem SKxy_eq_Iy : S K x y = Combinator.Calculus.I y := rfl\nend\n\nsection\n  open Combinator.Calculus\n    renaming\n      I → identity,\n      K → konstant\n\n  #check identity\n  #check konstant\nend\n\nsection\n  open Combinator.Calculus\n    hiding S\n\n  #check I\n  #check K\nend\n\nsection\n  namespace Demo\n    inductive MyType\n    | val\n\n    namespace N1\n      scoped infix:68 \" ≋ \" =&gt; BEq.beq\n\n      scoped instance : BEq MyType where\n        beq _ _ := true\n\n      def Alias := MyType\n    end N1\n  end Demo\n\n  -- bring `≋` and the instance in scope, but not `Alias`\n  open scoped Demo.N1\n\n  #check Demo.MyType.val == Demo.MyType.val\n  #check Demo.MyType.val ≋ Demo.MyType.val\n  -- #check Alias -- unknown identifier 'Alias'\nend\n```\n</code>",
 "0":
 "<code class=\"docstring\">`mvcgen` will break down a Hoare triple proof goal like `⦃P⦄ prog ⦃Q⦄` into verification conditions,\nprovided that all functions used in `prog` have specifications registered with `@[spec]`.\n\n### Verification Conditions and specifications\n\nA verification condition is an entailment in the stateful logic of `Std.Do.SPred`\nin which the original program `prog` no longer occurs.\nVerification conditions are introduced by the `mspec` tactic; see the `mspec` tactic for what they\nlook like.\nWhen there's no applicable `mspec` spec, `mvcgen` will try and rewrite an application\n`prog = f a b c` with the simp set registered via `@[spec]`.\n\n### Features\n\nWhen used like `mvcgen +noLetElim [foo_spec, bar_def, instBEqFloat]`, `mvcgen` will additionally\n\n* add a Hoare triple specification `foo_spec : ... → ⦃P⦄ foo ... ⦃Q⦄` to `spec` set for a\n  function `foo` occurring in `prog`,\n* unfold a definition `def bar_def ... := ...` in `prog`,\n* unfold any method of the `instBEqFloat : BEq Float` instance in `prog`.\n* it will no longer substitute away `let`-expressions that occur at most once in `P`, `Q` or `prog`.\n\n### Config options\n\n`+noLetElim` is just one config option of many. Check out `Lean.Elab.Tactic.Do.VCGen.Config` for all\noptions. Of particular note is `stepLimit = some 42`, which is useful for bisecting bugs in\n`mvcgen` and tracing its execution.\n\n### Extended syntax\n\nOften, `mvcgen` will be used like this:\n```\nmvcgen [...]\ncase inv1 =&gt; by exact I1\ncase inv2 =&gt; by exact I2\nall_goals (mleave; try grind)\n```\nThere is special syntax for this:\n```\nmvcgen [...] invariants\n· I1\n· I2\nwith grind\n```\nWhen `I1` and `I2` need to refer to inaccessibles (`mvcgen` will introduce a lot of them for program\nvariables), you can use case label syntax:\n```\nmvcgen [...] invariants\n| inv1 _ acc _ =&gt; I1 acc\n| _ =&gt; I2\nwith grind\n```\nThis is more convenient than the equivalent `· by rename_i _ acc _; exact I1 acc`.\n\n### Invariant suggestions\n\n`mvcgen` will suggest invariants for you if you use the `invariants?` keyword.\n```\nmvcgen [...] invariants?\n```\nThis is useful if you do not recall the exact syntax to construct invariants.\nFurthermore, it will suggest a concrete invariant encoding \"this holds at the start of the loop and\nthis must hold at the end of the loop\" by looking at the corresponding VCs.\nAlthough the suggested invariant is a good starting point, it is too strong and requires users to\ninterpolate it such that the inductive step can be proved. Example:\n```\ndef mySum (l : List Nat) : Nat := Id.run do\n  let mut acc := 0\n  for x in l do\n    acc := acc + x\n  return acc\n\n/--\ninfo: Try this:\n  invariants\n    · ⇓⟨xs, letMuts⟩ =&gt; ⌜xs.prefix = [] ∧ letMuts = 0 ∨ xs.suffix = [] ∧ letMuts = l.sum⌝\n-/\n#guard_msgs (info) in\ntheorem mySum_suggest_invariant (l : List Nat) : mySum l = l.sum := by\n  generalize h : mySum l = r\n  apply Id.of_wp_run_eq h\n  mvcgen invariants?\n  all_goals admit\n```\n</code>"}