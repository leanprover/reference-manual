window.docContents[1].resolve({"/Axioms/#standard-axioms":{"contents":"There are seven standard axioms in Lean. The first three axioms are important parts of how mathematics is done in Lean:\n\n* Classical.choice.{u} {α : Sort u} : Nonempty α → α\n* propext {a b : Prop} : (a ↔ b) → a = b\n* Quot.sound.{u} {α : Sort u}\n  {r : α → α → Prop} {a b : α} :\n  r a b → Quot.mk r a = Quot.mk r b\n\n\nAll three of these axioms are discussed in the book Theorem Proving in Lean.\n\nThe axiom sorryAx is used as part of the implementation of the sorry tactic and sorry term.\nUses of this axiom are not intended to occur in finished proofs, as it can be used to prove anything:\n\n* sorryAx {α : Sort u} (synthetic := true) : α\n\n\nThree final axioms do not truly exist for their mathematical content; from a mathematical perspective they prove trivial statements:\n\n*  Lean.trustCompiler : True\n*  Lean.ofReduceBool (a b : Bool) : Lean.reduceBool a = b → a = b\n*  Lean.ofReduceNat (a b : Nat) : Lean.reduceNat a = b → a = b\n\n\nThese axioms instead track proofs that depend on the correctness of the entire compiler, and not just on the much smaller kernel.\n\nCreating and Tracking Proofs That Trust the CompilerThe functions Lean.reduceBool and Lean.reduceNat can be invoked to have the compiler perform a calculation; this can greatly improve performance of implementations of proof by reflection.def largeNumber : Nat := Lean.reduceNat (230_000 + 4_500 + 1_000_067)\nThe resulting term depends on the axiom Lean.trustCompiler in order to track the fact that this calculation depends on the correctness of the compiler.#print axioms largeNumber\n'largeNumber' depends on axioms: [Lean.trustCompiler]\nThe most common way that proofs end up trusting the compiler is through the native_decide tactic:def bigSum : (List.range 1_001).sum = 500_500 := by native_decide\n#print axioms bigSum\n'bigSum' depends on axioms: [Lean.ofReduceBool, Lean.trustCompiler]\n\n\n","context":"Lean Reference\u0009Axioms","header":"8.4. Standard Axioms","id":"/Axioms/#standard-axioms"},"/Basic-Types/Strings/#The-Lean-Language-Reference--Basic-Types--Strings--Logical-Model--Backwards-Compatibility":{"contents":"In prior versions of Lean, the logical model of strings was a structure that contained a list of characters.\nThis model is still useful.\nIt is still accessible using String.ofList, which converts a list of characters into a String, and String.toList, which converts a String into a list of characters.\n\nCreates a string that contains the characters in a list, in order.Examples:* ['L', '∃', '∀', 'N'].asString = \"L∃∀N\"* [].asString = \"\"* ['a', 'a', 'a'].asString = \"aaa\"\n\nConverts a string to a list of characters.Since strings are represented as dynamic arrays of bytes containing the string encoded using\nUTF-8, this operation takes time and space linear in the length of the string.Examples:* \"abc\".toList = ['a', 'b', 'c']* \"\".toList = []* \"\\n\".toList = ['\\n']\n\n","context":"Lean Reference\u0009Basic Types\u0009Strings\u0009Logical Model","header":"20.8.1.1. Backwards Compatibility","id":"/Basic-Types/Strings/#The-Lean-Language-Reference--Basic-Types--Strings--Logical-Model--Backwards-Compatibility"},"/Basic-Types/The-Unit-Type/#The-Lean-Language-Reference--Basic-Types--The-Unit-Type":{"contents":"The unit type is the canonical type with exactly one element, named unit and represented by the empty tuple ().\nIt describes only a single value, which consists of said constructor applied to no arguments whatsoever.\n\nUnit is analogous to void in languages derived from C: even though void has no elements that can be named, it represents the return of control flow from a function with no additional information.\nIn functional programming, Unit is the return type of things that \"return nothing\".\nMathematically, this is represented by a single completely uninformative value, as opposed to an empty type such as Empty, which represents unreachable code.\n\nWhen programming with monads, Unit is especially useful.\nFor any type α, m α represents an action that has side effects and returns a value of type α.\nThe type m Unit represents an action that has some side effects but does not return a value.\n\nThere are two variants of the unit type:\n\n* Unit is a Type that exists in the smallest non-propositional universe.* PUnit is universe polymorphic and can be used in any non-propositional universe.\n\nBehind the scenes, Unit is actually defined as PUnit.{1}.\nUnit should be preferred over PUnit when possible to avoid unnecessary universe parameters.\nIf in doubt, use Unit until universe errors occur.\n\nThe canonical type with one element. This element is written ().Unit has a number of uses:* It can be used to model control flow that returns from a function call without providing other\ninformation.* Monadic actions that return Unit have side effects without computing values.* In polymorphic types, it can be used to indicate that no data is to be stored in a particular\nfield.\n\nThe only element of the unit type.It can be written as an empty tuple: ().\n\nThe canonical universe-polymorphic type with just one element.It should be used in contexts that require a type to be universe polymorphic, thus disallowing\nUnit.The only element of the universe-polymorphic unit type.\n\n\n\n","context":"Lean Reference\u0009Basic Types","header":"20.9. The Unit Type","id":"/Basic-Types/The-Unit-Type/#The-Lean-Language-Reference--Basic-Types--The-Unit-Type"},"/Definitions/Headers-and-Signatures/#bracketed-parameter-syntax":{"contents":"Parameters other than identifiers or underscores are collectively referred to as bracketed binders because every syntactic form for specifying them has some kind of brackets, braces, or parentheses.\nAll bracketed binders specify the type of a parameter, and most include parameter names.\nThe name is optional for instance implicit parameters.\nUsing an underscore (_) instead of a parameter name indicates an anonymous parameter.\n\nExplicit ParametersParenthesized parameters indicate explicit parameters.\nIf more than one identifier or underscore is provided, then all of them become parameters with the same type.\n\nOptional and Automatic ParametersParenthesized parameters with a := assign default values to parameters.\nParameters with default values are called optional parameters.\nAt a call site, if the parameter is not provided, then the provided term is used to fill it in.\nPrior parameters in the signature are in scope for the default value, and their values at the call site are substituted into the default value term.If a tactic script is provided, then the tactics are executed at the call site to synthesize a parameter value; parameters that are filled in via tactics are called automatic parameters.\n\nImplicit ParametersParameters in curly braces indicate implicit parameters.\nUnless provided by name at a call site, these parameters are expected to be synthesized via unification at call sites.\nImplicit parameters are synthesized at all call sites.\n\nStrict Implicit ParametersParameters in double curly braces indicate strict implicit parameters.\n⦃ … ⦄ and {{ … }} are equivalent.\nLike implicit parameters, these parameters are expected to be synthesized via unification at call sites when they are not provided by name.\nStrict implicit parameters are only synthesized at call sites when subsequent parameters in the signature are also provided.\n\nInstance Implicit ParametersParameters in square brackets indicate instance implicit parameters, which are synthesized at call sites using instance synthesis.\n\nThe parameters are always in scope in the signature's type, which occurs after the colon.\nThey are also in scope in the declaration's body, while names bound in the type itself are only in scope in the type.\nThus, parameter names are used twice:\n\n* As names in the declaration's function type, bound as part of a dependent function type.* As names in the declaration's body.\n   In function definitions, they are bound by a fun.\n\nParameter ScopeThe signature of add contains one parameter, n.\nAdditionally, the signature's type is (k : Nat) → Nat, which is a function type that includes k.\nThe parameter n is in scope in the function's body, but k is not.def add (n : Nat) : (k : Nat) → Nat\n  | 0 => n\n  | k' + 1 => 1 + add n k'\nLike add, the signature of mustBeEqual contains one parameter, n.\nIt is in scope both in the type, where it occurs in a proposition, and in the body, where it occurs as part of the message.def mustBeEqual (n : Nat) : (k : Nat) → n = k → String :=\n  fun _ =>\n    fun\n    | rfl => s!\"Equal - both are {n}!\"\n\n\n\nThe section on function application describes the interpretation of optional, automatic, implicit, and instance implicit parameters in detail.\n\n","context":"Lean Reference\u0009Definitions\u0009Headers and Signatures","header":"7.2.3. Bracketed Parameter Bindings","id":"/Definitions/Headers-and-Signatures/#bracketed-parameter-syntax"},"/Error-Explanations/lean___dependsOnNoncomputable/#The-Lean-Language-Reference--Error-Explanations--lean___dependsOnNoncomputable":{"contents":"\n\nThis error indicates that the specified definition depends on one or more definitions that do not\ncontain executable code and is therefore required to be marked as noncomputable. Such definitions\ncan be type-checked but do not contain code that can be executed by Lean.\n\nIf you intended for the definition named in the error message to be noncomputable, marking it as\nnoncomputable will resolve this error. If you did not, inspect the noncomputable definitions on\nwhich it depends: they may be noncomputable because they failed to compile, are axioms, or were\nthemselves marked as noncomputable. Making all of your definition's noncomputable dependencies\ncomputable will also resolve this error. See the manual section on\nModifiers for more information about noncomputable\ndefinitions.\n\n\n\n","context":"Lean Reference\u0009Error Explanations","header":"lean.dependsOnNoncomputable","id":"/Error-Explanations/lean___dependsOnNoncomputable/#The-Lean-Language-Reference--Error-Explanations--lean___dependsOnNoncomputable"},"/Notations-and-Macros/Defining-New-Syntax/#syntax-indentation":{"contents":"Internally, the parser maintains a saved source position.\nSyntax rules may include instructions that interact with these saved positions, causing parsing to fail when a condition is not met.\nIndentation-sensitive constructs, such as do, save a source position, parse their constituent parts while taking this saved position into account, and then restore the original position.\n\nIn particular, Indentation-sensitvity is specified by combining withPosition or withPositionAfterLinebreak, which save the source position at the start of parsing some other syntax, with colGt, colGe, and colEq, which compare the current column with the column from the most recently-saved position.\nlineEq can also be used to ensure that two positions are on the same line in the source file.\n\nwithPosition(p) runs p while setting the \"saved position\" to the current position.\nThis has no effect on its own, but various other parsers access this position to achieve some\ncomposite effect:* colGt, colGe, colEq compare the column of the saved position to the current position,\nused to implement Python-style indentation sensitive blocks* lineEq ensures that the current position is still on the same line as the saved position,\nused to implement composite tokensThe saved position is only available in the read-only state, which is why this is a scoping parser:\nafter the withPosition(..) block the saved position will be restored to its original value.This parser has the same arity as p - it just forwards the results of p.\n\nwithoutPosition(p) runs p without the saved position, meaning that position-checking\nparsers like colGt will have no effect. This is usually used by bracketing constructs like\n(...) so that the user can locally override whitespace sensitivity.This parser has the same arity as p - it just forwards the results of p.\n\n\n\nThe colGt parser requires that the next token starts a strictly greater column than the saved\nposition (see withPosition). This can be used for whitespace sensitive syntax for the arguments\nto a tactic, to ensure that the following tactic is not interpreted as an argument.example (x : False) : False := by\n  revert x\n  exact id\nHere, the revert tactic is followed by a list of colGt ident, because otherwise it would\ninterpret exact as an identifier and try to revert a variable named exact.This parser has arity 0 - it does not capture anything.\n\nThe colGe parser requires that the next token starts from at least the column of the saved\nposition (see withPosition), but allows it to be more indented.\nThis can be used for whitespace sensitive syntax to ensure that a block does not go outside a\ncertain indentation scope. For example it is used in the lean grammar for else if, to ensure\nthat the else is not less indented than the if it matches with.This parser has arity 0 - it does not capture anything.\n\nThe colEq parser ensures that the next token starts at exactly the column of the saved\nposition (see withPosition). This can be used to do whitespace sensitive syntax like\na by block or do block, where all the lines have to line up.This parser has arity 0 - it does not capture anything.\n\nThe lineEq parser requires that the current token is on the same line as the saved position\n(see withPosition). This can be used to ensure that composite tokens are not \"broken up\" across\ndifferent lines. For example, else if is parsed using lineEq to ensure that the two tokens\nare on the same line.This parser has arity 0 - it does not capture anything.\n\nAligned ColumnsThis syntax for saving notes takes a bulleted list of items, each of which must be aligned at the same column.syntax \"note \" ppLine withPosition((colEq \"◦ \" str ppLine)+) : term\nThere is no elaborator or macro associated with this syntax, but the following example is accepted by the parser:#check\n  note\n    ◦ \"One\"\n    ◦ \"Two\"\nelaboration function for `«termNote__◦__»` has not been implemented\n  note\n    ◦ \"One\"\n    ◦ \"Two\"\n\nThe syntax does not require that the list is indented with respect to the opening token, which would require an extra withPosition and a colGt.#check\n  note\n◦ \"One\"\n◦ \"Two\"\nelaboration function for `«termNote__◦__»` has not been implemented\n  note\n    ◦ \"One\"\n    ◦ \"Two\"\n\nThe following examples are not syntactically valid because the columns of the bullet points do not match.#check\n  note\n    ◦ \"One\"\n   ◦ \"Two\"\n<example>:4:3-4:4: expected end of input\n#check\n  note\n   ◦ \"One\"\n     ◦ \"Two\"\n<example>:4:5-4:6: expected end of input\n\n\n","context":"Lean Reference\u0009Notations and Macros\u0009Defining New Syntax","header":"22.4.12. Indentation","id":"/Notations-and-Macros/Defining-New-Syntax/#syntax-indentation"},"/The--grind--tactic/Algebraic-Solver-_LPAR_Commutative-Rings___-Fields_RPAR_/#The-Lean-Language-Reference--The--grind--tactic--Algebraic-Solver-_LPAR_Commutative-Rings___-Fields_RPAR_--Solver-Type-Classes--Algebraic-Structures":{"contents":"To enable the algebraic solver, a type should have an instance of the most specific possible algebraic structure that the solver supports.\nIn order of increasing specificity, that is Semiring, Ring, CommSemiring, CommRing, and Field.\n\nA semiring, i.e. a type equipped with addition, multiplication, and a map from the natural numbers,\nsatisfying appropriate compatibilities.Use Ring instead if the type also has negation,\nCommSemiring if the multiplication is commutative,\nor CommRing if the type has negation and multiplication is commutative.In every semiring there is a canonical map from the natural numbers to the semiring,\nproviding the values of 0 and 1. Note that this function need not be injective.Natural number numerals in the semiring.\nThe field ofNat_eq_natCast ensures that these are (propositionally) equal to the values of natCast.Scalar multiplication by natural numbers.Exponentiation by a natural number.Zero is the right identity for addition.Addition is commutative.Addition is associative.Multiplication is associative.One is the right identity for multiplication.One is the left identity for multiplication.Left distributivity of multiplication over addition.Right distributivity of multiplication over addition.Zero is right absorbing for multiplication.Zero is left absorbing for multiplication.The zeroth power of any element is one.The successor power law for exponentiation.Numerals are consistently defined with respect to addition.Numerals are consistently defined with respect to the canonical map from natural numbers.\n\nA commutative semiring, i.e. a semiring with commutative multiplication.Use CommRing if the type has negation.Multiplication is commutative.\n\nA ring, i.e. a type equipped with addition, negation, multiplication, and a map from the integers,\nsatisfying appropriate compatibilities.Use CommRing if the multiplication is commutative.In every ring there is a canonical map from the integers to the ring.Scalar multiplication by integers.Negation is the left inverse of addition.Subtraction is addition of the negative.Scalar multiplication by the negation of an integer is the negation of scalar multiplication by that integer.Scalar multiplication by natural numbers is consistent with scalar multiplication by integers.The canonical map from the integers is consistent with the canonical map from the natural numbers.The canonical map from the integers is consistent with negation.\n\nA commutative ring, i.e. a ring with commutative multiplication.Multiplication is commutative.\n\n\n\n","context":"Lean Reference\u0009The  grind  tactic\u0009Algebraic Solver (Commutative Rings, Fields)\u0009Solver Type Classes","header":"17.8.1.1. Algebraic Structures","id":"/The--grind--tactic/Algebraic-Solver-_LPAR_Commutative-Rings___-Fields_RPAR_/#The-Lean-Language-Reference--The--grind--tactic--Algebraic-Solver-_LPAR_Commutative-Rings___-Fields_RPAR_--Solver-Type-Classes--Algebraic-Structures"},"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Language--CutSat":{"contents":"* #7312 implements proof term generation for cooper_dvd_left and its\nvariants in the cutsat procedure for linear integer arithmetic.* #7315 implements the Cooper conflict resolution in cutsat. We still\nneed to implement the backtracking and disequality case.* #7339 implements cooper conflict resolution in the cutsat procedure.\nIt also fixes several bugs in the proof term construction. We still need\nto add more tests, but we can already solve the following example that\nomega fails to solve:example (x y : Int) :\n    27 ≤ 11*x + 13*y →\n    11*x + 13*y ≤ 45 →\n    -10 ≤ 7*x - 9*y →\n    7*x - 9*y ≤ 4 → False := by\n  grind\n* #7351 ensures cutsat does not have to perform case analysis in the\nunivariate polynomial case. That it, it can close a goal whenever there\nis no solution for a divisibility constraint in an interval. Example of\ntheorem that is now proved in a single step by cutsat:example (x : Int) : 100 ≤ x → x ≤ 10000 → 20000 ∣ 3*x → False := by\n  grind\n* #7357 adds support for / and % to the cutsat procedure.* #7369 uses let-declarations for each polynomial occurring in a proof\nterm generated by the cutsat procedure.* #7370 simplifies the proof term due to the Cooper's conflict\nresolution in cutsat.* #7373 implements the last missing case for the cutsat procedure and\nfixes a bug. During model construction, we may encounter a bounded\ninterval containing integer solutions that satisfy the divisibility\nconstraint but fail to satisfy known disequalities.* #7394 adds infrastructure necessary for supporting Nat in the cutsat\nprocedure. It also makes the grind more robust.* #7396 fixes a bug in the cutsat model construction. It was searching\nfor a solution in the wrong direction.* #7401 improves the cutsat model search procedure by tightening\ninequalities using divisibility constraints.* #7494 implements support for Nat inequalities in the cutsat\nprocedure.* #7495 implements support for Nat divisibility constraints in the\ncutsat procedure.* #7501 implements support for Nat equalities and disequalities in the\ncutsat procedure.* #7502 implements support for Nat div and mod in the cutsat\nprocedure.* #7503 implements support for Nat.sub in cutsat* #7536 implements support for ¬ d ∣ p in the cutsat procedure.* #7537 implements support for Int.natAbs and Int.toNat in the\ncutsat procedure.* #7538 fixes a bug in the cutsat model construction. It was not\nresetting the decision stack at the end of the search.* #7561 fixes the support for nonlinear Nat terms in cutsat. For\nexample, cutsat was failing in the following exampleexample (i j k l : Nat) : i / j + k + l - k = i / j + l := by grind\nbecause we were not adding the fact that i / j is non negative when we\ninject the Nat expression into Int.* #7579 improves the counterexamples produced by the cutsat procedure,\nand adds proper support for Nat. Before this PR, the assignment for an\nnatural variable x would be represented as NatCast.natCast x.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.19.0 (2025-05-01)\u0009Language","header":"CutSat","id":"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Language--CutSat"},"/releases/v4.26.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___26___0-_LPAR_2025-12-13_RPAR_--Library":{"contents":"* #9515 adds a missing lemma for the List API.* #10739 adds two missing NeZero instances for n^0 where n : Nat\nand n : Int.* #10743 renames theorems that use sorted in their name to instead use\npairwise.* #10765 extends the all/any functions from hash sets to hash maps\nand dependent hash maps and verifies them.* #10769 adds a find? consumer in analogy to List.find? and variants\nthereof.* #10776 adds iterators and slices for DTreeMap/TreeMap/TreeSet\nbased on zippers and provides basic lemmas about them.* #10820 shows that the iterators returned by String.Slice.split and\nString.Slice.splitInclusive are finite as long as the forward matcher\niterator for the pattern is finite (which we already know for all of our\npatterns).* #10852 renames String.Range to Lean.Syntax.Range, to reflect that\nit is not part of the standard library.* #10853 renames String.endPos to String.rawEndPos, as in a future\nrelease the name String.endPos will be taken by the function that is\ncurrently called String.endValidPos.* #10854 fixes the IPv4 address encoding from libuv to lean* #10865 makes the spec Std.Do.Spec.forIn'_list and friends more\nuniverse polymorphic.* #10896 adds union operations on DTreeMap/TreeMap/TreeSet and their raw\nvariants and provides lemmas about union operations.* #10933 adds the basic infrastructure to perform termination proofs\nabout String.ValidPos and String.Slice.Pos.* #10941 removes a redundant instance requirement from\nStd.instIrreflLtOfIsPreorderOfLawfulOrderLT.* #10946 adds union operation on ExtDHashMap/ExtHashMap/ExtHashSet nd\nprovides lemmas about union operations.* #10952 replaces Iter(M).size with the Iter(M).count. While the\nformer used a special IteratorSize type class, the latter relies on\nIteratorLoop. The IteratorSize class is deprecated. The PR also\nrenames lemmas about ranges be replacing _Rcc with _rcc, _Rco with\n_roo (and so on) in names, in order to be more consistent with the\nnaming convention.* #10966 fixes some mis-stated lemmas which should have been about the\n.Raw variants of maps.* #10986 defines String.Slice.replace and redefines String.replace to\nuse the Slice version.* #10993 allows grind to work extensionally on extensional maps/sets.* #11006 removes the duplicate lemmas\nStd.Do.SPred.{and_pure,or_pure,imp_pure,entails_pure_intro}.* #11008 inlines several Decidable instances for performance reasons.* #11017 establishes String.ofList and String.toList as the preferred\nmethod for converting between strings and lists of characters and\ndeprecates the alternatives String.mk, List.asString and\nString.data.* #11019 introduces slices of lists that are available via slice notation\n(e.g., xs[1...5]).* #11021 adds more theory about Splits for strings and deduces the\nfirst user-facing String lemma, String.toList_map.* #11058 changes Nat.ble by joining the two Nat.ble Nat.zero _ cases\ninto one, allowing decide (0 <= x) = true and decide (0 < succ x) = true to be solvable by rfl.* #11060 add list min and max operations to complement min? and\nmax? ones in the same vain as head? and head.* #11070 adds union operation on ExtDHashMap/ExtHashMap/ExtHashSet nd\nprovides lemmas about union operations.* #11076 adds getEntry/getEntry?/getEntry!/getEntryD operation on\nDHashMap.* #11100 adds theorem Int.ediv_pow {a b : Int} {n : Nat} (hab : b ∣ a) : (a / b) ^ n = a ^ n / b ^ n and related lemmas.* #11102 adds some annotations missing in the Array bootstrapping files.* #11113 adds some small missing lemmas.* #11123 adds theorems about folds over flatMaps, for\nList/Array/Vector.* #11127 removes all uses of String.Iterator from core, preferring\nString.ValidPos instead.* #11138 adds a csimp lemma for faster runtime evaluation of Int.pow\nin terms of Nat.pow.* #11139 replaces #11138, which just added a @[csimp] lemma for\nInt.pow, this time actually replacing the definition. This means we\nnot only get fast runtime behaviour, but take advantage of the special\nkernel support for Nat.pow.* #11150 adds a new, inactive and unused doElem_elab attribute that\nwill allow users to register custom elaborators for doElems in the\nform of the new type DoElab. The old do elaborator is active by\ndefault but can be switched off by disabling the new option\nbackward.do.legacy.* #11152 renames String.Iterator to String.Legacy.Iterator.* #11154 renames Substring  to Substring.Raw.* #11159 adds lemmas about the sizes of ranges of Ints, analogous to the\nNat lemmas in Init.Data.Range.Polymorphic.NatLemmas. See also\nhttps://leanprover.zulipchat.com/#narrow/channel/270676-lean4/topic/Reasonning.20about.20PRange.20sizes.20.28with.20.60Int.60.29/with/546466339.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.26.0 (2025-12-13)","header":"Library","id":"/releases/v4.26.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___26___0-_LPAR_2025-12-13_RPAR_--Library"}});