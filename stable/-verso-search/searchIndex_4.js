window.docContents[4].resolve({"/Basic-Types/Bitvectors/#The-Lean-Language-Reference--Basic-Types--Bitvectors--Logical-Model":{"contents":"Bitvectors are represented as a wrapper around a Fin with a suitable bound.\nBecause Fin itself is a wrapper around a Nat, bitvectors are able to use the kernel's special support for efficient computation with natural numbers.\n\nA bitvector of the specified width.This is represented as the underlying Nat number in both the runtime\nand the kernel, inheriting all the special support for Nat.Construct a BitVec w from a number less than 2^w.\nO(1), because we use Fin as the internal representation of a bitvector.Interpret a bitvector as a number less than 2^w.\nO(1), because we use Fin as the internal representation of a bitvector.\n\n","context":"Lean Reference\u0009Basic Types\u0009Bitvectors","header":"20.5.1. Logical Model","id":"/Basic-Types/Bitvectors/#The-Lean-Language-Reference--Basic-Types--Bitvectors--Logical-Model"},"/Build-Tools-and-Distribution/Managing-Toolchains-with-Elan/#elan":{"contents":"Elan is the Lean toolchain manager.\nIt is responsible both for installing toolchains and for running their constituent programs.\nElan makes it possible to seamlessly work on a variety of projects, each of which is designed to be built with a particular version of Lean, without having to manually install and select toolchain versions.\nEach project is typically configured to use a particular version, which is transparently installed as needed, and changes to the Lean version are tracked automatically.\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Build Tools","header":"24.2. Managing Toolchains with Elan","id":"/Build-Tools-and-Distribution/Managing-Toolchains-with-Elan/#elan"},"/Definitions/Recursive-Definitions/#well-founded-preprocessing":{"contents":"Lean preprocesses the function's body before determining the proof obligations at each call site, transforming it into an equivalent definition that may include additional information.\nThis preprocessing step is primarily used to enrich the local context with additional assumptions that may be necessary in order to solve the termination proof obligations, freeing users from the need to perform equivalent transformations by hand.\nPreprocessing uses the simplifier and is extensible by the user.\n\nThe preprocessing happens in three steps:1. Lean annotates occurrences of a function's parameter, or a subterm of a parameter, with the wfParam gadget.wfParam {α} (a : α) : α\nMore precisely, every occurrence of the function's parameters is wrapped in wfParam.\n    Whenever a match expression has any discriminant wrapped in wfParam, the gadget is removed and every occurrence of a pattern match variable (regardless of whether it comes from the discriminant with the wfParam gadget) is wrapped in wfParam.\n    The wfParam gadget is additionally floated out of projection function applications.2. The annotated function body is simplified using the simplifier, using only simplification rules from the wf_preprocess custom simp set.3. Finally, any left-over wfParam markers are removed.Annotating function parameters that are used for well-founded recursion allows the preprocessing simplification rules to distinguish between parameters and other terms.\n\nPreprocessing Simp Set for Well-Founded RecursionTheorems tagged with the wf_preprocess attribute are used during the processing of functions defined\nby well-founded recursion. They are applied to the function's body to add additional hypotheses,\nsuch as replacing if c then _ else _ with if h : c then _ else _ or xs.map with\nxs.attach.map. Also see wfParam.Warning: These rewrites are only applied to the declaration for the purpose of the logical\ndefinition, but do not affect the compiled code. In particular they can cause a function definition\nthat diverges as compiled to be accepted without an explicit partial keyword, for example if they\nremove irrelevant subterms or change the evaluation order by hiding terms under binders. Therefore\navoid tagging theorems with [wf_preprocess] unless they preserve also operational behavior.\n\nThe wfParam gadget is used internally during the construction of recursive functions by\nwellfounded recursion, to keep track of the parameter for which the automatic introduction\nof List.attach (or similar) is plausible.\n\nSome rewrite rules in the wf_preprocess simp set apply generally, without heeding the wfParam marker.\nIn particular, the theorem ite_eq_dite is used to extend the context of an if-then-else expression branch with an assumption about the condition:This assumption's name should be an inaccessible name based on h, as is indicated by using binderNameHint with the term (). Binder name hints are described in the tactic language reference.\n\nite_eq_dite {P : Prop} {α : Sort u} {a b : α} [Decidable P]  :\n  (if P then a else b) =\n  if h : P then\n    binderNameHint h () a\n  else\n    binderNameHint h () b\n\n\n\n\nOther rewrite rules use the wfParam marker to restrict their applicability; they are used only when a function (like List.map) is applied to a parameter or subterm of a parameter, but not otherwise.\nThis is typically done in two steps:1. A theorem such as List.map_wfParam recognizes a call of List.map on a function parameter (or subterm), and uses List.attach to enrich the type of the list elements with the assertion that they are indeed elements of that list:List.map_wfParam (xs : List α) (f : α → β) :\n  (wfParam xs).map f = xs.attach.unattach.map f\n2. A theorem such as List.map_unattach makes that assertion available to the function parameter of List.map.List.map_unattach (P : α → Prop)\n  (xs : List { x : α // P x }) (f : α → β) :\n  xs.unattach.map f = xs.map fun ⟨x, h⟩ =>\n    binderNameHint x f <|\n    binderNameHint h () <|\n    f (wfParam x)\nThis theorem uses the binderNameHint gadget to preserve a user-chosen binder name, should f be a lambda expression.By separating the introduction of List.attach from the propagation of the introduced assumption, the desired the x ∈ xs assumption is made available to f even in chains such as (xs.reverse.filter p).map f.\n\n\n\nThis preprocessing can be disabled by setting the option wf.preprocess to false.\nTo see the preprocessed function definition, before and after the removal of wfParam markers, set the option trace.Elab.definition.wf to true.\n\nenable/disable tracing for the given module and submodules\n\nPreprocessing for a custom data typeThis example demonstrates what is necessary to enable automatic well-founded recursion for a custom container type.\nThe structure type Pair is a homogeneous pair: it contains precisely two elements, both of which have the same type.\nIt can be thought of as being similar to a list or array that always contains precisely two elements.As a container, Pair can support a map operation.\nTo support well-founded recursion in which recursive calls occur in the body of a function being mapped over a Pair, some additional definitions are required, including a membership predicate, a theorem that relates the size of a member to the size of the containing pair, helpers to introduce and eliminate assumptions about membership, wf_preprocess rules to insert these helpers, and an extension to the decreasing_trivial tactic.\nEach of these steps makes it easier to work with Pair, but none are strictly necessary; there's no need to immediately implement all steps for every type./-- A homogeneous pair -/\nstructure Pair (α : Type u) where\n  fst : α\n  snd : α\n\n/-- Mapping a function over the elements of a pair -/\ndef Pair.map (f : α → β) (p : Pair α) : Pair β where\n  fst := f p.fst\n  snd := f p.snd\nDefining a nested inductive data type of binary trees that uses Pair and attempting to define its map function demonstrates the need for preprocessing rules./-- A binary tree defined using `Pair` -/\ninductive Tree (α : Type u) where\n  | leaf : α → Tree α\n  | node : Pair (Tree α) → Tree α\nA straightforward definition of the map function fails:def Tree.map (f : α → β) : Tree α → Tree β\n  | leaf x => leaf (f x)\n  | node p => node (p.map (fun t' => t'.map f))\ntermination_by t => t\nfailed to prove termination, possible solutions:\n  - Use `have`-expressions to prove the remaining goals\n  - Use `termination_by` to specify a different well-founded relation\n  - Use `decreasing_by` to specify your own tactic for discharging this kind of goal\nα : Type u_1\np : Pair (Tree α)\nt' : Tree α\n⊢ sizeOf t' < 1 + sizeOf p\nClearly the proof obligation is not solvable, because nothing connects t' to p.The standard idiom to enable this kind of function definition is to have a function that enriches each element of a collection with a proof that they are, in fact, elements of the collection.\nStating this property requires a membership predicate.inductive Pair.Mem (p : Pair α) : α → Prop where\n  | fst : Mem p p.fst\n  | snd : Mem p p.snd\n\ninstance : Membership α (Pair α) where\n  mem := Pair.Mem\nEvery inductive type automatically has a SizeOf instance.\nAn element of a collection should be smaller than the collection, but this fact must be proved before it can be used to construct a termination proof:theorem Pair.sizeOf_lt_of_mem {α} [SizeOf α]\n    {p : Pair α} {x : α} (h : x ∈ p) :\n    sizeOf x < sizeOf p := by\n  cases h <;> cases p <;> (simp; omega)\nThe next step is to define attach and unattach functions that enrich the elements of the pair with a proof that they are elements of the pair, or remove said proof.\nHere, the type of Pair.unattach is more general and can be used with any subtype; this is a typical pattern.def Pair.attach (p : Pair α) : Pair {x : α // x ∈ p} where\n  fst := ⟨p.fst, .fst⟩\n  snd := ⟨p.snd, .snd⟩\n\ndef Pair.unattach {P : α → Prop} :\n    Pair {x : α // P x} → Pair α :=\n  Pair.map Subtype.val\nTree.map can now be defined by using Pair.attach and Pair.sizeOf_lt_of_mem explicitly:def Tree.map (f : α → β) : Tree α → Tree β\n  | leaf x => leaf (f x)\n  | node p => node (p.attach.map (fun ⟨t', _⟩ => t'.map f))\ntermination_by t => t\ndecreasing_by\n  have := Pair.sizeOf_lt_of_mem ‹_›\n  simp_all +arith\n  omega\nThis transformation can be made fully automatic.\nThe preprocessing feature of well-founded recursion can be used to automate the introduction of the Pair.attach function.\nThis is done in two stages.\nFirst, when Pair.map is applied to one of the function's parameters, it is rewritten to an attach/unattach composition.\nThen, when a function is mapped over the result of Pair.unattach, the function is rewritten to accept the proof of membership and bring it into scope.@[wf_preprocess]\ntheorem Pair.map_wfParam (f : α → β) (p : Pair α) :\n    (wfParam p).map f = p.attach.unattach.map f := by\n  cases p\n  simp [wfParam, Pair.attach, Pair.unattach, Pair.map]\n\n@[wf_preprocess]\ntheorem Pair.map_unattach {P : α → Prop}\n    (p : Pair (Subtype P)) (f : α → β) :\n    p.unattach.map f =\n    p.map fun ⟨x, h⟩ =>\n      binderNameHint x f <|\n      f (wfParam x) := by\n  cases p; simp [wfParam, Pair.unattach, Pair.map]\nNow the function body can be written without extra considerations, and the membership assumption is still available to the termination proof.def Tree.map (f : α → β) : Tree α → Tree β\n  | leaf x => leaf (f x)\n  | node p => node (p.map (fun t' => t'.map f))\ntermination_by t => t\ndecreasing_by\n  have := Pair.sizeOf_lt_of_mem ‹_›\n  simp_all\n  omega\nThe proof can be made fully automatic by adding sizeOf_lt_of_mem to the decreasing_trivial tactic, as is done for similar built-in theorems.macro \"sizeOf_pair_dec\" : tactic =>\n  `(tactic| with_reducible\n    have := Pair.sizeOf_lt_of_mem ‹_›\n    omega\n    done)\n\nmacro_rules\n  | `(tactic| decreasing_trivial) =>\n    `(tactic| sizeOf_pair_dec)\n\ndef Tree.map (f : α → β) : Tree α → Tree β\n  | leaf x => leaf (f x)\n  | node p => node (p.map (fun t' => t'.map f))\ntermination_by t => t\nTo keep the example short, the sizeOf_pair_dec tactic is tailored to this particular recursion pattern and isn't really general enough for a general-purpose container library.\nIt does, however, demonstrate that libraries can be just as convenient in practice as the container types in the standard library.\n\n","context":"Lean Reference\u0009Definitions\u0009Recursive Definitions\u0009Well-Founded Recursion","header":"7.6.3.6. Preprocessing Function Definitions","id":"/Definitions/Recursive-Definitions/#well-founded-preprocessing"},"/Error-Explanations/About___--dependsOnNoncomputable/#The-Lean-Language-Reference--Error-Explanations--About___--dependsOnNoncomputable--Examples":{"contents":"Necessarily Noncomputable Function Not Appropriately Markedaxiom transform : Nat → Nat\n\ndef transformIfZero : Nat → Nat\n  | 0 => transform 0\n  | n => n\n`transform` not supported by code generator; consider marking definition as `noncomputable`\naxiom transform : Nat → Nat\n\nnoncomputable def transformIfZero : Nat → Nat\n  | 0 => transform 0\n  | n => n\nIn this example, transformIfZero depends on the axiom transform. Because transform is an\naxiom, it does not contain any executable code; although the value transform 0 has type Nat,\nthere is no way to compute its value. Thus, transformIfZero must be marked noncomputable because\nits execution would depend on this axiom.\n\nNoncomputable Dependency Can Be Made Computablenoncomputable def getOrDefault [Nonempty α] : Option α → α\n  | some x => x\n  | none => Classical.ofNonempty\n\ndef endsOrDefault (ns : List Nat) : Nat × Nat :=\n  let head := getOrDefault ns.head?\n  let tail := getOrDefault ns.getLast?\n  (head, tail)\nfailed to compile definition, consider marking it as 'noncomputable' because it depends on 'getOrDefault', which is 'noncomputable'\ndef getOrDefault [Inhabited α] : Option α → α\n  | some x => x\n  | none => default\n\ndef endsOrDefault (ns : List Nat) : Nat × Nat :=\n  let head := getOrDefault ns.head?\n  let tail := getOrDefault ns.getLast?\n  (head, tail)\nThe original definition of getOrDefault is noncomputable due to its use of Classical.choice.\nUnlike in the preceding example, however, it is possible to implement a similar but computable\nversion of getOrDefault (using the Inhabited type class), allowing endsOrDefault to be\ncomputable. (The differences between Inhabited and Nonempty are described in the documentation\nof inhabited types in the manual section on Basic Classes.)\n\nNoncomputable Instance in Namespaceopen Classical in\n/--\nReturns `y` if it is in the image of `f`,\nor an element of the image of `f` otherwise.\n-/\ndef fromImage (f : Nat → Nat) (y : Nat) :=\n  if ∃ x, f x = y then\n    y\n  else\n    f 0\nfailed to compile definition, consider marking it as 'noncomputable' because it depends on 'propDecidable', which is 'noncomputable'\nopen Classical in\n/--\nReturns `y` if it is in the image of `f`,\nor an element of the image of `f` otherwise.\n-/\nnoncomputable def fromImage (f : Nat → Nat) (y : Nat) :=\n  if ∃ x, f x = y then\n    y\n  else\n    f 0\nThe Classical namespace contains Decidable instances that are not computable. These are a common\nsource of noncomputable dependencies that do not explicitly appear in the source code of a\ndefinition. In the above example, for instance, a Decidable instance for the proposition\n∃ x, f x = y is synthesized using a Classical decidability instance; therefore, fromImage must\nbe marked noncomputable.\n\n","context":"Lean Reference\u0009Error Explanations\u0009About:  dependsOnNoncomputable","header":"Examples","id":"/Error-Explanations/About___--dependsOnNoncomputable/#The-Lean-Language-Reference--Error-Explanations--About___--dependsOnNoncomputable--Examples"},"/Notations-and-Macros/Extending-Lean___s-Output/#delaborators":{"contents":"A delaborator is function of type Lean.PrettyPrinter.Delaborator.Delab, which is an abbreviation for Lean.PrettyPrinter.Delaborator.DelabM Term.\nUnlike unexpanders, delaborators are not implemented as functions.\nThis is to make it easier to implement them correctly: the monad DelabM tracks the current position in the expression that's being delaborated so the delaboration mechanism can annotate the resulting syntax.Delaborators are registered with the delab attribute.\nAn internal table maps the names of the constructors of Expr (without namespaces) to delaborators.\nAdditionally, the name app.﻿c is consulted to find delaborators for applications of the constant c, and the name mdata.﻿k is consulted to find delaborators for Expr.mdata constructors with a single key k in their metadata.Delaborator RegistrationThe delab attribute registers a delaborator for the indicated constructor or metadata key of Expr.The app_delab  attribute registers a delaborator for applications of the indicated constant after resolving it in the current scope.The monad DelabM is a reader monad that includes access to the current position in the Expr.\nRecursive delaboration is performed by adjusting the reader monad's tracked position, rather than by explicitly passing a subexpression to another function.\nThe most important functions for working with subexpressions in delaborators are in the namespace Lean.PrettyPrinter.Delaborator.SubExp:* getExpr retrieves the current expression for analysis.* withAppFn adjusts the current position to be that of the function in an application.* withAppArg adjusts the current position to be that of the argument in an application* withAppFnArgs decomposes the current expression into a non-application function and its arguments, focusing on each.* withBindingBody descends into the body of a function or function type.Further functions to descend into the remaining constructors of Expr are available.\n\n\n\n","context":"Lean Reference\u0009Notations and Macros\u0009Extending Lean's Output","header":"22.7.2. Delaborators","id":"/Notations-and-Macros/Extending-Lean___s-Output/#delaborators"},"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Library":{"contents":"* #6496 adds short-circuit support to bv_decide to accelerate\nmultiplications with shared coefficients. In particular, a * x = b * x\ncan be extended to a = b v (a * x = b * x). The latter is faster if a = b is true, as a = b may be evaluated without considering the\nmultiplication circuit. On the other hand, we require the multiplication\ncircuit, as a * x = b * x -> a = b is not always true due to two's\ncomplement wrapping.* #7141 generalizes cond to allow the motive to be in Sort u, not\njust Type u.* #7289 adds getKey_beq, getKey_congr and variants to the hashmap\napi.* #7319 continues alignment of lemmas about Int.ediv/fdiv/tdiv,\nincluding adding notes about \"missing\" lemmas that do not apply in one\ncase. Also lemmas about emod/fmod/tmod. There's still more to do.* #7338 adds @[simp] to Int.neg_inj.* #7341 adds an equivalence relation to the hash map with several lemmas\nfor it.* #7356 adds lemmas reducing monadic operations with pure to the\nnon-monadic counterparts.* #7358 fills further gaps in the integer division API, and mostly\nachieves parity between the three variants of integer division. There\nare still some inequality lemmas about tdiv and fdiv that are\nmissing, but as they would have quite awkward statements I'm hoping that\nfor now no one is going to miss them.* #7378 adds lemmas about Int that will be required in #7368.* #7380 moves DHashMap.Raw.foldRev(M) into DHashMap.Raw.Internal.* #7406 makes the instance for Subsingleton (Squash α) work for α : Sort u.* #7418 renames several hash map lemmas (get -> getElem) and uses\nm[k]? instead of get? m k (and also for get! and get).* #7432 adds a consequence of Nat.add_div using a divisibility\nhypothesis.* #7433 makes simp able to simplify basic for loops in monads other\nthan Id.* #7435 reviews the Nat and Int API, making the interfaces more\nconsistent.* #7445 renames Array.mkEmpty to emptyWithCapacity. (Similarly for\nByteArray and FloatArray.)* #7446 prefers using ∅ instead of .empty functions. We may later\nrename .empty functions to avoid the naming clash with\nEmptyCollection, and to better express semantics of functions which\ntake an optional capacity argument.* #7451 renames the member insert_emptyc_eq of the LawfulSingleton\ntype class to insert_empty_eq to conform to the recommended spelling of\n∅ as empty.* #7466 further cleans up simp lemmas for Int.* #7516 changes the order of arguments for List.modify and\nList.insertIdx, making them consistent with Array.* #7522 splits off the required theory about Nat, Fin and BitVec\nfrom #7484.* #7529 upstreams bind_congr from Mathlib and proves that the minimum\nof a sorted list is its head and weakens the antisymmetry condition of\nmin?_eq_some_iff. Instead of requiring an Std.Antisymm instance,\nmin?_eq_some_iff now only expects a proof that the relation is\nantisymmetric on the elements of the list. If the new premise is left\nout, an autoparam will try to derive it from Std.Antisymm, so existing\nusages of the theorem will most likely continue to work.* #7541 corrects names of a number of lemmas, where the incorrect name\nwas identified automatically by a\ntool\nwritten by @Rob23oba.* #7554 adds SMT-LIB operators to detect overflow BitVec.negOverflow,\naccording to the SMTLIB\nstandard,\nand the theorem proving equivalence of such definition with the BitVec\nlibrary functions (negOverflow_eq).* #7558 changes the definition of Nat.div and Nat.mod to use a\nstructurally recursive, fuel-based implementation rather than\nwell-founded recursion. This leads to more predictable reduction behavior\nin the kernel.* #7565 adds BitVec.toInt_sdiv plus a lot of related bitvector theory\naround divisions.* #7614 marks Nat.div and Nat.modCore as irreducible, to recover\nthe behavior from before #7558.* #7672 reviews the implicitness of arguments across List/Array/Vector,\ngenerally trying to make arguments implicit where possible, although\nsometimes correcting propositional arguments which were incorrectly\nimplicit to explicit.* #7687 provides Inhabited, Ord (if missing), TransOrd,\nLawfulEqOrd and LawfulBEqOrd instances for various types, namely\nBool, String, Nat, Int, UIntX, Option, Prod and date/time\ntypes. It also adds a few related theorems, especially about how the\nOrd instance for Int relates to LE and LT.* #7692 upstreams a small number of ordering lemmas for Fin from\nmathlib.* #7700 provides Ord-related instances such as TransOrd for IntX,\nOrdering, BitVec, Array, List and Vector.* #7704 adds lemmas about the modulo operation defined on signed bounded\nintegers.* #7706 performs various cleanup tasks on Init/Data/UInt/* and\nInit/Data/SInt/*.* #7729 replaces assert! with assertBEq to fix issues where asserts\ndidn't trigger the ctest due to being in a separate task. This was\ncaused by panics not being caught in tasks, while IO errors were handled\nby the AsyncTask if we use the block function on them.* #7756 adds lemmas about Nat.gcd (some of which are currently present\nin mathlib).BREAKING CHANGE: While many lemmas were renamed and the lemma with the old signature was simply deprecated, some lemmas were changed without renaming them. They now use the getElem variants instead of get.\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.19.0 (2025-05-01)","header":"Library","id":"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Library"},"/releases/v4.27.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___27___0-_LPAR_2026-01-24_RPAR_--Library":{"contents":"* #8406 adds lemmas of the form getElem_swapIfInBounds* and deprecates\ngetElem_swap'.* #9302 modifies Option.instDecidableEq and Option.decidableEqNone\nso that the latter can be made into a global instance without causing\ndiamonds. It also adds Option.decidableNoneEq.* #10204 changes the interface of the ForIn, ForIn', and ForM\ntype classes to not take a Monad m parameter. This is a breaking change\nfor most downstream instances, which will now need to assume\n[Monad m].* #10945 adds Std.Tricho r, a type class for relations which identifies\nthem as trichotomous. This is preferred to Std.Antisymm (¬ r · ·) in\nall cases (which it is equivalent to).* #11038 introduces a new fixpoint combinator,\nWellFounded.extrinsicFix. A termination proof, if provided at all, can\nbe given extrinsically, i.e., looking at the term from the outside, and\nis only required if one intends to formally verify the behavior of the\nfixpoint. The new combinator is then applied to the iterator API.\nConsumers such as toList or ForIn no longer require a proof that the\nunderlying iterator is finite. If one wants to ensure the termination of\nthem intrinsically, there are strictly terminating variants available\nas, for example, it.ensureTermination.toList instead of it.toList.* #11112 adds intersection operation on DHashMap/HashMap/HashSet\nand provides several lemmas about its behaviour.* #11141 provides a polymorphic ForIn instance for slices and an MPL\nspec lemma for the iteration over slices using for ... in. It also\nprovides a version specialized to Subarray.* #11165 provides intersection on DTreeMap/TreeMap/TreeSetand\nprovides several lemmas about it.* #11178 provides more lemmas about Subarray and ListSlice and it\nalso adds support for subslices of these two types of slices.* #11180 redefines String.take and variants to operate on\nString.Slice. While previously functions returning a substring of the\ninput sometimes returned String and sometimes returned\nSubstring.Raw, they now uniformly return String.Slice.* #11212 adds support for difference operation for\nDHashMap/HashMap/HashSet and proves several lemmas about it.* #11218 renames String.offsetOfPos to String.Pos.Raw.offsetOfPos to\nalign with the other String.Pos.Raw operations.* #11222 implements elabToSyntax for creating scoped syntax s : Syntax for an arbitrary elaborator el : Option Expr -> TermElabM Expr\nsuch that elabTerm s = el.* #11223 adds missing lemmas relating emptyWithCapacity/empty and\ntoList/keys/values for DHashMap/HashMap/HashSet.* #11231 adds several lemmas that relate\ngetMin/getMin?/getMin!/getMinD and insertion to the empty\n(D)TreeMap/TreeSet and their extensional variants.* #11232 deprecates String.toSubstring in favor of\nString.toRawSubstring (cf. #11154).* #11235 registers a node kind for Lean.Parser.Term.elabToSyntax in\norder to support the Lean.Elab.Term.elabToSyntax functionality without\nregistering a dedicated parser for user-accessible syntax.* #11237 fixes the error thrown by UInt64.fromJson? and\nUSize.fromJson? to use the missing s!.* #11240 renames String.ValidPos to String.Pos, String.endValidPos\nto String.endPos and String.startValidPos to String.startPos.* #11241 provides intersection operation for\nExtDHashMap/ExtHashMap/ExtHashSet and proves several lemmas about\nit.* #11242 significantly changes the signature of the ToIterator type\nclass. The obtained iterators' state is no longer dependently typed and\nis an outParam instead of being bundled inside the class. Among other\nbenefits, simp can now rewrite inside of Slice.toList and\nSlice.toArray. The downside is that we lose flexibility. For example,\nthe former combinator-based implementation of Subarray's iterators is\nno longer feasible because the states are dependently typed. Therefore,\nthis PR provides a hand-written iterator for Subarray, which does not\nrequire a dependently typed state and is faster than the previous one.* #11243 adds ofArray to DHashMap/HashMap/HashSet and proves a\nsimp lemma allowing to rewrite ofArray to ofList.* #11250 introduces a function String.split which is based on\nString.Slice.split and therefore supports all pattern types and\nreturns a Std.Iter String.Slice.* #11255 reduces the allocations when using string patterns. In\nparticular\nstartsWith, dropPrefix?, endsWith, dropSuffix? are optimized.* #11263 fixes several memory leaks in the new String API.* #11266 adds BEq instance for DHashMap/HashMap/HashSet and their\nextensional variants and proves lemmas relating it to the equivalence of\nhashmaps/equality of extensional variants.* #11267 renames congruence lemmas for union on\nDHashMap/HashMap/HashSet/DTreeMap/TreeMap/TreeSet to fit the\nconvention of being in the Equiv namespace.* #11276 cleans up the API around String.find and moves it uniformly to\nthe new position types String.ValidPos and String.Slice.Pos* #11281 adds a few deprecations for functions that never existed but\nthat are still helpful for people migrating their code post-#11180.* #11282 adds the alias String.Slice.any for String.Slice.contains.* #11285 adds Std.Slice.Pattern instances for p : Char -> Prop as\nlong as DecidablePred p, to allow things like \"hello\".dropWhile (· = 'h').* #11286 adds a function String.Slice.length, with the following\ndeprecation string: There is no constant-time length function on slices.\nUse s.positions.count instead, or isEmpty if you only need to know\nwhether the slice is empty.* #11289 redefines String.foldl, String.isNat to use their\nString.Slice counterparts.* #11290 renames String.replaceStartEnd to String.slice,\nString.replaceStart to String.sliceFrom, and String.replaceEnd to\nString.sliceTo, and similar for the corresponding functions on\nString.Slice.* #11299 add many @[grind] annotations for Fin, and updates the\ntests.* #11308 redefines front and back on String to go through\nString.Slice and adds the new String functions front?, back?,\npositions, chars, revPositions, revChars, byteIterator,\nrevBytes, lines.* #11316 adds grind_pattern Exists.choose_spec => P.choose.* #11317 adds grind_pattern Subtype.property => self.val.* #11321 provides specialized lemmas about Nat ranges, including simp\nannotations and induction principles for proving properties for all\nranges.* #11327 adds two lemmas to prove a / c < b / c.* #11341 adds a coercion from String to String.Slice.* #11343 renames String.bytes to String.toByteArray.* #11354 adds simple lemmas that show that searching from a position in a\nstring returns something that is at least that position.* #11357 updates the foldr, all, any and contains functions on\nString to be defined in terms of their String.Slice counterparts.* #11358 adds String.Slice.toInt? and variants.* #11376 aims to improve the performance of String.contains,\nString.find, etc. when using patterns of type Char or Char -> Bool\nby moving the needle out of the iterator state and thus working around\nmissing unboxing in the compiler.* #11380 renames String.Slice.Pos.ofSlice to String.Pos.ofToSlice to\nadhere with the (yet-to-be documented) naming convention for mapping\npositions to positions. It then adds several new functions so that for\nevery way to construct a slice from a string and slice, there are now\nfunctions for mapping positions forwards and backwards along this\nconstruction.* #11384 adds the necessary instances for grind to reason about\nString.Pos.Raw, String.Pos and String.Slice.Pos.* #11399 adds support for the difference operation for\nExtDHashMap/ExtHashMap/ExtHashSet and proves several lemmas about\nit.* #11404 adds BEq instance for DTreeMap/TreeMap/TreeSet and their\nextensional variants and proves lemmas relating it to the equivalence of\nhashmaps/equality of extensional variants.* #11407 adds the difference operation on DTreeMap/TreeMap/TreeSet\nand proves several lemmas about it.* #11421 adds decidable equality to DHashMap/HashMap/HashSet and\ntheir extensional variants.* #11439 performs minor maintenance on the String API* #11448 moves the Inhabited instances in constant DTreeMap (and\nrelated) queries, such as Const.get!, where the Inhabited instance\ncan be provided before proving a key.* #11452 adds lemmas stating that if a get operation returns a value,\nthen the queried key must be contained in the collection. These lemmas\nare added for HashMap and TreeMap-based collections, with a similar\nlemma also added for Init.getElem.* #11465 fixes various typos across the codebase in documentation and\ncomments.* #11503 marks Char -> Bool patterns as default instances for string\nsearch. This means that things like \" \".find (·.isWhitespace) can now\nbe elaborated without error.* #11521 fixes a segmentation fault that was triggered when initializing\na new timer and a reset was called at the same time.* #11527 adds decidable equality to DTreeMap/TreeMap/TreeSet and\ntheir extensional variants.* #11528 adds lemmas relating minKey? and min? on the keys list for\nall DTreeMap and other containers derived from it.* #11542 removes @[grind =] from List.countP_eq_length_filter and\nArray.countP_eq_size_filter, as users reported this was problematic.* #11548 adds Lean.ToJson and Lean.FromJson instances for\nString.Slice.* #11565 adds lemmas that relate insert/insertIfNew and toList on\nDTreeMap/DHashMap-derived containers.* #11574 adds a lemma that the cast of a natural number into any ordered\nring is non-negative. We can't annotate this directly for grind, but\nwill probably add this to grind's linarith internals.* #11578 refactors the usage of get operation on\nHashMap/TreeMap/ExtHashMap/ExtTreeMap to getElem instance.* #11591 adds missing lemmas about how ReaderT.run, OptionT.run,\nStateT.run, and ExceptT.run interact with MonadControl operations.* #11596 adds @[suggest_for ℤ] on Int and @[suggest_for ℚ] on\nRat, following the pattern established by @[suggest_for ℕ] on Nat\nin #11554.* #11600 adds a few lemmas about EStateM.run on basic operations.* #11625 adds @[expose] to decidable_of_bool so that\nproofs-by-decide elsewhere that reduce to decidable_of_bool continue\nto reduce.* #11654 updates the grind docstring. It was still mentioning cutsat\nwhich has been renamed to lia. This issue was reported during ItaLean.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.27.0 (2026-01-24)","header":"Library","id":"/releases/v4.27.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___27___0-_LPAR_2026-01-24_RPAR_--Library"}});