window.docContents[75].resolve({"/Definitions/Recursive-Definitions/#inferring-well-founded-recursion":{"contents":"If a recursive function definition does not indicate a termination measure, Lean will attempt to discover one automatically.\nIf neither termination_by nor decreasing_by is provided, Lean will try to infer structural recursion before attempting well-founded recursion.\nIf a decreasing_by clause is present, only well-founded recursion is attempted.\n\nTo infer a suitable termination measure, Lean considers multiple basic termination measures, which are termination measures of type Nat, and then tries all tuples of these measures.\n\nThe basic termination measures considered are:\n\n* all parameters whose type have a non-trivial SizeOf instance* the expression e₂ - e₁ whenever the local context of a recursive call has an assumption of type e₁ < e₂ or e₁ ≤ e₂, where e₁ and e₂ are of type Nat and depend only on the function's parameters. This approach is based on work by .* in a mutual group, an additional basic measure is used to distinguish between recursive calls to other functions in the group and recursive calls to the function being defined (for details, see the section on mutual well-founded recursion)\n\nCandidate measures are basic measures or tuples of basic measures.\nIf any of the candidate measures allow all proof obligations to be discharged by the termination proof tactic (that is, the tactic specified by decreasing_by, or decreasing_trivial if there is no decreasing_by clause), then an arbitrary such candidate measure is selected as the automatic termination measure.\n\nA termination_by? clause causes the inferred termination annotation to be shown.\nIt can be automatically added to the source file using the offered suggestion or code action.\n\nTo avoid the combinatorial explosion of trying all tuples of measures, Lean first tabulates all basic termination measures, determining whether the basic measure is decreasing, strictly decreasing, or non-decreasing.\nA decreasing measure is smaller for at least one recursive call and never increases at any recursive call, while a strictly decreasing measure is smaller at all recursive calls.\nA non-decreasing measure is one that the termination tactic could not show to be decreasing or strictly decreasing.\nA suitable tuple is chosen based on the table.This approach is based on .\nThis table shows up in the error message when no automatic measure could be found.\n\nTermination failureIf there is no termination_by clause, Lean attempts to infer a measure for well-founded recursion.\nIf it fails, then it prints the table mentioned above.\nIn this example, the decreasing_by clause simply prevents Lean from also attempting structural recursion; this keeps the error message specific.def f : (n m l : Nat) → Nat\n  | n+1, m+1, l+1 => [\n      f (n+1) (m+1) (l+1),\n      f (n+1) (m-1) (l),\n      f (n)   (m+1) (l) ].sum\n  | _, _, _ => 0\ndecreasing_by all_goals decreasing_tactic\nCould not find a decreasing measure.\nThe basic measures relate at each recursive call as follows:\n(<, ≤, =: relation proved, ? all proofs failed, _: no proof attempted)\n           n m l\n1) 32:6-25 = = =\n2) 33:6-23 = < _\n3) 34:6-23 < _ _\nPlease use `termination_by` to specify a decreasing measure.\nThe three recursive calls are identified by their source positions.\nThis message conveys the following facts:* In the first recursive call, all arguments are (provably) equal to the parameters* In the second recursive call, the first argument is equal to the first parameter and the second argument is provably smaller than the second parameter.\n  The third parameter was not checked for this recursive call, because it was not necessary to determine that no suitable termination argument exists.* In the third recursive call, the first argument decreases strictly, and the other arguments were not checked.When termination proofs fail in this manner, a good technique to discover the problem is to explicitly indicate the expected termination argument using termination_by.\nThis will surface the messages from the failing tactic.\n\n\n\nArray IndexingThe purpose of considering expressions of the form e₂ - e₁ as measures is to support the common idiom of counting up to some upper bound, in particular when traversing arrays in possibly interesting ways.\nIn the following function, which performs binary search on a sorted array, this heuristic helps Lean to find the j - i measure.def binarySearch (x : Int) (xs : Array Int) : Option Nat :=\n  go 0 xs.size\nwhere\n  go (i j : Nat) (hj : j ≤ xs.size := by omega) :=\n    if h : i < j then\n      let mid := (i + j) / 2\n      let y := xs[mid]\n      if x = y then\n        some mid\n      else if x < y then\n        go i mid\n      else\n        go (mid + 1) j\n    else\n      none\n  termination_by?\nThe fact that the inferred termination argument uses some arbitrary measure, rather than an optimal or minimal one, is visible in the inferred measure, which contains a redundant j:Try this:\n  [apply] termination_by (j, j - i)\n\n\n\n\nTermination Proof Tactics During InferenceThe tactic indicated by decreasing_by is used slightly differently when inferring the termination measure than it is in the actual termination proof.* During inference, it is applied to a single goal, attempting to prove < or ≤ on Nat.* During the termination proof, it is applied to many simultaneous goals (one per recursive call), and the goals may involve the lexicographic ordering of pairs.A consequence is that a decreasing_by block that addresses goals individually and which works successfully with an explicit termination argument can cause inference of the termination measure to fail:def ack : Nat → Nat → Nat\n  | 0, n => n + 1\n  | m + 1, 0 => ack m 1\n  | m + 1, n + 1 => ack m (ack (m + 1) n)\ndecreasing_by\n  · apply Prod.Lex.left\n    omega\n  · apply Prod.Lex.right\n    omega\n  · apply Prod.Lex.left\n    omega\nIt is advisable to always include a termination_by clause whenever an explicit decreasing_by proof is given.\n\nInference too powerfulBecause decreasing_tactic avoids the need to backtrack by being incomplete with regard to lexicographic ordering, Lean may infer a termination measure that leads to goals that the tactic cannot prove.\nIn this case, the error message is the one that results from the failing tactic rather than the one that results from being unable to find a measure.\nThis is what happens in notAck:def notAck : Nat → Nat → Nat\n  | 0, n => n + 1\n  | m + 1, 0 => notAck m 1\n  | m + 1, n + 1 => notAck m (notAck (m / 2 + 1) n)\ndecreasing_by all_goals decreasing_tactic\nfailed to prove termination, possible solutions:\n  - Use `have`-expressions to prove the remaining goals\n  - Use `termination_by` to specify a different well-founded relation\n  - Use `decreasing_by` to specify your own tactic for discharging this kind of goal\ncase h\nm n : Nat\n⊢ m / 2 + 1 < m + 1\nIn this case, explicitly stating the termination measure helps.\n\n","context":"Lean Reference\u0009Definitions\u0009Recursive Definitions\u0009Well-Founded Recursion","header":"7.6.3.4. Inferring Well-Founded Recursion","id":"/Definitions/Recursive-Definitions/#inferring-well-founded-recursion"},"/Notations-and-Macros/Macros/#macros":{"contents":"Macros are transformations from Syntax to Syntax that occur during elaboration and during tactic execution.\nReplacing syntax with the result of transforming it with a macro is called macro expansion.\nMultiple macros may be associated with a single syntax kind, and they are attempted in order of definition.\nMacros are run in a monad that has access to some compile-time metadata and has the ability to either emit an error message or to delegate to subsequent macros, but the macro monad is much less powerful than the elaboration monads.\n\n\n\nMacros are associated with syntax kinds.\nAn internal table maps syntax kinds to macros of type Syntax → MacroM Syntax.\nMacros delegate to the next entry in the table by throwing the unsupportedSyntax exception.\nA given Syntax value is a macro when there is a macro associated with its syntax kind that does not throw unsupportedSyntax.\nIf a macro throws any other exception, an error is reported to the user.\nSyntax categories are irrelevant to macro expansion; however, because each syntax kind is typically associated with a single syntax category, they do not interfere in practice.\n\nMacro Error ReportingThe following macro reports an error when its parameter is the literal numeral five.\nIt expands to its argument in all other cases.syntax &\"notFive\" term:arg : term\nopen Lean in\nmacro_rules\n  | `(term|notFive 5) =>\n    Macro.throwError \"'5' is not allowed here\"\n  | `(term|notFive $e) =>\n    pure e\nWhen applied to terms that are not syntactically the numeral five, elaboration succeeds:#eval notFive (2 + 3)\n5\nWhen the error case is triggered, the user receives an error message:#eval notFive 5\n'5' is not allowed here\n\n\nBefore elaborating a piece of syntax, the elaborator checks whether its syntax kind has macros associated with it.\nThese are attempted in order.\nIf a macro succeeds, potentially returning syntax with a different kind, the check is repeated and macros are expanded again until the outermost layer of syntax is no longer a macro.\nElaboration or tactic execution can then proceed.\nOnly the outermost layer of syntax (typically a node) is expanded, and the output of macro expansion may contain nested syntax that is a macro.\nThese nested macros are expanded in turn when the elaborator reaches them.\n\nIn particular, macro expansion occurs in three situations in Lean:\n\n1. During term elaboration, macros in the outermost layer of the syntax to be elaborated are expanded prior to invoking the syntax's term elaborator.2. During command elaboration, macros in the outermost layer of the syntax to be elaborated are expanded prior to invoking the syntax's command elaborator.3. During tactic execution, macros in the outermost layer of the syntax to be elaborated are expanded prior to executing the syntax as a tactic.\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Notations and Macros","header":"20.5. Macros","id":"/Notations-and-Macros/Macros/#macros"},"/Tactic-Proofs/Custom-Tactics/#tactic-macros":{"contents":"The easiest way to define a new tactic is as a macro that expands into already-existing tactics.\nMacro expansion is interleaved with tactic execution.\nThe tactic interpreter first expands tactic macros just before they are to be interpreted.\nBecause tactic macros are not fully expanded prior to running a tactic script, they can use recursion; as long as the recursive occurrence of the macro syntax is beneath a tactic that can be executed, there will not be an infinite chain of expansion.\n\nRecursive tactic macroThis recursive implementation of a tactic akin to repeat is defined via macro expansion.\nWhen the argument $t fails, the recursive occurrence of rep is never invoked, and is thus never macro expanded.syntax \"rep\" tactic : tactic\nmacro_rules\n  | `(tactic|rep $t) =>\n  `(tactic|\n    first\n      | $t; rep $t\n      | skip)\n\nexample : 0 ≤ 4 := by\n  rep (apply Nat.le.step)\n  apply Nat.le.refl\n\n\nLike other Lean macros, tactic macros are hygienic.\nReferences to global names are resolved when the macro is defined, and names introduced by the tactic macro cannot capture names from its invocation site.\n\nWhen defining a tactic macro, it's important to specify that the syntax being matched or constructed is for the syntax category tactic.\nOtherwise, the syntax will be interpreted as that of a term, which will match against or construct an incorrect AST for tactics.\n\n\n\n","context":"Lean Reference\u0009Tactic Proofs\u0009Custom Tactics","header":"13.8.1. Tactic Macros","id":"/Tactic-Proofs/Custom-Tactics/#tactic-macros"},"/Terms/Holes/#The-Lean-Language-Reference--Terms--Holes":{"contents":"A hole or placeholder term is a term that indicates the absence of instructions to the elaborator.\nIn terms, holes can be automatically filled when the surrounding context would only allow one type-correct term to be written where the hole is.\nOtherwise, a hole is an error.\nIn patterns, holes represent universal patterns that can match anything.\n\nHolesHoles are written with underscores.\n\nFilling Holes with UnificationThe function the can be used similarly to show or a type ascription.def the (α : Sort u) (x : α) : α := x\nIf the second parameter's type can be inferred, then the first parameter can be a hole.\nBoth of these commands are equivalent:#check the String \"Hello!\"\n\n#check the _ \"Hello\"\n\n\nWhen writing proofs, it can be convenient to explicitly introduce unknown values.\nThis is done via synthetic holes, which are never solved by unification and may occur in multiple positions.\nThey are primarily useful in tactic proofs, and are described in the section on metavariables in proofs.\n\nSynthetic Holes\n\n","context":"Lean Reference\u0009Terms","header":"10.9. Holes","id":"/Terms/Holes/#The-Lean-Language-Reference--Terms--Holes"},"/releases/v4.24.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___24___0-_LPAR_2025-10-14_RPAR_--Language":{"contents":"* #8891 improves the error message produced when passing (automatically\nredundant) local hypotheses to grind.* #9651 modifies the generation of induction and partial correctness\nlemmas for mutual blocks defined via partial_fixpoint. Additionally,\nthe generation of lattice-theoretic induction principles of functions\nvia mutual blocks is modified for consistency with partial_fixpoint.* #9674 cleans up optParam/autoParam/etc. annotations before\nelaborating definition bodies, theorem bodies, fun bodies, and let\nfunction bodies. Both variables and binders in declaration headers are\nsupported.* #9918 prevents rcases and obtain from creating absurdly long case\ntag names when taking single constructor types (like Exists) apart.\nFixes #6550* #9923 adds a guard for a delaborator that is causing panics in\ndoc-gen4. This is a band-aid solution for now, and @sgraf812 will take a\nlook when they're back from leave.* #9926 guards the Std.Tactic.Do.MGoalEntails delaborator by a check\nensuring that there are at least 3 arguments present, preventing\npotential panics.* #9927 implements extended induction-inspired syntax for mvcgen,\nallowing optional using invariants and with sections.* #9930 reverts the way grind cutsat embeds Nat.sub into Int. It\nfixes a regression reported by David Renshaw on Zulip.* #9938 removes a duplicate mpure_intro tactic definition.* #9939 expands mvcgen using invariants | $n => $t to mvcgen; case inv<$n> => exact $t to avoid MVar instantiation mishaps observable in\nthe test case for #9581.* #9942 modifies intro to create tactic info localized to each\nhypothesis, making it possible to see how intro works\nvariable-by-variable. Additionally:* The tactic supports intro rfl to introduce an equality and\nimmediately substitute it, like rintro rfl (recall: the rfl pattern\nis like doing intro h; subst h). The rintro tactic can also now\nsupport HEq in rfl patterns if eq_of_heq applies.* In intro (h : t), elaboration of t is interleaved with unification\nwith the type of h, which prevents default instances from causing\nunification to fail.* Tactics that change types of hypotheses (including intro (h : t),\ndelta, dsimp) now update the local instance cache.* #9945 optimizes the proof terms produced by grind cutsat. It removes\nunused entries from the context objects when generating the final proof,\nsignificantly reducing the amount of junk in the resulting terms.\nExample:/--\ntrace: [grind.debug.proof] fun h h_1 h_2 h_3 h_4 h_5 h_6 h_7 h_8 =>\n      let ctx := RArray.leaf (f 2);\n      let p_1 := Poly.add 1 0 (Poly.num 0);\n      let p_2 := Poly.add (-1) 0 (Poly.num 1);\n      let p_3 := Poly.num 1;\n      le_unsat ctx p_3 (eagerReduce (Eq.refl true)) (le_combine ctx p_2 p_1 p_3 (eagerReduce (Eq.refl true)) h_8 h_1)\n-/\n#guard_msgs in -- Context should contain only `f 2`\nopen Lean Int Linear in\nset_option trace.grind.debug.proof true in\nexample (f : Nat → Int) :\n    f 1 <= 0 → f 2 <= 0 → f 3 <= 0 → f 4 <= 0 → f 5 <= 0 →\n    f 6 <= 0 → f 7 <= 0 → f 8 <= 0 → -1 * f 2 + 1 <= 0 → False := by\n  grind\n* #9946 optimizes the proof terms produced by grind ring. It is\nsimilar to #9945, but for the ring module in grind.\nIt removes unused entries from the context objects when generating the\nfinal proof, significantly reducing the amount of junk in the resulting\nterms. Example:/--\ntrace: [grind.debug.proof] fun h h_1 h_2 h_3 =>\n      Classical.byContradiction fun h_4 =>\n        let ctx := RArray.branch 1 (RArray.leaf x) (RArray.leaf x⁻¹);\n        let e_1 := (Expr.var 0).mul (Expr.var 1);\n        let e_2 := Expr.num 0;\n        let e_3 := Expr.num 1;\n        let e_4 := (Expr.var 0).pow 2;\n        let m_1 := Mon.mult (Power.mk 1 1) Mon.unit;\n        let m_2 := Mon.mult (Power.mk 0 1) Mon.unit;\n        let p_1 := Poly.num (-1);\n        let p_2 := Poly.add (-1) (Mon.mult (Power.mk 0 1) Mon.unit) (Poly.num 0);\n        let p_3 := Poly.add 1 (Mon.mult (Power.mk 0 2) Mon.unit) (Poly.num 0);\n        let p_4 := Poly.add 1 (Mon.mult (Power.mk 0 1) (Mon.mult (Power.mk 1 1) Mon.unit)) (Poly.num (-1));\n        let p_5 := Poly.add 1 (Mon.mult (Power.mk 0 1) Mon.unit) (Poly.num 0);\n        one_eq_zero_unsat ctx p_1 (eagerReduce (Eq.refl true))\n          (Stepwise.simp ctx 1 p_4 (-1) m_1 p_5 p_1 (eagerReduce (Eq.refl true))\n            (Stepwise.core ctx e_1 e_3 p_4 (eagerReduce (Eq.refl true)) (diseq0_to_eq x h_4))\n            (Stepwise.mul ctx p_2 (-1) p_5 (eagerReduce (Eq.refl true))\n              (Stepwise.superpose ctx 1 m_2 p_4 (-1) m_1 p_3 p_2 (eagerReduce (Eq.refl true))\n                (Stepwise.core ctx e_1 e_3 p_4 (eagerReduce (Eq.refl true)) (diseq0_to_eq x h_4))\n                (Stepwise.core ctx e_4 e_2 p_3 (eagerReduce (Eq.refl true)) h))))\n-/\n#guard_msgs in -- Context should contains only `x` and its inverse.\nset_option trace.grind.debug.proof true in\nset_option pp.structureInstances false in\nopen Lean Grind CommRing in\nexample [Field α] (x y z w : α) :\n   x^2 = 0 → y^2 = 0 → z^3 = 0 → w^2 = 0 → x = 0 := by\n  grind\n* #9947 optimizes the proof terms produced by grind linarith. It is\nsimilar to #9945, but for the linarith module in grind.\nIt removes unused entries from the context objects when generating the\nfinal proof, significantly reducing the amount of junk in the resulting\nterms.* #9951 generates .ctorIdx functions for all inductive types, not just\nenumeration types. This can be a building block for other constructions\n(BEq, noConfusion) that are size-efficient even for large\ninductives.* #9952 adds “non-branching case statements”: For each inductive\nconstructor T.con this adds a function T.con.with that is similar\nT.casesOn, but has only one arm (the one for con), and an additional\nt.toCtorIdx = 12 assumption.* #9954 removes the option grind +ringNull. It provided an alternative\nproof term construction for the grind ring module, but it was less\neffective than the default proof construction mode and had effectively\nbecome dead code.\nalso optimizes semiring normalization proof terms using the\ninfrastructure added in #9946.\nRemark: After updating stage0, we can remove several background\ntheorems from the Init/Grind folder.* #9958 ensures that equations in the grind cutsat module are\nmaintained in solved form. That is, given an equation a*x + p = 0 used\nto eliminate x, the linear polynomial p must not contain other\neliminated variables. Before this PR, equations were maintained in\ntriangular form. We are going to use the solved form to linearize\nnonlinear terms.* #9968 modifies macros, which implement non-atomic definitions and\n$cmd1 in $cmd2 syntax. These macros involve implicit scopes,\nintroduced through section and namespace commands. Since\nsections or namespaces are designed to delimit local attributes, this\nhas led to unintuitive behaviour when applying local attributes to\ndefinitions appearing in the above-mentioned contexts. This has been\ncausing the following examples to fail:axiom A : Prop\n\n* #9974 registers a parser alias for Lean.Parser.Command.visibility.\nThis avoids having to import Lean.Parser.Command in simple command\nmacros that use visibilities.* #9980 fixes a bug in the dynamic variable reordering function used in\ngrind cutsat.* #9989 changes the new extended syntax for mvcgen to mvcgen invariants ... with ....* #9995 almost completely rewrites the inductive predicate recursion\nalgorithm; in particular IndPredBelow to function more consistently.\nHistorically, the brecOn generation through IndPredBelow has been\nvery error-prone -- this should be fixed now since the new algorithm is\nvery direct and doesn't rely on tactics or meta-variables at all.\nAdditionally, the new structural recursion procedure for inductive\npredicates shares more code with regular structural recursion and thus\nallows for mutual and nested recursion in the same way it was possible\nwith regular structural recursion. For example, the following works now:mutual\n\n* #9996 improves support for nonlinear monomials in grind cutsat. For\nexample, given a monomial a * b, if cutsat discovers that a = 2,\nit now propagates that a * b = 2 * b.\nRecall that nonlinear monomials like a * b are treated as variables in\ncutsat, a procedure designed for linear integer arithmetic.* #10007 lets #print print private before protected, matching the\nsyntax.* #10008 fixes a bug in #eval where clicking on the evaluated\nexpression could show errors in the Infoview. This was caused by #eval\nnot saving the temporary environment that is used when elaborating the\nexpression.* #10010 improves support for nonlinear / and % in grind cutsat.\nFor example, given a / b, if cutsat discovers that b = 2, it now\npropagates that a / b = b / 2. is similar to #9996, but for\n/ and %. Example:example (a b c d : Nat)\n    : b > 1 → d = 1 → b ≤ d + 1 → a % b = 1 → a = 2 * c → False := by\n  grind\n* #10020 fixes a missing case for PR #10010.* #10021 make some minor changes to the grind annotation analysis script,\nincluding sorting results and handling errors. Still need to add an\nexternal UI.* #10022 improves support for Fin n in grind cutsat when n is not a\nnumeral. For example, the following goals can now be solved\nautomatically:example (p d : Nat) (n : Fin (p + 1))\n    : 2 ≤ p → p ≤ d + 1 → d = 1 → n = 0 ∨ n = 1 ∨ n = 2 := by\n  grind\n\n* #10034 changes the \"declaration uses 'sorry'\" error to pretty print an\nactual sorry expression in the message. The effect is that the sorry\nis hoverable and, if it's labeled, you can \"go to definition\" to see\nwhere it came from.* #10038 ensures grind error messages use {.ofConstName declName}\nwhen referencing declaration names.* #10060 allows for more fine-grained control over what derived instances\nhave exposed definitions under the module system: handlers should not\nexpose their implementation unless either the deriving item or a\nsurrounding section is marked with @[expose]. Built-in handlers to be\nupdated after a stage 0 update.* #10069 adds helper theorems to support NatModule in grind linarith.* #10071 improves support for a^n in grind cutsat. For example, if\ncutsat discovers that a and b are equal to numerals, it now\npropagates the equality. is similar to #9996, but a^b.\nExample:example (n : Nat) : n = 2 → 2 ^ (n+1) = 8 := by\n  grind\n* #10085 adds a parser alias for the rawIdent parser, so that it can be\nused in syntax declarations in Init.* #10093 adds background theorems for a new solver to be implemented in\ngrind that will support associative and commutative operators.* #10095 modifies the grind algebra typeclasses to use SMul x y\ninstead of HMul x y y.* #10105 adds support for detecting associative operators in grind. The\nnew AC module also detects whether the operator is commutative,\nidempotent, and whether it has a neutral element. The information is\ncached.* #10113 deprecates .toCtorIdx for the more naturally named .ctorIdx\n(and updates the standard library).* #10120 fixes an issue where private definitions recursively invoked\nusing generalized field notation (dot notation) would give an \"invalid\nfield\" errors. It also fixes an issue where \"invalid field notation\"\nerrors would pretty print the name of the declaration with a _private\nprefix.* #10125 allows #guard_msgs to report the relative positions of logged\nmessages with the config option (positions := true).* #10129 replaces the interim order typeclasses used by Grind with the\nnew publicly available classes in Std.* #10134 makes the generation of functional induction principles more\nrobust when the user let-binds a variable that is then match'ed on.\nFixes #10132.* #10135 lets the ctorIdx definition for single constructor inductives\navoid the pointless .casesOn, and uses macro_inline to avoid\ncompiling the function and wasting symbols.* #10141 reverts the macro_inline part of #10135.* #10144 changes the construction of a CompleteLattice instance on\npredicates (maps intro Prop) inside of\ncoinductive_fixpoint/inductive_fixpoint machinery.* #10146 implements the basic infrastructure for the new procedure\nhandling AC operators in grind. It already supports normalizing\ndisequalities. Future PRs will add support for simplification using\nequalities, and computing critical pairs. Examples:example {α : Sort u} (op : α → α → α) [Std.Associative op] (a b c : α)\n    : op a (op b c) = op (op a b) c := by\n  grind only\n\n* #10151 ensures where finally tactics can access private data under\nthe module system even when the corresponding holes are in the public\nscope as long as all of them are of proposition types.* #10152 introduces an alternative construction for DecidableEq\ninstances that avoids the quadratic overhead of the default\nconstruction.* #10166 reviews the expected-to-fail-right-now tests for grind, moving\nsome (now passing) tests to the main test suite, updating some tests,\nand adding some tests about normalisation of exponents.* #10177 fixes a bug in the grind preprocessor exposed by #10160.* #10179 fixes grind instance normalization procedure.\nSome modules in grind use builtin instances defined directly in core\n(e.g., cutsat), while others synthesize them using synthInstance\n(e.g., ring). This inconsistency is problematic, as it may introduce\nmismatches and result in two different representations for the same\nterm. fixes the issue.* #10183 lets match equations be proved by rfl if possible, instead of\nexplicitly unfolding the LHS first. May lead to smaller proofs.* #10185 documents all grind attribute modifiers (e.g., =, usr,\next, etc).* #10186 adds supports for simplifying disequalities in the grind ac\nmodule.* #10189 implements the proof terms for the new grind ac module.\nExamples:example {α : Sort u} (op : α → α → α) [Std.Associative op] (a b c d : α)\n    : op a (op b b) = op c d → op c (op d c) = op (op a b) (op b c) := by\n  grind only\n\n* #10205 adds superposition for associative and commutative operators in\ngrind ac. Examples:example (a b c d e f g h : Nat) :\n    max a b = max c d → max b e = max d f → max b g = max d h →\n    max (max f d) (max c g) = max (max e (max d (max b (max c e)))) h := by\n  grind -cutsat only\n\n* #10206 adds superposition for associative (but non-commutative)\noperators in grind ac. Examples:example {α} (op : α → α → α) [Std.Associative op] (a b c d : α)\n   : op a b = c →\n     op b a = d →\n     op (op c a) (op b c) = op (op a d) (op d b) := by\n  grind\n\n* #10208 adds the extra critical pairs to ensure the grind ac procedure\nis complete when the operator is AC and idempotent. Example:example {α : Sort u} (op : α → α → α) [Std.Associative op] [Std.Commutative op] [Std.IdempotentOp op]\n      (a b c d : α) : op a (op b b) = op d c → op (op b a) (op b c) = op c (op d c)  := by\n  grind only\n* #10221 adds the extra critical pairs to ensure the grind ac procedure\nis complete when the operator is associative and idempotent, but not\ncommutative. Example:example {α : Sort u} (op : α → α → α) [Std.Associative op] [Std.IdempotentOp op] (a b c d e f x y w : α)\n    : op d (op x c) = op a b →\n      op e (op f (op y w)) = op a (op b c) →\n      op d (op x c) = op e (op f (op y w)) := by\n  grind only\n\n* #10223 implements equality propagation from the new AC module into the\ngrind core. Examples:example {α β : Sort u} (f : α → β) (op : α → α → α) [Std.Associative op] [Std.Commutative op]\n    (a b c d : α) : op a (op b b) = op d c → f (op (op b a) (op b c)) = f (op c (op d c)) := by\n  grind only\n\n* #10230 adds MonoBind for more monad transformers. This allows using\npartial_fixpoint for more complicated monads based on Option and\nEIO. Example:abbrev M := ReaderT String (StateT String.Pos Option)\n\n* #10237 fixes a missing case in the grind canonicalizer. Some types\nmay include terms or propositions that are internalized later in the\ngrind state.* #10239 fixes the E-matching procedure for theorems that contain\nuniverse parameters not referenced by any regular parameter. This kind\nof theorem seldom happens in practice, but we do have instances in the\nstandard library. Example:@[simp, grind =] theorem Std.Do.SPred.down_pure {φ : Prop} : (⌜φ⌝ : SPred []).down = φ := rfl\n* #10241 adds some test cases for grind working with Fin. There are\nmany still failing tests in tests/lean/grind/grind_fin.lean which I'm\nintending to triage and work on.* #10245 changes the implementation of a function unfoldPredRel used in\n(co)inductive predicate machinery, that unfolds pointwise order on\npredicates to quantifications and implications. Previous implementation\nrelied on withDeclsDND that could not deal with types which depend on\neach other. This caused the following example to fail:inductive infSeq_functor1.{u} {α : Type u} (r : α → α → Prop) (call : {α : Type u} → (r : α → α → Prop) → α → Prop) : α → Prop where\n  | step : r a b → infSeq_functor1 r call b → infSeq_functor1 r call a\n\n* #10265 fixes a panic in grind ring exposed by #10242. grind ring\nshould not assume that all normalizations have been applied, because\nsome subterms cannot be rewritten by simp due to typing constraints.\nMoreover, grind uses preprocessLight in a few places, and it skips\nthe simplifier/normalizer.* #10267 implements the infrastructure for supporting NatModule in\ngrind linarith and uses it to handle disequalities. Another PR will\nadd support for equalities and inequalities. Example:open Lean Grind\nvariable (M : Type) [NatModule M] [AddRightCancel M]\n\n* #10269 changes the string interpolation procedure to omit redundant\nempty parts. For example s!\"{1}{2}\" previously elaborated to toString \"\" ++ toString 1 ++ toString \"\" ++ toString 2 ++ toString \"\" and now\nelaborates to toString 1 ++ toString 2.* #10271 changes the naming of the internal functions in deriving\ninstances like BEq to use accessible names. This is necessary to\nreasonably easily prove things about these functions. For example after\nderiving BEq for a type T, the implementation of instBEqT is in\ninstBEqT.beq.* #10273 tries to do the right thing about the visibility of the\nsame-ctor-match-construct.* #10274 changes the implementation of the linear DecidableEq\nimplementation to use match decEq rather than if h :  to compare the\nconstructor tags. Otherwise, the “smart unfolding” machinery will not\nlet rfl decide that different constructors are different.* #10277 adds the missing instances IsPartialOrder, IsLinearPreorder\nand IsLinearOrder for OfNatModule.Q α.* #10278 adds support for NatModule equalities and inequalities in\ngrind linarith. Examples:open Lean Grind Std\n\n* #10280 adds the auxiliary theorem Lean.Grind.Linarith.eq_normN for\nnormalizing NatModule equations when the instance AddRightCancel is\nnot available.* #10281 implements NatModule normalization when the AddRightCancel\ninstance is not available. Note that in this case, the embedding into\nIntModule is not injective. Therefore, we use a custom normalizer,\nsimilar to the CommSemiring normalizer used in the grind ring\nmodule. Example:open Lean Grind\nexample [NatModule α] (a b c : α)\n    : 2•a + 2•(b + 2•c) + 3•a = 4•a + c + 2•b + 3•c + a := by\n  grind\n* #10282 improves the counterexamples produced by grind linarith for\nNatModules. grind now hides occurrences of the auxiliary function\nGrind.IntModule.OfNatModule.toQ.* #10283 implements diagnostic information for the grind ac module. It\nnow displays the basis, normalized disequalities, and additional\nproperties detected for each associative operator.* #10290 adds infrastructure for registering new grind solvers. grind\nalready includes many solvers, and this PR is the first step toward\nmodularizing the design and supporting user-defined solvers.* #10294 completes the grind solver extension design and ports the\ngrind ac solver to the new framework. Future PRs will document the API\nand port the remaining solvers. An additional benefit of the new design\nis faster build times.* #10296 fixes a bug in an auxiliary function used to construct proof\nterms in grind cutsat.* #10300 offers an alternative noConfusion construction for the\noff-diagonal use (i.e. for different constructors), based on comparing\nthe .ctorIdx. This should lead to faster type checking, as the kernel\nonly has to reduce .ctorIdx twice, instead of the complicate\nnoConfusionType construction.* #10301 exposes ctorIdx and per-constructor eliminators. Fixes #10299.* #10306 fixes a few bugs in the rw tactic: it could \"steal\" goals\nbecause they appear in the type of the rewrite, it did not do an occurs\ncheck, and new proof goals would not be synthetic opaque. also\nlets the rfl tactic assign synthetic opaque metavariables so that it\nis equivalent to exact rfl.* #10307 upstreams the Verso parser and adds preliminary support for\nVerso in docstrings. This will allow the compiler to check examples and\ncross-references in documentation.* #10309 modifies the simpa tactic so that in simpa ... using e there\nis tactic info on the range simpa ... using that shows the simplified\ngoal.* #10313 adds missing grind normalization rules for natCast and\nintCast Examples:open Lean.Grind\nvariable (R : Type) (a b : R)\n\n* #10314 skips model based theory combination on instances.* #10315 adds T.ctor.noConfusion declarations, which are\nspecializations of T.noConfusion to equalities between T.ctor. The\npoint is to avoid reducing the T.noConfusionType construction every\ntime we use injection or a similar tactic.* #10316 shares common functionality relate to equalities between same\nconstructors, and when these are type-correct. In particular it uses the\nmore complete logic from mkInjectivityThm also in other places, such\nas CasesOnSameCtor and the deriving code for BEq, DecidableEq,\nOrd, for more consistency and better error messages.* #10321 ensures that the auxiliary temporary metavariable IDs created by\nthe E-matching module used in grind are not affected by what has been\nexecuted before invoking grind. The goal is to increase grind’s\nrobustness.* #10322 introduces limited functionality frontends cutsat and\ngrobner for grind. We disable theorem instantiation (and case\nsplitting for grobner), and turn off all other solvers. Both still\nallow grind configuration options, so for example one can use cutsat +ring (or grobner +cutsat) to solve problems that require both.* #10323 fixes the grind canonicalizer for OfNat.ofNat applications.\nExample:example {C : Type} (h : Fin 2 → C) :\n    -- `0` in the first `OfNat.ofNat` is not a raw literal\n    h (@OfNat.ofNat (Fin (1 + 1)) 0 Fin.instOfNat) = h 0 := by\n  grind\n* #10324 disables an unused instance that causes expensive typeclass\nsearches.* #10325 implements model-based theory combination for types A which\nimplement the ToInt interface. Examples:example {C : Type} (h : Fin 4 → C) (x : Fin 4)\n    : 3 ≤ x → x ≤ 3 → h x = h (-1) := by\n  grind\n\n* #10326 fixes a performance issue in grind linarith. It was creating\nunnecessary NatModule/IntModule structures for commutative rings\nwithout an order. This kind of type should be handled by grind ring\nonly.* #10331 implements mkNoConfusionImp in Lean rather than in C. This\nreduces our reliance on C, and may bring performance benefits from not\nreducing noConfusionType during elaboration time (it still gets\nreduced by the kernel when type-checking).* #10332 ensures that the infotree recognizes Classical.propDecidable\nas an instance, when below a classical tactic.* #10335 fixes the nested proof term detection in grind. It must check\nwhether the gadget Grind.nestedProof is over-applied.* #10342 implements a new E-matching pattern inference procedure that is\nfaithful to the behavior documented in the reference manual regarding\nminimal indexable subexpressions. The old inference procedure was\nfailing to enforce this condition. For example, the manual documents\n[grind ->] as follows* #10373 adds a pp.unicode option and a unicode(\"→\", \"->\") syntax\ndescription alias for the lower-level unicodeSymbol \"→\" \"->\" parser.\nThe syntax is added to the notation command as well. When pp.unicode\nis true (the default) then the first form is used when pretty printing,\nand otherwise the second ASCII form is used. A variant, unicode(\"→\", \"->\", preserveForPP) causes the -> form to be preferred; delaborators\ncan insert → directly into the syntax, which will be pretty printed\nas-is; this allows notations like fun to use custom options such as\npp.unicode.fun to opt into the unicode form when pretty printing.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.24.0 (2025-10-14)","header":"Language","id":"/releases/v4.24.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___24___0-_LPAR_2025-10-14_RPAR_--Language"},"/releases/v4.9.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___9___0-_LPAR_2024-07-01_RPAR_--Lake":{"contents":"* #4518 makes trace reading more robust. Lake now rebuilds if trace files are invalid or unreadable and is backwards compatible with previous pure numeric traces.* #4057 adds support for docstrings on require commands.* #4088 improves hovers for family_def and library_data commands.* #4147 adds default README.md to package templates* #4261 extends lake test help page, adds help page for lake check-test,\nadds lake lint and tag @[lint_driver], adds support for specifying test and lint drivers from dependencies,\nadds testDriverArgs and lintDriverArgs options, adds support for library test drivers,\nmakes lake check-test and lake check-lint only load the package without dependencies.* #4270 adds lake pack and lake unpack for packing and unpacking Lake build artifacts from an archive.* #4083\nSwitches the manifest format to use major.minor.patch semantic\nversions. Major version increments indicate breaking changes (e.g., new\nrequired fields and semantic changes to existing fields). Minor version\nincrements (after 0.x) indicate backwards-compatible extensions (e.g.,\nadding optional fields, removing fields). This change is backwards\ncompatible. Lake will still successfully read old manifests with numeric\nversions. It will treat the numeric version N as semantic version\n0.N.0. Lake will also accept manifest versions with - suffixes\n(e.g., x.y.z-foo) and then ignore the suffix.* #4273 adds a lift from JobM to FetchM for backwards compatibility reasons.* #4351 fixes LogIO-to-CliM-lifting performance issues.* #4343 make Lake store the dependency trace for a build in\nthe cached build long and then verifies that it matches the trace of the current build before replaying the log.* #4402 moves the cached log into the trace file (no more .log.json).\nThis means logs are no longer cached on fatal errors and this ensures that an out-of-date log is not associated with an up-to-date trace.\nSeparately, .hash file generation was changed to be more reliable as well.\nThe .hash files are deleted as part of the build and always regenerate with --rehash.* Other fixes or improvements* #4056 cleans up tests* #4244 fixes noRelease test when Lean repo is tagged* #4346 improves tests/serve* #4356 adds build log path to the warning for a missing or invalid build log.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.9.0 (2024-07-01)","header":"Lake","id":"/releases/v4.9.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___9___0-_LPAR_2024-07-01_RPAR_--Lake"},"/releases/v4.9.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___9___0-_LPAR_2024-07-01_RPAR_--Lean-internals":{"contents":"* Defeq and WHNF algorithms* #4029 remove unnecessary checkpointDefEq* #4206 fixes isReadOnlyOrSyntheticOpaque to respect metavariable depth.* #4217 fixes missing occurs check for delayed assignments.* Definition transparency* #4052 adds validation to application of @[reducible]/@[semireducible]/@[irreducible] attributes (with local/scoped modifiers as well).\nSetting set_option allowUnsafeReductibility true turns this validation off.* Inductive types* #3591 fixes a bug where indices could be incorrectly promoted to parameters.* #3398 fixes a bug in the injectivity theorem generator.* #4342 fixes elaboration of mutual inductives with instance parameters.* Diagnostics and profiling* #3986 adds option trace.profiler.useHeartbeats to switch trace.profiler.threshold to being in terms of heartbeats instead of milliseconds.* #4082 makes set_option diagnostics true report kernel diagnostic information.* Typeclass resolution* #4119 fixes multiple issues with TC caching interacting with synthPendingDepth, adds maxSynthPendingDepth option with default value 1.* #4210 ensures local instance cache does not contain multiple copies of the same instance.* #4216 fix handling of metavariables, to avoid needing to set the option backward.synthInstance.canonInstances to false.* Other fixes or improvements* #4080 fixes propagation of state for Lean.Elab.Command.liftCoreM and Lean.Elab.Command.liftTermElabM.* #3944 makes the Repr deriving handler be consistent between structure and inductive for how types and proofs are erased.* #4113 propagates maxHeartbeats to kernel to control \"(kernel) deterministic timeout\" error.* #4125 reverts #3970 (monadic generalization of FindExpr).* #4128 catches stack overflow in auto-bound implicits feature.* #4129 adds tryCatchRuntimeEx combinator to replace catchRuntimeEx reader state.* #4155 simplifies the expression canonicalizer.* #4151 and #4369\nadd many missing trace classes.* #4185 makes congruence theorem generators clean up type annotations of argument types.* #4192 fixes restoration of infotrees when auto-bound implicit feature is activated,\nfixing a pretty printing error in hovers and strengthening the unused variable linter.* dfb496 fixes declareBuiltin to allow it to be called multiple times per declaration.* #4569 fixes an issue introduced in a merge conflict, where the interrupt exception was swallowed by some tryCatchRuntimeEx uses.* #4584 (backported as b056a0) adapts kernel interruption to the new cancellation system.* Cleanup: #4112, #4126, #4091, #4139, #4153.* Tests: 030406, #4133.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.9.0 (2024-07-01)","header":"Lean internals","id":"/releases/v4.9.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___9___0-_LPAR_2024-07-01_RPAR_--Lean-internals"}});