window.docContents[43].resolve({"/Basic-Types/Finite-Natural-Numbers/#The-Lean-Language-Reference--Basic-Types--Finite-Natural-Numbers--Coercions-and-Literals":{"contents":"There is a coercion from Fin n to Nat that discards the proof that the number is less than the bound.\nIn particular, this coercion is precisely the projection Fin.val.\nOne consequence of this is that uses of Fin.val are displayed as coercions rather than explicit projections in proof states.\n\nCoercing from Fin to NatA Fin n can be used where a Nat is expected:#eval let one : Fin 3 := ⟨1, by omega⟩; (one : Nat)\n1\nUses of Fin.val show up as coercions in proof states:n : Nat\ni : Fin n\n⊢ ↑i < n\n\nNatural number literals may be used for Fin types, implemented as usual via an OfNat instance.\nThe OfNat instance for Fin n requires that the upper bound n is not zero, but does not check that the literal is less than n.\nIf the literal is larger than the type can represent, the remainder when dividing it by n is used.\n\nNumeric Literals for FinIf n > 0, then natural number literals can be used for Fin n:example : Fin 5 := 3\nexample : Fin 20 := 19\nWhen the literal is greater than or equal to n, the remainder when dividing by n is used:#eval (5 : Fin 3)\n2\n#eval ([0, 1, 2, 3, 4, 5, 6] : List (Fin 3))\n[0, 1, 2, 0, 1, 2, 0]\nIf Lean can't synthesize an instance of NeZero n, then there is no OfNat (Fin n) instance:example : Fin 0 := 0\nfailed to synthesize\n  OfNat (Fin 0) 0\nnumerals are polymorphic in Lean, but the numeral `0` cannot be used in a context where the expected type is\n  Fin 0\ndue to the absence of the instance above\n\nHint: Additional diagnostic information may be available using the `set_option diagnostics true` command.\nexample (k : Nat) : Fin k := 0\nfailed to synthesize\n  OfNat (Fin k) 0\nnumerals are polymorphic in Lean, but the numeral `0` cannot be used in a context where the expected type is\n  Fin k\ndue to the absence of the instance above\n\nHint: Additional diagnostic information may be available using the `set_option diagnostics true` command.\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Finite Natural Numbers","header":"19.3.2. Coercions and Literals","id":"/Basic-Types/Finite-Natural-Numbers/#The-Lean-Language-Reference--Basic-Types--Finite-Natural-Numbers--Coercions-and-Literals"},"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Hash-Sets--Conversion":{"contents":"Creates a hash set from a list of elements. Note that unlike repeatedly calling insert, if the\ncollection contains multiple elements that are equal (with regard to ==), then the last element\nin the collection will be present in the returned hash set.\n\nTransforms the hash set into a list of elements in some order.\n\nCreates a hash set from an array of elements. Note that unlike repeatedly calling insert, if the\ncollection contains multiple elements that are equal (with regard to ==), then the last element\nin the collection will be present in the returned hash set.\n\nTransforms the hash set into an array of elements in some order.\n\n","context":"Lean Reference\u0009Basic Types\u0009Maps and Sets\u0009Hash Sets","header":"19.18.6.6. Conversion","id":"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Hash-Sets--Conversion"},"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Concepts-and-Terminology--Builds":{"contents":"Producing a desired artifact, such as a .olean file or an executable binary, is called a build.\nBuilds are triggered by the build command or by other commands that require an artifact to be present, such as exe.\nA build consists of the following steps: Configuring the package\n\nIf package configuration file is newer than the cached configuration file lakefile.olean, then the package configuration is re-elaborated.\n  This also occurs when the cached file is missing or when the --reconfigure or -R flag is provided.\n  Changes to options using -K do not trigger re-elaboration of the configuration file; -R is necessary in these cases.\n\n Computing dependencies\n\nThe set of artifacts that are required to produce the desired output are determined, along with the targets and facets that produce them.\n  This process is recursive, and the result is a graph of dependencies.\n  The dependencies in this graph are distinct from those declared for a package: packages depend on other packages, while build targets depend on other build targets, which may be in the same package or in a different one.\n  One facet of a given target may depend on other facets of the same target.\n  Lake automatically analyzes the imports of Lean modules to discover their dependencies, and the extraDepTargets field can be used to add additional dependencies to a target.\n\n Replaying traces\n\nRather than rebuilding everything in the dependency graph from scratch, Lake uses saved trace files to determine which artifacts require building.\n  During a build, Lake records which source files or other artifacts were used to produce each artifact, saving a hash of each input; these traces are saved in the build directory.More specifically, each artifact's trace file contains a Merkle tree hash mixture of its inputs' hashes.\n  If the inputs are all unmodified, then the corresponding artifact is not rebuilt.\n  Trace files additionally record the log from each build task; these outputs are replayed as if the artifact had been built anew.\n  Re-using prior build products when possible is called an incremental build.\n\n Building artifacts\n\nWhen all unmodified dependencies in the dependency graph have been replayed from their trace files, Lake proceeds to build each artifact.\n  This involves running the appropriate build tool on the input files and saving the artifact and its trace file, as specified in the corresponding facet.\n\n\n\nLake uses two separate hash algorithms.\nText files are hashed after normalizing newlines, so that files that differ only by platform-specific newline conventions are hashed identically.\nOther files are hashed without any normalization.\n\nAlong with the trace files, Lean caches input hashes.\nWhenever an artifact is built, its hash is saved in a separate file that can be re-read instead of computing the hash from scratch.\nThis is a performance optimization.\nThis feature can be disabled, causing all hashes to be recomputed from their inputs, using the --rehash command-line option.\n\nDuring a build, the following directories are provided to the underlying build tools:* The source directory contains Lean source code that is available for import.* The library directories contain .olean files along with the shared and static libraries that are available for linking; it normally consists of the root package's library directory (found in .lake/build/lib), the library directories for the other packages in the workspace, the library directory for the current Lean toolchain, and the system library directory.* The Lake home is the directory in which Lake is installed, including binaries, source code, and libraries.\n   The libraries in the Lake home are needed to elaborate Lake configuration files, which have access to the full power of Lean.\n\n","context":"Lean Reference\u0009Build Tools\u0009Lake\u0009Concepts and Terminology","header":"22.1.1.1. Builds","id":"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Concepts-and-Terminology--Builds"},"/Terms/Type-Ascription/#The-Lean-Language-Reference--Terms--Type-Ascription":{"contents":"Type ascriptions explicitly annotate terms with their types.\nThey are a way to provide Lean with the expected type for a term.\nThis type must be definitionally equal to the type that is expected based on the term's context.\nType ascriptions are useful for more than just documenting a program:\n\n* There may not be sufficient information in the program text to derive a type for a term. Ascriptions are one way to provide the type.* An inferred type may not be the one that was desired for a term.* The expected type of a term is used to drive the insertion of coercions, and ascriptions are one way to control where coercions are inserted.\n\nPostfix Type AscriptionsType ascriptions must be surrounded by parentheses.\nThey indicate that the first term's type is the second term.\n\nIn cases where the term that requires a type ascription is long, such as a tactic proof or a do block, the postfix type ascription with its mandatory parentheses can be difficult to read.\nAdditionally, for both proofs and do blocks, the term's type is essential to its interpretation.\nIn these cases, the prefix versions can be easier to read.\n\nPrefix Type AscriptionsWhen the term in the body of show is a tactic proof, the keyword from may be omitted.\n\nAscribing Statements to ProofsThis example is unable to execute the tactic proof because the desired proposition is not known.\nAs part of running the earlier tactics, the proposition is automatically refined to be one that the tactics could prove.\nHowever, their default cases fill it out incorrectly, leading to a proof that fails.example (n : Nat) := by\n  induction n\n  next => rfl\n  next n' ih =>\n    simp only [HAdd.hAdd, Add.add, Nat.add] at *\n    rewrite [ih]\n    rfl\nInvalid rewrite argument: Expected an equality or iff proof or definition name, but `ih` is a proof of\n  0 ≍ n'\nA prefix type ascription with show can be used to provide the proposition being proved.\nThis can be useful in syntactic contexts where adding it as a local definition would be inconvenient.example (n : Nat) := show 0 + n = n by\n  induction n\n  next => rfl\n  next n' ih =>\n    simp only [HAdd.hAdd, Add.add, Nat.add] at *\n    rewrite [ih]\n    rfl\n\n\nAscribing Types to do BlocksThis example lacks sufficient type information to synthesize the Pure instance.example := do\n  return 5\ntypeclass instance problem is stuck, it is often due to metavariables\n  Pure ?m.64\nA prefix type ascription with show, together with a hole, can be used to indicate the monad.\nThe default OfNat _ 5 instance provides enough type information to fill the hole with Nat.example := show StateM String _ from do\n  return 5\n\n\n","context":"Lean Reference\u0009Terms","header":"10.10. Type Ascription","id":"/Terms/Type-Ascription/#The-Lean-Language-Reference--Terms--Type-Ascription"},"/The--grind--tactic/Case-Analysis/#The-Lean-Language-Reference--The--grind--tactic--Case-Analysis--Selection-Heuristics":{"contents":"grind decides which sub‑term to split on by combining three sources of signal:\n\n Structural flags\n\nThese configuration flags determine whether grind performs certain case splits: splitIte (default true)\n\nEvery if-term should be split, as if by the split tactic.\n\n splitMatch (default true)\n\nEvery match-term should be split, as if by the split tactic.\n\n  splitImp (default false)\n\nHypotheses of the form A → B whose antecedent A is propositional are split by considering all possibilities for A.\n    Arithmetic antecedents are special‑cased: if A is an arithmetic literal (that is, a proposition formed by operators such as ≤, =, ¬, Dvd, …) then grind will split even when splitImp := false so the integer solver can propagate facts.\n\n\n\n Global limits\n\nThe grind option splits := n caps the depth of the search tree.\n  Once a branch performs n splits grind stops splitting further in that branch; if the branch cannot be closed it reports that the split threshold has been reached.\n\n Manual annotations\n\nInductive predicates or structures may be tagged with the grind cases attribute.\n  grind treats every instance of that predicate as a candidate for splitting.\n\n\n\nCase AnalysisThe cases modifier marks inductively-defined predicates as suitable for case splitting.\n\nEager Case AnalysisThe cases eager modifier marks inductively-defined predicates as suitable for case splitting,\nand instructs grind to perform it eagerly while preprocessing hypotheses.\n\nSplitting Conditional ExpressionsIn this example, grind proves the theorem by considering both cases for the conditional:example (c : Bool) (x y : Nat)\n    (h : (if c then x else y) = 0) :\n    x = 0 ∨ y = 0 := by\n  grind\nDisabling splitIte causes the proof to fail:example (c : Bool) (x y : Nat)\n    (h : (if c then x else y) = 0) :\n    x = 0 ∨ y = 0 := by\n  grind -splitIte\nIn particular, it cannot make progress after discovering that the conditional expression is equal to 0:`grind` failed\ncase grind\nc : Bool\nx y : Nat\nh : (if c = true then x else y) = 0\nleft : ¬x = 0\nright : ¬y = 0\n⊢ False\n[grind] Goal diagnostics\n  [facts] Asserted facts\n  [eqc] False propositions\n    [prop] x = 0\n    [prop] y = 0\n  [eqc] Equivalence classes\n    [eqc] others\n      [eqc] {0, if c = true then x else y}\n  [cutsat] Assignment satisfying linear constraints\nForbidding all case splitting causes the proof to fail for the same reason:example (c : Bool) (x y : Nat)\n    (h : (if c then x else y) = 0) :\n    x = 0 ∨ y = 0 := by\n  grind (splits := 0)\n`grind` failed\ncase grind\nc : Bool\nx y : Nat\nh : (if c = true then x else y) = 0\nleft : ¬x = 0\nright : ¬y = 0\n⊢ False\n[grind] Goal diagnostics\n  [facts] Asserted facts\n  [eqc] False propositions\n    [prop] x = 0\n    [prop] y = 0\n  [eqc] Equivalence classes\n    [eqc] others\n      [eqc] {0, if c = true then x else y}\n  [cutsat] Assignment satisfying linear constraints\n  [limits] Thresholds reached\nAllowing just one split is sufficient:example (c : Bool) (x y : Nat)\n    (h : (if c then x else y) = 0) :\n    x = 0 ∨ y = 0 := by\n  grind (splits := 1)\n\n\nSplitting Pattern MatchingDisabling case splitting on pattern matches causes grind to fail in this example:example (h : y = match x with | 0 => 1 | _ => 2) :\n    y > 0 := by\n  grind -splitMatch\n`grind` failed\ncase grind\ny x : Nat\nh : y =\n  match x with\n  | 0 => 1\n  | x => 2\nh_1 : y = 0\n⊢ False\n[grind] Goal diagnostics\n  [facts] Asserted facts\n  [eqc] True propositions\n    [prop] (x = 0 → False) →\n          (match x with\n            | 0 => 1\n            | x => 2) =\n            2\n  [eqc] Equivalence classes\n    [eqc] {y, 0}\n      [eqc] {match x with\n          | 0 => 1\n          | x => 2}\n    [eqc] {x = 0 → False, (fun x_0 => x_0 = 0 → False) x, x = 0 → False}\n  [ematch] E-matching patterns\n  [cutsat] Assignment satisfying linear constraints\n\n[grind] Diagnostics\nEnabling the option causes the proof to succeed:example (h : y = match x with | 0 => 1 | _ => 2) :\n    y > 0 := by\n  grind\n\n\nSplitting PredicatesNot30 is a somewhat verbose way to state that a number is not 30:inductive Not30 : Nat → Prop where\n  | gt : x > 30 → Not30 x\n  | lt : x < 30 → Not30 x\nBy default, grind cannot show that Not30 implies that a number is, in fact, not 30:example : Not30 n → n ≠ 30 := by grind\nThis is because grind does not consider both cases for Not30`grind` failed\ncase grind\nn : Nat\nh : Not30 n\nh_1 : n = 30\n⊢ False\n[grind] Goal diagnostics\n  [facts] Asserted facts\n  [eqc] True propositions\n    [prop] Not30 n\n  [eqc] Equivalence classes\n    [eqc] {n, 30}\n  [cutsat] Assignment satisfying linear constraints\nAdding the grind cases attribute to Not30 allows the proof to succeed:attribute [grind cases] Not30\n\nexample : Not30 n → n ≠ 30 := by grind\nSimilarly, the grind cases attribute on Even allows grind to perform case splits:@[grind cases]\ninductive Even : Nat → Prop\n  | zero : Even 0\n  | step : Even n → Even (n + 2)\n\nattribute [grind cases] Even\n\nexample (h : Even 5) : False := by\n  grind\n\nset_option trace.grind.split true in\nexample (h : Even (n + 2)) : Even n := by\n  grind\n\n\n","context":"Lean Reference\u0009The  grind  tactic\u0009Case Analysis","header":"17.5.1. Selection Heuristics","id":"/The--grind--tactic/Case-Analysis/#The-Lean-Language-Reference--The--grind--tactic--Case-Analysis--Selection-Heuristics"},"/releases/v4.11.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___11___0-_LPAR_2024-09-02_RPAR_--Compiler___-runtime___-and-FFI":{"contents":"* #4661 moves Std from libleanshared to much smaller libInit_shared. This fixes the Windows build.* #4668 fixes initialization, explicitly initializing Std in lean_initialize.* #4746 adjusts shouldExport to exclude more symbols to get below Windows symbol limit. Some exceptions are added by #4884 and #4956 to support Verso.* #4778 adds lean_is_exclusive_obj (Lean.isExclusiveUnsafe) and lean_set_external_data.* #4515 fixes calling programs with spaces on Windows.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.11.0 (2024-09-02)","header":"Compiler, runtime, and FFI","id":"/releases/v4.11.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___11___0-_LPAR_2024-09-02_RPAR_--Compiler___-runtime___-and-FFI"},"/releases/v4.14.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___14___0-_LPAR_2024-12-02_RPAR_--Compiler___-runtime___-and-FFI":{"contents":"* #5685 fixes help message flags, removes the -f flag and adds the -g flag (@James-Oswald).* #5930 adds --short-version (-V) option to display short version (@juhp).* #5144 switches all 64-bit platforms over to consistently using GMP for bignum arithmetic.* #5753 raises the minimum supported Windows version to Windows 10 1903 (released May 2019).\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.14.0 (2024-12-02)","header":"Compiler, runtime, and FFI","id":"/releases/v4.14.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___14___0-_LPAR_2024-12-02_RPAR_--Compiler___-runtime___-and-FFI"},"/releases/v4.17.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___17___0-_LPAR_2025-03-03_RPAR_--Highlights--New-CLI-Features":{"contents":"* #6427 adds the Lean CLI option --src-deps which parallels --deps.\nIt parses the Lean code's header and prints out the paths to the\n(transitively) imported modules' source files (deduced from\nLEAN_SRC_PATH).* #6323 adds a new Lake CLI command, lake query, that both builds\ntargets and outputs their results. It can produce raw text or JSON\n-formatted output (with --json / -J).\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.17.0 (2025-03-03)\u0009Highlights","header":"New CLI Features","id":"/releases/v4.17.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___17___0-_LPAR_2025-03-03_RPAR_--Highlights--New-CLI-Features"},"/releases/v4.17.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___17___0-_LPAR_2025-03-03_RPAR_--Pretty-Printing":{"contents":"* #6703 modifies the delaborator so that in pp.tagAppFns mode,\ngeneralized field notation is tagged with the head constant. The effect\nis that docgen documentation will linkify dot notation. Internal change:\nnow formatted rawIdent can be tagged.* #6716 renames the option infoview.maxTraceChildren to\nmaxTraceChildren and applies it to the cmdline driver and language\nserver clients lacking an info view as well. It also implements the\ncommon idiom of the option value 0 meaning \"unlimited\".* #6729 makes the pretty printer for .coeFun-tagged functions respect\npp.tagAppFns. The effect is that in docgen, when an expression pretty\nprints as f x y z with f a coerced function, then if f is a\nconstant it will be linkified.* #6730 changes how app unexpanders are invoked. Before the ref was\n.missing, but now the ref is the head constant's delaborated syntax.\nThis way, when pp.tagAppFns is true, then tokens in app unexpanders\nare annotated with the head constant. The consequence is that in docgen,\ntokens will be linkified. This new behavior is consistent with how\nnotation defines app unexpanders.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.17.0 (2025-03-03)","header":"Pretty Printing","id":"/releases/v4.17.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___17___0-_LPAR_2025-03-03_RPAR_--Pretty-Printing"}});