window.docContents[233].resolve({"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Dependent-Tree-Based-Maps--Unbundled-Variants":{"contents":"Unbundled maps separate well-formedness proofs from data.\nThis is primarily useful when defining nested inductive types.\nTo use these variants, import the module Std.DTreeMap.Raw.\n\nDependent tree maps without a bundled well-formedness invariant, suitable for use in nested\ninductive types. The well-formedness invariant is called Raw.WF. When in doubt, prefer DTreeMap\nover DTreeMap.Raw. Lemmas about the operations on Std.DTreeMap.Raw are available in the\nmodule Std.Data.DTreeMap.Raw.Lemmas.A tree map stores an assignment of keys to values. It depends on a comparator function that\ndefines an ordering on the keys and provides efficient order-dependent queries, such as retrieval\nof the minimum or maximum.To ensure that the operations behave as expected, the comparator function cmp should satisfy\ncertain laws that ensure a consistent ordering:* If a is less than (or equal) to b, then b is greater than (or equal) to a\nand vice versa (see the OrientedCmp typeclass).* If a is less than or equal to b and b is, in turn, less than or equal to c, then a\nis less than or equal to c (see the TransCmp typeclass).Keys for which cmp a b = Ordering.eq are considered the same, i.e., there can be only one entry\nwith key either a or b in a tree map. Looking up either a or b always yields the same entry,\nif any is present. The get operations of the dependent tree map additionally require a\nLawfulEqCmp instance to ensure that cmp a b = .eq always implies a = b, so that their\nrespective value types are equal.To avoid expensive copies, users should make sure that the tree map is used linearly.Internally, the tree maps are represented as size-bounded trees, a type of self-balancing binary\nsearch tree with efficient order statistic lookups.Internal implementation detail of the tree map.\n\nWell-formedness predicate for tree maps. Users of DTreeMap will not need to interact with\nthis. Users of DTreeMap.Raw will need to provide proofs of WF to lemmas and should use lemmas\nlike WF.empty and WF.insert (which are always named exactly like the operations they are about)\nto show that map operations preserve well-formedness. The constructors of this type are internal\nimplementation details and should not be accessed by users.Internal implementation detail of the tree map.\n\n","context":"Lean Reference\u0009Basic Types\u0009Maps and Sets\u0009Dependent Tree-Based Maps","header":"19.18.9.7. Unbundled Variants","id":"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Dependent-Tree-Based-Maps--Unbundled-Variants"},"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Extensional-Hash-Sets--Properties":{"contents":"Returns true if the hash set contains no elements.Note that if your BEq instance is not reflexive or your Hashable instance is not\nlawful, then it is possible that this function returns false even though m.contains a = false\nfor all a.\n\nThe number of elements present in the set\n\n","context":"Lean Reference\u0009Basic Types\u0009Maps and Sets\u0009Extensional Hash Sets","header":"19.18.7.2. Properties","id":"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Extensional-Hash-Sets--Properties"},"/Coercions/Coercing-Between-Types/#coercion-impl":{"contents":"The appropriate CoeHead, CoeOut, Coe, or CoeTail instance is sufficient to cause a desired coercion to be inserted.\nHowever, the implementation of the coercion should be registered as a coercion using the coe attribute.\nThis causes Lean to display uses of the coercion with the ↑ operator.\nIt also causes the norm_cast tactic to treat the coercion as a cast, rather than as an ordinary function.\n\nCoercion DeclarationsThe @[coe] attribute on a function (which should also appear in a\ninstance : Coe A B := ⟨myFn⟩ declaration) allows the delaborator to show\napplications of this function as ↑ when printing expressions.\n\nImplementing CoercionsThe enum inductive type Weekday represents the days of the week:inductive Weekday where\n  | mo | tu | we | th | fr | sa | su\nAs a seven-element type, it contains the same information as Fin 7.\nThere is a bijection:def Weekday.toFin : Weekday → Fin 7\n  | mo => 0\n  | tu => 1\n  | we => 2\n  | th => 3\n  | fr => 4\n  | sa => 5\n  | su => 6\n\ndef Weekday.fromFin : Fin 7 → Weekday\n  | 0 => mo\n  | 1 => tu\n  | 2 => we\n  | 3 => th\n  | 4 => fr\n  | 5 => sa\n  | 6 => su\nEach type can be coerced to the other:instance : Coe Weekday (Fin 7) where\n  coe := Weekday.toFin\n\ninstance : Coe (Fin 7) Weekday where\n  coe := Weekday.fromFin\nWhile this works, instances of the coercions that occur in Lean's output are not presented using the coercion operator, which is what Lean users expect.\nInstead, the name Weekday.fromFin is used explicitly:def wednesday : Weekday := (2 : Fin 7)\n\n#print wednesday\ndef wednesday : Weekday :=\nWeekday.fromFin 2\nAdding the coe attribute to the definition of a coercion causes it to be displayed using the coercion operator:attribute [coe] Weekday.fromFin\nattribute [coe] Weekday.toFin\n\ndef friday : Weekday := (5 : Fin 7)\n\n#print friday\ndef friday : Weekday :=\n↑5\n\n\n","context":"Lean Reference\u0009Coercions\u0009Coercing Between Types","header":"12.2.1. Implementing Coercions","id":"/Coercions/Coercing-Between-Types/#coercion-impl"},"/The--grind--tactic/Bigger-Examples/#The-Lean-Language-Reference--The--grind--tactic--Bigger-Examples--IndexMap":{"contents":"In this section we'll build an example of a new data structure and basic API for it, illustrating the use of grind.\nThe example will be derived from Rust's indexmap data structure.\n\n is intended as a replacement for HashMap (in particular, it has fast hash-based lookup), but allowing the user to maintain control of the order of the elements.\nWe won't give a complete API, just set up some basic functions and theorems about them.\n\nThe two main functions we'll implement for now are  and :\n\n* insert k v checks if k is already in the map. If so, it replaces the value with v, keeping k in the same position in the ordering.\n  If it is not already in the map, insert adds (k, v) to the end of the map.* eraseSwap k removes the element with key k from the map, and swaps it with the last element of the map (or does nothing if k is not in the map).\n  (This behavior may be surprising: this function exists because it is an efficient way to an erase element when you don't care about the order of the remaining elements.\n  Another function, not implemented here, would preserve the order of the remaining elements, but at the cost of running in time proportional to the number of elements after the erased element.)\n\nOur goals will be:\n\n Complete encapsulation\n\nThe implementation of  is hidden from the users, and the theorems about the implementation details are private.\n\n Use grind as much as possible\n\nWe'll prefer adding a private theorem and annotating it with @[grind] over writing a longer proof whenever practical.\n\n Use auto-parameters as much as possible\n\nIdeally, we don't even need to see the proofs; they should mostly be handled invisibly by grind.\n\n\n\nTo begin with, we'll write out a skeleton of what we want to achieve, liberally using sorry as a placeholder for all proofs.\nIn particular, this version makes no use of grind.\n\n\n\nLet's get started.\nWe'll aspire to never writing a proof by hand, and the first step of that is to install auto-parameters for the size_keys and WF field,\nso we can omit these fields whenever grind can prove them.\nWhile we're modifying the definition of IndexMap itself, lets make all the fields private, since we're planning on having complete encapsulation.\n\n\n\nLet's give grind access to the definition of size, and size_keys private field:\n\n\n\nOur first sorrys in the draft version are the  and  fields in our construction of .\nSurely these are trivial, and solvable by grind, so we simply delete those fields:\n\nOur next task is to deal with the sorry in our construction of the original  instance:\n\n\n\nThe goal at this sorry is\n\nm : IndexMap α β\na : α\nh : a ∈ m\n⊢ m.indices[a] < m.values.size\n\n\nLet's try proving this as a stand-alone theorem, via grind, and see where grind gets stuck.\nBecause we've added grind annotations for  and  already, we can safely reformulate the goal as:\n\n\n\nThis fails, and looking at the Goal diagnostics section of the message from grind we see that it hasn't done much:\n\n\n\nAn immediate problem we can see here is that\ngrind does not yet know that a ∈ m is the same as a ∈ m.indices.\nLet's add this fact:\n\n\n\nHowever this proof is going to work, we know the following:* It must use the well-formedness condition of the map.* It can't do so without relating m.indices[a] and m.indices[a]? (because the later is what appears in the well-formedness condition).* The expected relationship there doesn't even hold unless the map m.indices satisfies LawfulGetElem,\n  for which we need instances of LawfulBEq α and LawfulHashable α.\n\nLet's configure things so that those are available:and then give grind one manual hint, to relate  and :\n\nWith that theorem proved, we want to make it accessible to grind.\nWe could either add @[local grind] before the theorem statement,\nor write attribute [local grind] getElem_indices_lt after the theorem statement.\nThese will use grind's built-in heuristics for deciding a pattern to match the theorem on.\n\nIn this case, let's see which patterns the grind attribute generates:These patterns are not useful.\nThe first is matching on the entire conclusion of the theorem (in fact, a normalized version of it, in which x < y has been replaced by x + 1 ≤ y).\nThe second is too general: it will match any term that includes the theorem's assumptions, ignoring the conclusion.\n\nWe want something more general than the entire conclusion, the conclusion should not be ignored.\nWe'd like this theorem to fire whenever grind sees , and so instead of using the attribute we write a custom pattern:\n\nThe Lean standard library uses the get_elem_tactic tactic as an auto-parameter for the xs[i] notation\n(which desugars to GetElem.getElem xs i h, with the proof h generated by get_elem_tactic).\nWe'd like to not only have grind fill in these proofs, but even to be able to omit these proofs.\nTo achieve this, we add the line(In later versions of Lean this may be part of the built-in behavior.)\n\nWe can now return to constructing our  instance, and simply write:with neither any sorrys, nor any explicitly written proofs.\n\nNext, we want to expose the content of these definitions, but only locally in this file:Again we're using the  pattern to hide these implementation details,\nbut allow grind to see these facts locally.\n\nNext, we want to prove the  instance, and hope that grind can fill in the proofs:Success!\n\nLet's press onward, and see if we can define  without having to write any proofs:In both branches, grind is automatically proving both the  and  fields!\nNote also in the first branch the  calls  and \nare having their “in-bounds” obligations automatically filled in by grind via the get_elem_tactic auto-parameter.\n\nNext let's try eraseSwap:This fails while attempting to prove the  field in the second branch.\nAs usual, there is detailed information from grind about its failure state, but almost too much to be helpful!\nLet's look at the model produced by cutsat and see if we can see what's going on:This model consists of an  of size 3,\nwith keys a_1, a_2 and the otherwise unnamed (keys m_1).back ⋯.\n\nEverything looks fine, except the line:(((indices m_1).erase a_1).insert ((keys m_1).back ⋯) i_1)[a_2] := 0\nThis shouldn't be possible! Since the three keys are distinct,\nwe should have(((indices m_1).erase a_1).insert ((keys m_1).back ⋯) i_1)[a_2] =\n  ((indices m_1).erase a_1)[a_2] =\n  (indices m_1)[a_2] =\n  1\nNow that we've found something suspicious, we can look through the equivalence classes identified by grind.\n(In the future we'll be providing search tools for inspecting equivalence classes, but for now you need to read through manually.)\nWe find amongst many others:{a_2,\n  (keys m_1).back ⋯,\n  (keys m_1)[(keys m_1).size - 1],\n  (keys m_1)[i_2], ...}\nThis should imply, by the injectivity of , that i_2 = (keys m_1).size - 1.\nSince this identity wasn't reflected by the cutsat model,\nwe suspect that grind is not managing to use the injectivity of .\n\nThinking about the way that we've provided the well-formedness condition, as\n∀ (i : Nat) (a : α), keys[i]? = some a ↔ indices[a]? = some i, this perhaps isn't surprising:\nit's expressed in terms of keys[i]? and indices[a]?.\nLet's add a variant version of the well-formedness condition using getElem instead of getElem?:\n\n\n\nWe can verify that with this available, grind can now prove:\n\n\n\nTrying again with , everything goes through cleanly now, with no manual proofs:\n\n\n\nFinally we turn to the verification theorems about the basic operations, relating , , and .\nBy adding a  annotation allowing grind to unfold the definitions of these operations,\nthe proofs all go through effortlessly:\n\n\n\nNote that these are part of the public API of , so we need to mark them as @[grind],\nso that users without our internal local grind annotations can still use them in grind proofs.\n\nPutting this all together, our prototype API has reached the following state:\n\n\n\nmacro_rules | `(tactic| get_elem_tactic_extensible) => `(tactic| grind)\n\nopen Std\n\nstructure IndexMap\n    (α : Type u) (β : Type v) [BEq α] [Hashable α] where\n  private indices : HashMap α Nat\n  private keys : Array α\n  private values : Array β\n  private size_keys' : keys.size = values.size := by grind\n  private WF : ∀ (i : Nat) (a : α),\n    keys[i]? = some a ↔ indices[a]? = some i := by grind\n\nnamespace IndexMap\n\nvariable {α : Type u} {β : Type v} [BEq α] [Hashable α]\nvariable {m : IndexMap α β} {a : α} {b : β} {i : Nat}\n\n@[inline] def size (m : IndexMap α β) : Nat :=\n  m.values.size\n\n@[local grind =] private theorem size_keys : m.keys.size = m.size :=\n  m.size_keys'\n\ndef emptyWithCapacity (capacity := 8) : IndexMap α β where\n  indices := HashMap.emptyWithCapacity capacity\n  keys := Array.emptyWithCapacity capacity\n  values := Array.emptyWithCapacity capacity\n\ninstance : EmptyCollection (IndexMap α β) where\n  emptyCollection := emptyWithCapacity\n\ninstance : Inhabited (IndexMap α β) where\n  default := ∅\n\n@[inline] def contains (m : IndexMap α β)\n    (a : α) : Bool :=\n  m.indices.contains a\n\ninstance : Membership α (IndexMap α β) where\n  mem m a := a ∈ m.indices\n\ninstance {m : IndexMap α β} {a : α} : Decidable (a ∈ m) :=\n  inferInstanceAs (Decidable (a ∈ m.indices))\n\n@[local grind] private theorem mem_indices_of_mem\n    {m : IndexMap α β} {a : α} :\n    a ∈ m ↔ a ∈ m.indices := Iff.rfl\n\n@[inline] def findIdx? (m : IndexMap α β) (a : α) : Option Nat :=\n  m.indices[a]?\n\n@[inline] def findIdx (m : IndexMap α β) (a : α)\n    (h : a ∈ m := by get_elem_tactic) : Nat :=\n  m.indices[a]\n\n@[inline] def getIdx? (m : IndexMap α β) (i : Nat) : Option β :=\n  m.values[i]?\n\n@[inline] def getIdx (m : IndexMap α β) (i : Nat)\n    (h : i < m.size := by get_elem_tactic) : β :=\n  m.values[i]\n\nvariable [LawfulBEq α] [LawfulHashable α]\n\nattribute [local grind _=_] IndexMap.WF\n\nprivate theorem getElem_indices_lt {h : a ∈ m} : m.indices[a] < m.size := by\n  have : m.indices[a]? = some m.indices[a] := by grind\n  grind\n\ngrind_pattern getElem_indices_lt => m.indices[a]\n\nattribute [local grind] size\n\ninstance : GetElem? (IndexMap α β) α β (fun m a => a ∈ m) where\n  getElem m a h :=\n    m.values[m.indices[a]]\n  getElem? m a :=\n    m.indices[a]?.bind (fun i => (m.values[i]?))\n  getElem! m a :=\n    m.indices[a]?.bind (fun i => (m.values[i]?)) |>.getD default\n\n@[local grind] private theorem getElem_def\n    (m : IndexMap α β) (a : α) (h : a ∈ m) :\n    m[a] = m.values[m.indices[a]'h] :=\n  rfl\n@[local grind] private theorem getElem?_def\n    (m : IndexMap α β) (a : α) :\n    m[a]? = m.indices[a]?.bind (fun i => (m.values[i]?)) :=\n  rfl\n@[local grind] private theorem getElem!_def\n    [Inhabited β] (m : IndexMap α β) (a : α) :\n    m[a]! = (m.indices[a]?.bind (m.values[·]?)).getD default :=\n  rfl\n\ninstance : LawfulGetElem (IndexMap α β) α β (fun m a => a ∈ m) where\n  getElem?_def := by grind\n  getElem!_def := by grind\n\n@[inline] def insert [LawfulBEq α] (m : IndexMap α β) (a : α) (b : β) :\n    IndexMap α β :=\n  match h : m.indices[a]? with\n  | some i =>\n    { indices := m.indices\n      keys := m.keys.set i a\n      values := m.values.set i b }\n  | none =>\n    { indices := m.indices.insert a m.size\n      keys := m.keys.push a\n      values := m.values.push b }\n\ninstance [LawfulBEq α] : Singleton (α × β) (IndexMap α β) :=\n    ⟨fun ⟨a, b⟩ => (∅ : IndexMap α β).insert a b⟩\n\ninstance [LawfulBEq α] : Insert (α × β) (IndexMap α β) :=\n    ⟨fun ⟨a, b⟩ s => s.insert a b⟩\n\ninstance [LawfulBEq α] : LawfulSingleton (α × β) (IndexMap α β) :=\n    ⟨fun _ => rfl⟩\n\n@[local grind] private theorem WF'\n    (i : Nat) (a : α) (h₁ : i < m.keys.size) (h₂ : a ∈ m) :\n    m.keys[i] = a ↔ m.indices[a] = i := by\n  have := m.WF i a\n  grind\n\n/--\nErase the key-value pair with the given key,\nmoving the last pair into its place in the order.\nIf the key is not present, the map is unchanged.\n-/\n@[inline] def eraseSwap (m : IndexMap α β) (a : α) : IndexMap α β :=\n  match h : m.indices[a]? with\n  | some i =>\n    if w : i = m.size - 1 then\n      { indices := m.indices.erase a\n        keys := m.keys.pop\n        values := m.values.pop }\n    else\n      let lastKey := m.keys.back\n      let lastValue := m.values.back\n      { indices := (m.indices.erase a).insert lastKey i\n        keys := m.keys.pop.set i lastKey\n        values := m.values.pop.set i lastValue }\n  | none => m\n\n/-! ### Verification theorems -/\n\nattribute [local grind] getIdx findIdx insert\n\n@[grind] theorem getIdx_findIdx (m : IndexMap α β) (a : α) (h : a ∈ m) :\n    m.getIdx (m.findIdx a) = m[a] := by grind\n\n@[grind] theorem mem_insert (m : IndexMap α β) (a a' : α) (b : β) :\n    a' ∈ m.insert a b ↔ a' = a ∨ a' ∈ m := by\n  grind\n\n@[grind] theorem getElem_insert\n    (m : IndexMap α β) (a a' : α) (b : β) (h : a' ∈ m.insert a b) :\n    (m.insert a b)[a'] = if h' : a' == a then b else m[a'] := by\n  grind\n\n@[grind] theorem findIdx_insert_self\n    (m : IndexMap α β) (a : α) (b : β) :\n    (m.insert a b).findIdx a =\n      if h : a ∈ m then m.findIdx a else m.size := by\n  grind\n\nend IndexMap\n\n\nWe haven't yet proved all the theorems we would want about these operations (or indeed any theorems about ); the interested reader is encouraged to try proving more,\nand perhaps even releasing a complete  library!\n\nSummarizing the design principles discussed above about encapsulation:\n\n* the fields of  are all private, as these are implementation details.* the theorems about these fields are all private, and marked as @[local grind], rather than @[grind], as they won't be needed after we've set up the API.* the verification theorems are both marked as @[grind], and proved by grind:\n  the annotation is necessary because we want grind to be able to prove these facts even once we're outside the current module, and the @[local grind] theorems are no longer available.\n\n\n","context":"Lean Reference\u0009The  grind  tactic\u0009Bigger Examples","header":"17.10.3. IndexMap","id":"/The--grind--tactic/Bigger-Examples/#The-Lean-Language-Reference--The--grind--tactic--Bigger-Examples--IndexMap"}});