window.docContents[106].resolve({"/Basic-Types/Characters/#The-Lean-Language-Reference--Basic-Types--Characters--API-Reference--Conversions":{"contents":"Converts a Nat into a Char. If the Nat does not encode a valid Unicode scalar value, '\\0' is\nreturned instead.\n\nThe character's Unicode code point as a Nat.\n\nTrue for natural numbers that are valid Unicode scalar\nvalues.\n\nConverts an 8-bit unsigned integer into a character.The integer's value is interpreted as a Unicode code point.\n\nConverts a character into a UInt8 that contains its code point.If the code point is larger than 255, it is truncated (reduced modulo 256).\n\nThere are two ways to convert a character to a string.\nChar.toString converts a character to a singleton string that consists of only that character, while Char.quote converts the character to a string representation of the corresponding character literal.\n\nConstructs a singleton string that contains only the provided character.Examples:* 'L'.toString = \"L\"* '\"'.toString = \"\\\"\"\n\nQuotes the character to its representation as a character literal, surrounded by single quotes and\nescaped as necessary.Examples:* 'L'.quote = \"'L'\"* '\"'.quote = \"'\\\\\\\"'\"\n\nFrom Characters to StringsChar.toString produces a string that contains only the character in question:#eval 'e'.toString\n\"e\"\n#eval '\\x65'.toString\n\"e\"\n#eval '\"'.toString\n\"\\\"\"\nChar.quote produces a string that contains a character literal, suitably escaped:#eval 'e'.quote\n\"'e'\"\n#eval '\\x65'.quote\n\"'e'\"\n#eval '\"'.quote\n\"'\\\\\\\"'\"\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Characters\u0009API Reference","header":"19.7.4.1. Conversions","id":"/Basic-Types/Characters/#The-Lean-Language-Reference--Basic-Types--Characters--API-Reference--Conversions"},"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Dependent-Hash-Maps--Iteration":{"contents":"Updates the values of the hash map by applying the given function to all mappings.\n\nFolds the given function over the mappings in the hash map in some order.\n\nMonadically computes a value by folding the given function over the mappings in the hash\nmap in some order.\n\nSupport for the for loop construct in do blocks.\n\nCarries out a monadic action on each mapping in the hash map in some order.\n\n","context":"Lean Reference\u0009Basic Types\u0009Maps and Sets\u0009Dependent Hash Maps","header":"19.18.3.5. Iteration","id":"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Dependent-Hash-Maps--Iteration"},"/Definitions/Recursive-Definitions/#The-Lean-Language-Reference--Definitions--Recursive-Definitions--Well-Founded-Recursion--Termination-proofs":{"contents":"Once a measure is specified and its well-founded relation is determined, Lean determines the termination proof obligation for every recursive call.\n\n\n\nThe proof obligation for each recursive call is of the form g a₁ a₂ … ≺ g p₁ p₂ …, where:\n\n* g is the measure as a function of the parameters,* ≺ is the inferred well-founded relation,* a₁ a₂ … are the arguments of the recursive call and* p₁ p₂ … are the parameters of the function definition.\n\nThe context of the proof obligation is the local context of the recursive call.\nIn particular, local assumptions (such as those introduced by if h : _, match h : _ with  or have) are available.\nIf a function parameter is the discriminant of a pattern match (e.g. by a match expression), then this parameter is refined to the matched pattern in the proof obligation.\n\n\n\nThe overall termination proof obligation consists of one goal for each recursive call.\nBy default, the tactic decreasing_trivial is used to prove each proof obligation.\nA custom tactic script can be provided using the optional decreasing_by clause, which comes after the termination_by clause.\nThis tactic script is run once, with one goal for each proof obligation, rather than separately on each proof obligation.\n\n\n\nTermination Proof ObligationsThe following recursive definition of the Fibonacci numbers has two recursive calls, which results in two goals in the termination proof.def fib (n : Nat) :=\n  if h : n ≤ 1 then\n    1\n  else\n    fib (n - 1) + fib (n - 2)\ntermination_by n\ndecreasing_by\n  skip\nn : Nat\nh : ¬n ≤ 1\n⊢ n - 1 < n\n\nn : Nat\nh : ¬n ≤ 1\n⊢ n - 2 < nHere, the measure is simply the parameter itself, and the well-founded order is the less-than relation on natural numbers.\nThe first proof goal requires the user to prove that the argument of the first recursive call, namely n - 1, is strictly smaller than the function's parameter, n.Both termination proofs can be easily discharged using the omega tactic.def fib (n : Nat) :=\n  if h : n ≤ 1 then\n    1\n  else\n    fib (n - 1) + fib (n - 2)\ntermination_by n\ndecreasing_by\n  · omega\n  · omega\n\n\n\n\nRefined ParametersIf a parameter of the function is the discriminant of a pattern match, then the proof obligations mention the refined parameter.def fib : Nat → Nat\n  | 0 | 1 => 1\n  | .succ (.succ n) => fib (n + 1) + fib n\ntermination_by n => n\ndecreasing_by\n  skip\nn : Nat\n⊢ n + 1 < n.succ.succ\n\nn : Nat\n⊢ n < n.succ.succ\n\nAdditionally, the context is enriched with additional assumptions that can make it easier to prove termination.\nSome examples include:* In the branches of an if-then-else expression, a hypothesis that asserts the current branch's condition is added, much as if the dependent if-then-else syntax had been used.* In the function argument to certain higher-order functions, the context of the function's body is enriched with assumptions about the argument.This list is not exhaustive, and the mechanism is extensible.\nIt is described in detail in the section on preprocessing.\n\n\n\nEnriched Proof Obligation ContextsHere, the if does not add a local assumption about the condition (that is, whether n ≤ 1) to the local contexts in the branches.def fib (n : Nat) :=\n  if n ≤ 1 then\n    1\n  else\n    fib (n - 1) + fib (n - 2)\ntermination_by n\ndecreasing_by\n  skip\nNevertheless, the assumptions are available in the context of the termination proof:n : Nat\nh✝ : ¬n ≤ 1\n⊢ n - 1 < n\n\nn : Nat\nh✝ : ¬n ≤ 1\n⊢ n - 2 < nTermination proof obligations in body of a for​…​in loop are also enriched, in this case with a Std.Range membership hypothesis:def f (xs : Array Nat) : Nat := Id.run do\n  let mut s := xs.sum\n  for i in [:xs.size] do\n    s := s + f (xs.take i)\n  pure s\ntermination_by xs\ndecreasing_by\n  skip\nxs : Array Nat\ni : Nat\nh✝ : i ∈ [:xs.size]\n⊢ sizeOf (xs.take i) < sizeOf xsSimilarly, in the following (contrived) example, the termination proof contains an additional assumption showing that x ∈ xs.def f (n : Nat) (xs : List Nat) : Nat :=\n  List.sum (xs.map (fun x => f x []))\ntermination_by xs\ndecreasing_by\n  skip\nn : Nat\nxs : List Nat\nx : Nat\nh✝ : x ∈ xs\n⊢ sizeOf [] < sizeOf xsThis feature requires special setup for the higher-order function under which the recursive call is nested, as described in the section on preprocessing.\nIn the following definition, identical to the one above except using a custom, equivalent function instead of List.map, the proof obligation context is not enriched:def List.myMap := @List.map\ndef f (n : Nat) (xs : List Nat) : Nat :=\n  List.sum (xs.myMap (fun x => f x []))\ntermination_by xs\ndecreasing_by\n  skip\nn : Nat\nxs : List Nat\nx : Nat\n⊢ sizeOf [] < sizeOf xs\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Definitions\u0009Recursive Definitions\u0009Well-Founded Recursion","header":"7.6.3.2. Termination proofs","id":"/Definitions/Recursive-Definitions/#The-Lean-Language-Reference--Definitions--Recursive-Definitions--Well-Founded-Recursion--Termination-proofs"},"/Notations-and-Macros/Elaborators/#The-Lean-Language-Reference--Notations-and-Macros--Elaborators--Custom-Tactics":{"contents":"Custom tactics are described in the section on tactics.\n\n\n","context":"Lean Reference\u0009Notations and Macros\u0009Elaborators","header":"20.6.3. Custom Tactics","id":"/Notations-and-Macros/Elaborators/#The-Lean-Language-Reference--Notations-and-Macros--Elaborators--Custom-Tactics"},"/Tactic-Proofs/#tactics":{"contents":"The tactic language is a special-purpose programming language for constructing proofs.\nIn Lean, propositions are represented by types, and proofs are terms that inhabit these types.\nThe section on propositions describes propositions in more detail.\nWhile terms are designed to make it convenient to indicate a specific inhabitant of a type, tactics are designed to make it convenient to demonstrate that a type is inhabited.\nThis distinction exists because it's important that definitions pick out the precise objects of interest and that programs return the intended results, but proof irrelevance means that there's no technical reason to prefer one proof term over another.\nFor example, given two assumptions of a given type, a program must be carefully written to use the correct one, while a proof may use either without consequence.\n\nTactics are imperative programs that modify a proof state.\nA proof state consists of an ordered sequence of goals, which are contexts of local assumptions together with types to be inhabited; a tactic may either succeed with a possibly-empty sequence of further goals (called subgoals) or fail if it cannot make progress.\nIf a tactic succeeds with no subgoals, then the proof is complete.\nIf it succeeds with one or more subgoals, then its goal or goals will be proved when those subgoals have been proved.\nThe first goal in the proof state is called the main goal.\nWhile most tactics affect only the main goal, operators such as <;> and all_goals can be used to apply a tactic to many goals, and operators such as bullets, next or case can narrow the focus of subsequent tactics to only a single goal in the proof state.\n\nBehind the scenes, tactics construct proof terms.\nProof terms are independently checkable evidence of a theorem's truth, written in Lean's type theory.\nEach proof is checked in the kernel, and can be verified with independently-implemented external checkers, so the worst outcome from a bug in a tactic is a confusing error message, rather than an incorrect proof.\nEach goal in a tactic proof corresponds to an incomplete portion of a proof term.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference","header":"13. Tactic Proofs","id":"/Tactic-Proofs/#tactics"},"/Tactic-Proofs/Tactic-Reference/#The-Lean-Language-Reference--Tactic-Proofs--Tactic-Reference--SMT-Inspired-Automation":{"contents":"grind is a tactic inspired by modern SMT solvers. Picture a virtual whiteboard:\nevery time grind discovers a new equality, inequality, or logical fact,\nit writes it on the board, groups together terms known to be equal,\nand lets each reasoning engine read from and contribute to the shared workspace.\nThese engines work together to handle equality reasoning, apply known theorems,\npropagate new facts, perform case analysis, and run specialized solvers\nfor domains like linear arithmetic and commutative rings.grind is not designed for goals whose search space explodes combinatorially,\nthink large pigeonhole instances, graph‑coloring reductions, high‑order N‑queens boards,\nor a 200‑variable Sudoku encoded as Boolean constraints.  Such encodings require\nthousands (or millions) of case‑splits that overwhelm grind’s branching search.For bit‑level or combinatorial problems, consider using bv_decide.\nbv_decide calls a state‑of‑the‑art SAT solver (CaDiCaL) and then returns a\ncompact, machine‑checkable certificate.Equality reasoninggrind uses congruence closure to track equalities between terms.\nWhen two terms are known to be equal, congruence closure automatically deduces\nequalities between more complex expressions built from them.\nFor example, if a = b, then congruence closure will also conclude that f a = f b\nfor any function f. This forms the foundation for efficient equality reasoning in grind.\nHere is an example:example (f : Nat → Nat) (h : a = b) : f (f b) = f (f a) := by\n  grind\nApplying theorems using E-matchingTo apply existing theorems, grind uses a technique called E-matching,\nwhich finds matches for known theorem patterns while taking equalities into account.\nCombined with congruence closure, E-matching helps grind discover\nnon-obvious consequences of theorems and equalities automatically.Consider the following functions and theorems:def f (a : Nat) : Nat :=\n  a + 1\n\ndef g (a : Nat) : Nat :=\n  a - 1\n\n@[grind =]\ntheorem gf (x : Nat) : g (f x) = x := by\n  simp [f, g]\nThe theorem gf asserts that g (f x) = x for all natural numbers x.\nThe attribute [grind =] instructs grind to use the left-hand side of the equation,\ng (f x), as a pattern for E-matching.\nSuppose we now have a goal involving:example {a b} (h : f b = a) : g a = b := by\n  grind\nAlthough g a is not an instance of the pattern g (f x),\nit becomes one modulo the equation f b = a. By substituting a\nwith f b in g a, we obtain the term g (f b),\nwhich matches the pattern g (f x) with the assignment x := b.\nThus, the theorem gf is instantiated with x := b,\nand the new equality g (f b) = b is asserted.\ngrind then uses congruence closure to derive the implied equality\ng a = g (f b) and completes the proof.The pattern used to instantiate theorems affects the effectiveness of grind.\nFor example, the pattern g (f x) is too restrictive in the following case:\nthe theorem gf will not be instantiated because the goal does not even\ncontain the function symbol g.example (h₁ : f b = a) (h₂ : f c = a) : b = c := by\n  grind\nYou can use the command grind_pattern to manually select a pattern for a given theorem.\nIn the following example, we instruct grind to use f x as the pattern,\nallowing it to solve the goal automatically:grind_pattern gf => f x\n\nexample {a b c} (h₁ : f b = a) (h₂ : f c = a) : b = c := by\n  grind\nYou can enable the option trace.grind.ematch.instance to make grind print a\ntrace message for each theorem instance it generates.You can also specify a multi-pattern to control when grind should apply a theorem.\nA multi-pattern requires that all specified patterns are matched in the current context\nbefore the theorem is applied. This is useful for theorems such as transitivity rules,\nwhere multiple premises must be simultaneously present for the rule to apply.\nThe following example demonstrates this feature using a transitivity axiom for a binary relation R:opaque R : Int → Int → Prop\naxiom Rtrans {x y z : Int} : R x y → R y z → R x z\n\ngrind_pattern Rtrans => R x y, R y z\n\nexample {a b c d} : R a b → R b c → R c d → R a d := by\n  grind\nBy specifying the multi-pattern R x y, R y z, we instruct grind to\ninstantiate Rtrans only when both R x y and R y z are available in the context.\nIn the example, grind applies Rtrans to derive R a c from R a b and R b c,\nand can then repeat the same reasoning to deduce R a d from R a c and R c d.Instead of using grind_pattern to explicitly specify a pattern,\nyou can use the @[grind] attribute or one of its variants, which will use a heuristic to\ngenerate a (multi-)pattern. The complete list is available in the reference manual. The main ones are:* @[grind →] will select a multi-pattern from the hypotheses of the theorem (i.e. it will use the theorem for forwards reasoning).\nIn more detail, it will traverse the hypotheses of the theorem from left-to-right, and each time it encounters a minimal indexable\n(i.e. has a constant as its head) subexpression which \"covers\" (i.e. fixes the value of) an argument which was not\npreviously covered, it will add that subexpression as a pattern, until all arguments have been covered.* @[grind ←] will select a multi-pattern from the conclusion of theorem (i.e. it will use the theorem for backwards reasoning).\nThis may fail if not all the arguments to the theorem appear in the conclusion.* @[grind] will traverse the conclusion and then the hypotheses left-to-right, adding patterns as they increase the coverage,\nstopping when all arguments are covered.* @[grind =] checks that the conclusion of the theorem is an equality, and then uses the left-hand-side of the equality as a pattern.\nThis may fail if not all of the arguments appear in the left-hand-side.Here is the previous example again but using the attribute [grind →]opaque R : Int → Int → Prop\n@[grind →] axiom Rtrans {x y z : Int} : R x y → R y z → R x z\n\nexample {a b c d} : R a b → R b c → R c d → R a d := by\n  grind\nTo control theorem instantiation and avoid generating an unbounded number of instances,\ngrind uses a generation counter. Terms in the original goal are assigned generation zero.\nWhen grind applies a theorem using terms of generation ≤ n, any new terms it creates\nare assigned generation n + 1. This limits how far the tactic explores when applying\ntheorems and helps prevent an excessive number of instantiations.Key options:* grind (ematch := <num>) controls the number of E-matching rounds.* grind [<name>, ...] instructs grind to use the declaration name during E-matching.* grind only [<name>, ...] is like grind [<name>, ...] but does not use theorems tagged with @[grind].* grind (gen := <num>) sets the maximum generation.Linear integer arithmetic (cutsat)grind can solve goals that reduce to linear integer arithmetic (LIA) using an\nintegrated decision procedure called cutsat.  It understands* equalities   p = 0* inequalities  p ≤ 0* disequalities p ≠ 0* divisibility  d ∣ pThe solver incrementally assigns integer values to variables; when a partial\nassignment violates a constraint it adds a new, implied constraint and retries.\nThis model-based search is complete for LIA.Key options:* grind -cutsat disable the solver (useful for debugging)* grind +qlia accept rational models (shrinks the search space but is incomplete for ℤ)Examples:-- Even + even is never odd.\nexample {x y : Int} : 2 * x + 4 * y ≠ 5 := by\n  grind\n\n-- Mixing equalities and inequalities.\nexample {x y : Int} :\n    2 * x + 3 * y = 0 → 1 ≤ x → y < 1 := by\n  grind\n\n-- Reasoning with divisibility.\nexample (a b : Int) :\n    2 ∣ a + 1 → 2 ∣ b + a → ¬ 2 ∣ b + 2 * a := by\n  grind\n\nexample (x y : Int) :\n    27 ≤ 11*x + 13*y →\n    11*x + 13*y ≤ 45 →\n    -10 ≤ 7*x - 9*y →\n    7*x - 9*y ≤ 4 → False := by\n  grind\n\n-- Types that implement the `ToInt` type-class.\nexample (a b c : UInt64)\n    : a ≤ 2 → b ≤ 3 → c - a - b = 0 → c ≤ 5 := by\n  grind\nAlgebraic solver (ring)grind ships with an algebraic solver nick-named ring for goals that can\nbe phrased as polynomial equations (or disequations) over commutative rings,\nsemirings, or fields.Works out of the box\nAll core numeric types and relevant Mathlib types already provide the required\ntype-class instances, so the solver is ready to use in most developments.What it can decide:* equalities of the form p = q* disequalities p ≠ q* basic reasoning under field inverses (a / b := a * b⁻¹)* goals that mix ring facts with other grind enginesKey options:* grind -ring turn the solver off (useful when debugging)* grind (ringSteps := n) cap the number of steps performed by this procedure.Examplesopen Lean Grind\n\nexample [CommRing α] (x : α) : (x + 1) * (x - 1) = x^2 - 1 := by\n  grind\n\n-- Characteristic 256 means 16 * 16 = 0.\nexample [CommRing α] [IsCharP α 256] (x : α) :\n    (x + 16) * (x - 16) = x^2 := by\n  grind\n\n-- Works on built-in rings such as `UInt8`.\nexample (x : UInt8) : (x + 16) * (x - 16) = x^2 := by\n  grind\n\nexample [CommRing α] (a b c : α) :\n    a + b + c = 3 →\n    a^2 + b^2 + c^2 = 5 →\n    a^3 + b^3 + c^3 = 7 →\n    a^4 + b^4 = 9 - c^4 := by\n  grind\n\nexample [Field α] [NoNatZeroDivisors α] (a : α) :\n    1 / a + 1 / (2 * a) = 3 / (2 * a) := by\n  grind\nOther options* grind (splits := <num>) caps the depth of the search tree.  Once a branch performs num splits\ngrind stops splitting further in that branch.* grind -splitIte disables case splitting on if-then-else expressions.* grind -splitMatch disables case splitting on match expressions.* grind +splitImp instructs grind to split on any hypothesis A → B whose antecedent A is propositional.* grind -linarith disables the linear arithmetic solver for (ordered) modules and rings.Additional Examplesexample {a b} {as bs : List α} : (as ++ bs ++ [b]).getLastD a = b := by\n  grind\n\nexample (x : BitVec (w+1)) : (BitVec.cons x.msb (x.setWidth w)) = x := by\n  grind\n\nexample (as : Array α) (lo hi i j : Nat) :\n    lo ≤ i → i < j → j ≤ hi → j < as.size → min lo (as.size - 1) ≤ i := by\n  grind\n\n\n","context":"Lean Reference\u0009Tactic Proofs\u0009Tactic Reference","header":"13.5.11. SMT-Inspired Automation","id":"/Tactic-Proofs/Tactic-Reference/#The-Lean-Language-Reference--Tactic-Proofs--Tactic-Reference--SMT-Inspired-Automation"},"/Tactic-Proofs/The-Tactic-Language/#tactic-language-multiple-goals":{"contents":"The tactics all_goals and any_goals allow a tactic to be applied to every goal in the proof state.\nThe difference between them is that if the tactic fails for in any of the goals, all_goals itself fails, while any_goals fails only if the tactic fails in all of the goals.\n\nall_goals tac runs tac on each goal, concatenating the resulting goals.\nIf the tactic fails on any goal, the entire all_goals tactic fails.See also any_goals tac.\n\nany_goals tac applies the tactic tac to every goal,\nconcatenating the resulting goals for successful tactic applications.\nIf the tactic fails on all of the goals, the entire any_goals tactic fails.This tactic is like all_goals try tac except that it fails if none of the applications of tac succeeds.\n\n","context":"Lean Reference\u0009Tactic Proofs\u0009The Tactic Language\u0009Control Structures\u0009Goal Selection","header":"13.3.1.3.2. Working on Multiple Goals","id":"/Tactic-Proofs/The-Tactic-Language/#tactic-language-multiple-goals"},"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Compiler":{"contents":"* #7398 fixes a scoping error in the cce (Common Case Elimination) pass\nof the old code generator. This pass would create a join point for\ncommon minor premises even if some of those premises were in the bodies\nof locally defined functions, which results in an improperly scoped\nreference to a join point. The fix is to save/restore candidates when\nvisiting a lambda.* #7710 improves memory use of Lean, especially for longer-running\nserver processes, by up to 60%\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.19.0 (2025-05-01)","header":"Compiler","id":"/releases/v4.19.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___19___0-_LPAR_2025-05-01_RPAR_--Compiler"},"/releases/v4.22.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___22___0-_LPAR_2025-08-14_RPAR_--Highlights--Named-errors-with-explanations":{"contents":"Lean now supports named error messages with associated explanations.\n\n#8649 and #8730 add\nmacro syntax for registering\nand throwing named errors, mechanisms for displaying error names in the Infoview and at the command line,\nand the ability to link to error explanations in the reference manual.\n\nThis infrastructure lays the foundation for a searchable error index and improved diagnostics.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.22.0 (2025-08-14)\u0009Highlights","header":"Named errors with explanations","id":"/releases/v4.22.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___22___0-_LPAR_2025-08-14_RPAR_--Highlights--Named-errors-with-explanations"}});