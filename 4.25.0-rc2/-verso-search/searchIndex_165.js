window.docContents[165].resolve({"/Basic-Propositions/Quantifiers/#The-Lean-Language-Reference--Basic-Propositions--Quantifiers":{"contents":"Just as implication is implemented as ordinary function types in Prop, universal quantification is implemented as dependent function types in Prop.\nBecause Prop is impredicative, any function type in which the codomain is a Prop is itself a Prop, even if the domain is a Type.\nThe typing rules for dependent functions precisely match the introduction and elimination rules for universal quantification: if a predicate holds for any arbitrarily chosen element of a type, then it holds universally.\nIf a predicate holds universally, then it can be instantiated to a proof for any individual.\n\nUniversal QuantificationUniversal quantifiers bind one or more variables, which are then in scope in the final term.\nThe identifiers may also be _.\nWith parenthesized type annotations, multiple bound variables may have different types, while the unparenthesized variant requires that all have the same type.\n\nEven though universal quantifiers are represented by functions, their proofs should not be thought of as computations.\nBecause of proof irrelevance and the elimination restriction for propositions, there's no way to actually compute data using these proofs.\nAs a result, they are free to use reasoning principles that are not readily computed, such as the classical Axiom of Choice.\n\nExistential quantification is implemented as a structure that is similar to Subtype and Sigma: it contains a witness, which is a value that satisfies the predicate, along with a proof that the witness does in fact satisfy the predicate.\nIn other words, it is a form of dependent pair type.\nUnlike both Subtype and Sigma, it is a proposition; this means that programs cannot in general use a proof of an existential statement to obtain a value that satisfies the predicate.\n\nWhen writing a proof, the exists tactic allows one (or more) witness(es) to be specified for a (potentially nested) existential statement.\nThe constructor tactic, on the other hand, creates a metavariable for the witness; providing a proof of the predicate may solve the metavariable as well.\nThe components of an existential assumption can be made available individually by pattern matching with let or Lean.Parser.Tactic.match, as well as by using cases or rcases.\n\nProving Existential StatementsWhen proving that there exists some natural number that is the sum of four and five, the exists tactic expects the sum to be provided, constructing the equality proof using trivial:theorem ex_four_plus_five : ∃ n, 4 + 5 = n := by\n  exists 9\nThe constructor tactic, on the other hand, expects a proof.\nThe rfl tactic causes the sum to be determined as a side effect of checking definitional equality.theorem ex_four_plus_five' : ∃ n, 4 + 5 = n := by\n  constructor\n  rfl\n\n\nExistential quantification. If p : α → Prop is a predicate, then ∃ x : α, p x\nasserts that there is some x of type α such that p x holds.\nTo create an existential proof, use the exists tactic,\nor the anonymous constructor notation ⟨x, h⟩.\nTo unpack an existential, use cases h where h is a proof of ∃ x : α, p x,\nor let ⟨x, hx⟩ := h where `.Because Lean has proof irrelevance, any two proofs of an existential are\ndefinitionally equal. One consequence of this is that it is impossible to recover the\nwitness of an existential from the mere fact of its existence.\nFor example, the following does not compile:example (h : ∃ x : Nat, x = x) : Nat :=\n  let ⟨x, _⟩ := h  -- fail, because the goal is `Nat : Type`\n  x\nThe error message recursor 'Exists.casesOn' can only eliminate into Prop means\nthat this only works when the current goal is another proposition:example (h : ∃ x : Nat, x = x) : True :=\n  let ⟨x, _⟩ := h  -- ok, because the goal is `True : Prop`\n  trivial\nExistential introduction. If a : α and h : p a,\nthen ⟨a, h⟩ is a proof that ∃ x : α, p x.\n\nExistential QuantificationExistential quantifiers bind one or more variables, which are then in scope in the final term.\nThe identifiers may also be _.\nWith parenthesized type annotations, multiple bound variables may have different types, while the unparenthesized variant requires that all have the same type.\nIf more than one variable is bound, then the result is multiple instances of Exists, nested to the right.\n\nExtract an element from an existential statement, using Classical.choose.\n\n","context":"Lean Reference\u0009Basic Propositions","header":"18.3. Quantifiers","id":"/Basic-Propositions/Quantifiers/#The-Lean-Language-Reference--Basic-Propositions--Quantifiers"},"/Basic-Types/Bitvectors/#The-Lean-Language-Reference--Basic-Types--Bitvectors--API-Reference--Sequence-Operations":{"contents":"These operations treat bitvectors as sequences of bits, rather than as encodings of numbers.\n\nThe empty bitvector.\n\nPrepends a single bit to the front of a bitvector, using big-endian order (see append).The new bit is the most significant bit.\n\nAppend a single bit to the end of a bitvector, using big endian order (see append).\nThat is, the new bit is the least significant bit.\n\nShifts all bits of x to the left by 1 and sets the least significant bit to b.This is a non-dependent version of BitVec.concat that does not change the total bitwidth.\n\nTransforms a bitvector of length w into a bitvector of length v, padding with 0 as needed.The specific behavior depends on the relationship between the starting width w and the final width\nv:* If v > w, it is zero-extended; the high bits are padded with zeroes until the bitvector has v\nbits.* If v = w, the bitvector is returned unchanged.* If v < w, the high bits are truncated.BitVec.setWidth, BitVec.zeroExtend, and BitVec.truncate are aliases for this operation.SMT-LIB name: zero_extend.\n\nTransforms a bitvector of length w into a bitvector of length v, padding with 0 as needed.The specific behavior depends on the relationship between the starting width w and the final width\nv:* If v > w, it is zero-extended; the high bits are padded with zeroes until the bitvector has v\nbits.* If v = w, the bitvector is returned unchanged.* If v < w, the high bits are truncated.BitVec.setWidth, BitVec.zeroExtend, and BitVec.truncate are aliases for this operation.SMT-LIB name: zero_extend.\n\nIncreases the width of a bitvector to one that is at least as large by zero-extending it.This is a constant-time operation because the underlying Nat is unmodified; because the new width\nis at least as large as the old one, no overflow is possible.\n\nConcatenates two bitvectors using the “big-endian” convention that the more significant\ninput is on the left. Usually accessed via the ++ operator.SMT-LIB name: concat.Example:* 0xAB#8 ++ 0xCD#8 = 0xABCD#16.\n\nConcatenates i copies of x into a new vector of length w * i.\n\nReverses the bits in a bitvector.\n\nRotates the bits in a bitvector to the left.All the bits of x are shifted to higher positions, with the top n bits wrapping around to fill\nthe vacated low bits.SMT-LIB name: rotate_left, except this operator uses a Nat shift amount.Example:* (0b0011#4).rotateLeft 3 = 0b1001\n\nRotates the bits in a bitvector to the right.All the bits of x are shifted to lower positions, with the bottom n bits wrapping around to fill\nthe vacated high bits.SMT-LIB name: rotate_right, except this operator uses a Nat shift amount.Example:* rotateRight 0b01001#5 1 = 0b10100\n\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Bitvectors\u0009API Reference","header":"19.5.5.6. Sequence Operations","id":"/Basic-Types/Bitvectors/#The-Lean-Language-Reference--Basic-Types--Bitvectors--API-Reference--Sequence-Operations"},"/Basic-Types/Floating-Point-Numbers/#Float-api":{"contents":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Floating-Point Numbers","header":"19.6.2. API Reference","id":"/Basic-Types/Floating-Point-Numbers/#Float-api"},"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Tree-Based-Maps--Conversion--Unbundled-Variants":{"contents":"Unbundled maps separate well-formedness proofs from data.\nThis is primarily useful when defining nested inductive types.\nTo use these variants, import the module Std.TreeMap.Raw.\n\nTree maps without a bundled well-formedness invariant, suitable for use in nested\ninductive types. The well-formedness invariant is called Raw.WF. When in doubt, prefer TreeMap\nover TreeMap.Raw. Lemmas about the operations on Std.TreeMap.Raw are available in the\nmodule Std.Data.TreeMap.Raw.Lemmas.A tree map stores an assignment of keys to values. It depends on a comparator function that\ndefines an ordering on the keys and provides efficient order-dependent queries, such as retrieval\nof the minimum or maximum.To ensure that the operations behave as expected, the comparator function cmp should satisfy\ncertain laws that ensure a consistent ordering:* If a is less than (or equal) to b, then b is greater than (or equal) to a\nand vice versa (see the OrientedCmp typeclass).* If a is less than or equal to b and b is, in turn, less than or equal to c, then a\nis less than or equal to c (see the TransCmp typeclass).Keys for which cmp a b = Ordering.eq are considered the same, i.e., there can be only one entry\nwith key either a or b in a tree map. Looking up either a or b always yields the same entry,\nif any is present.To avoid expensive copies, users should make sure that the tree map is used linearly.Internally, the tree maps are represented as size-bounded trees, a type of self-balancing binary\nsearch tree with efficient order statistic lookups.Internal implementation detail of the tree map.\n\nWell-formedness predicate for tree maps. Users of TreeMap will not need to interact with\nthis. Users of TreeMap.Raw will need to provide proofs of WF to lemmas and should use lemmas\nlike WF.empty and WF.insert (which are always named exactly like the operations they are about)\nto show that map operations preserve well-formedness. The constructors of this type are internal\nimplementation details and should not be accessed by users.Internal implementation detail of the tree map.\n\n","context":"Lean Reference\u0009Basic Types\u0009Maps and Sets\u0009Tree-Based Maps\u0009Conversion","header":"19.18.8.6.1. Unbundled Variants","id":"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Tree-Based-Maps--Conversion--Unbundled-Variants"},"/Basic-Types/Strings/#The-Lean-Language-Reference--Basic-Types--Strings--API-Reference--String-Slices--API-Reference--Iteration":{"contents":"Creates an iterator over all characters (Unicode code points) in s.Examples:* \"abc\".toSlice.chars.toList = ['a', 'b', 'c']* \"ab∀c\".toSlice.chars.toList = ['a', 'b', '∀', 'c']\n\nCreates an iterator over all characters (Unicode code points) in s, starting from the end\nof the slice and iterating towards the start.Example:* \"abc\".toSlice.revChars.toList = ['c', 'b', 'a']* \"ab∀c\".toSlice.revChars.toList = ['c', '∀', 'b', 'a']\n\nCreates an iterator over all valid positions within {name}s.Examples* {lean}(\"abc\".toSlice.positions.map (fun ⟨p, h⟩ => p.get h) |>.toList) = ['a', 'b', 'c']* {lean}(\"abc\".toSlice.positions.map (·.val.offset.byteIdx) |>.toList) = [0, 1, 2]* {lean}(\"ab∀c\".toSlice.positions.map (fun ⟨p, h⟩ => p.get h) |>.toList) = ['a', 'b', '∀', 'c']* {lean}(\"ab∀c\".toSlice.positions.map (·.val.offset.byteIdx) |>.toList) = [0, 1, 2, 5]\n\nCreates an iterator over all valid positions within {name}s, starting from the last valid\nposition and iterating towards the first one.Examples* {lean}(\"abc\".toSlice.revPositions.map (fun ⟨p, h⟩ => p.get h) |>.toList) = ['c', 'b', 'a']* {lean}(\"abc\".toSlice.revPositions.map (·.val.offset.byteIdx) |>.toList) = [2, 1, 0]* {lean}(\"ab∀c\".toSlice.revPositions.map (fun ⟨p, h⟩ => p.get h) |>.toList) = ['c', '∀', 'b', 'a']* {lean}(\"ab∀c\".toSlice.revPositions.map (·.val.offset.byteIdx) |>.toList) = [5, 2, 1, 0]\n\nCreates an iterator over all bytes in {name}s.Examples:* {lean}\"abc\".toSlice.bytes.toList = [97, 98, 99]* {lean}\"ab∀c\".toSlice.bytes.toList = [97, 98, 226, 136, 128, 99]\n\nCreates an iterator over all bytes in {name}s, starting from the last one and iterating towards\nthe first one.Examples:* {lean}\"abc\".toSlice.revBytes.toList = [99, 98, 97]* {lean}\"ab∀c\".toSlice.revBytes.toList = [99, 128, 136, 226, 98, 97]\n\nSplits a slice at each subslice that matches the pattern pat, starting from the end of the\nslice and traversing towards the start.The subslices that matched the pattern are not included in any of the resulting subslices. If\nmultiple subslices in a row match the pattern, the resulting list will contain empty slices.This function is generic over all currently supported patterns except\nString/String.Slice.Examples:* (\"coffee tea water\".toSlice.revSplit Char.isWhitespace).allowNontermination.toList == [\"water\".toSlice, \"tea\".toSlice, \"coffee\".toSlice]* (\"coffee tea water\".toSlice.revSplit ' ').allowNontermination.toList == [\"water\".toSlice, \"tea\".toSlice, \"coffee\".toSlice]\n\nFolds a function over a slice from the start, accumulating a value starting with init. The\naccumulated value is combined with each character in order, using f.Examples:* \"coffee tea water\".toSlice.foldl (fun n c => if c.isWhitespace then n + 1 else n) 0 = 2* \"coffee tea and water\".toSlice.foldl (fun n c => if c.isWhitespace then n + 1 else n) 0 = 3* \"coffee tea water\".toSlice.foldl (·.push ·) \"\" = \"coffee tea water\"\n\nFolds a function over a slice from the end, accumulating a value starting with init. The\naccumulated value is combined with each character in reverse order, using f.Examples:* \"coffee tea water\".toSlice.foldr (fun c n => if c.isWhitespace then n + 1 else n) 0 = 2* \"coffee tea and water\".toSlice.foldr (fun c n => if c.isWhitespace then n + 1 else n) 0 = 3* \"coffee tea water\".toSlice.foldr (fun c s => s.push c) \"\" = \"retaw aet eeffoc\"\n\n","context":"Lean Reference\u0009Basic Types\u0009Strings\u0009API Reference\u0009String Slices\u0009API Reference","header":"19.8.4.12.1.9. Iteration","id":"/Basic-Types/Strings/#The-Lean-Language-Reference--Basic-Types--Strings--API-Reference--String-Slices--API-Reference--Iteration"},"/Functors___-Monads-and--do--Notation/Syntax/#The-Lean-Language-Reference--Functors___-Monads-and--do--Notation--Syntax--Infix-Operators--Functors":{"contents":"\n\nThere are two infix operators for Functor.map.\n\nFunctor Operatorsg <$> x is short for Functor.map g x.x <&> g is short for Functor.map g x.\n\n\n\n","context":"Lean Reference\u0009Functors, Monads and  do -Notation\u0009Syntax\u0009Infix Operators","header":"14.3.1.1. Functors","id":"/Functors___-Monads-and--do--Notation/Syntax/#The-Lean-Language-Reference--Functors___-Monads-and--do--Notation--Syntax--Infix-Operators--Functors"},"/Introduction/#introduction":{"contents":"The Lean Language Reference is intended as a comprehensive, precise description of Lean.\nIt is a reference work in which Lean users can look up detailed information, rather than a tutorial for new users.\nAt the moment, this reference manual is a public preview.\nFor tutorials and learning materials, please visit the Lean documentation page.\n\nThis document describes version 4.25.0-rc2 of Lean.\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference","header":"1. Introduction","id":"/Introduction/#introduction"},"/Source-Files-and-Modules/#whitespace":{"contents":"Tokens in Lean may be separated by any number of whitespace character sequences.\nWhitespace may be a space (\" \", Unicode 'SPACE (SP)' (U+0020)), a valid newline sequence, or a comment. \nNeither tab characters nor carriage returns not followed by newlines are valid whitespace sequences.\n\n","context":"Lean Reference\u0009Source Files and Modules\u0009Concrete Syntax","header":"5.2.1. Whitespace","id":"/Source-Files-and-Modules/#whitespace"},"/releases/v4.16.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___16___0-_LPAR_2025-02-03_RPAR_--Lake":{"contents":"* #6176 changes Lake's build process to no longer use leanc for\ncompiling C files or linking shared libraries and executables. Instead,\nit directly invokes the bundled compiler (or the native compiler if\nnone) using the necessary flags.* #6289 adapts Lake modules to use prelude and includes them in the\ncheck-prelude CI.* #6291 ensures the the log error position is properly preserved when\nprepending stray log entries to the job log. It also adds comparison\nsupport for Log.Pos.* #6388 merges BuildJob and Job, deprecating the former. Job now\ncontains a trace as part of its state which can be interacted with\nmonadically. also simplifies the implementation of OpaqueJob.* #6411 adds the ability to override package entries in a Lake manifest\nvia a separate JSON file. This file can be specified on the command line\nwith --packages or applied persistently by placing it at\n.lake/package-overrides.json.* #6422 fixes a bug in #6388 where the Package.afterBuildCahe*\nfunctions would produce different traces depending on whether the cache\nwas fetched.* #6627 aims to fix the trace issues reported by Mathlib that are\nbreaking lake exe cache in downstream projects.* #6631 sets MACOSX_DEPLOYMENT_TARGET for shared libraries (it was\npreviously only set for executables).\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.16.0 (2025-02-03)","header":"Lake","id":"/releases/v4.16.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___16___0-_LPAR_2025-02-03_RPAR_--Lake"},"/releases/v4.23.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___23___0-_LPAR_2025-09-15_RPAR_--Server":{"contents":"* #9040 improves the 'Go to Definition' UX, specifically:* Using 'Go to Definition' on a type class projection will now extract\nthe specific instances that were involved and provide them as locations\nto jump to. For example, using 'Go to Definition' on the toString of\ntoString 0 will yield results for ToString.toString and ToString Nat.* Using 'Go to Definition' on a macro that produces syntax with type\nclass projections will now also extract the specific instances that were\ninvolved and provide them as locations to jump to. For example, using\n'Go to Definition' on the + of 1 + 1 will yield results for\nHAdd.hAdd, HAdd α α α and Add Nat.* Using 'Go to Declaration' will now provide all the results of 'Go to\nDefinition' in addition to the elaborator and the parser that were\ninvolved. For example, using 'Go to Declaration' on the + of 1 + 1\nwill yield results for HAdd.hAdd, HAdd α α α, Add Nat,\nmacro_rules | `($x + $y) => ... and infixl:65 \" + \" => HAdd.hAdd.* Using 'Go to Type Definition' on a value with a type that contains\nmultiple constants will now provide 'Go to Definition' results for each\nconstant. For example, using 'Go to Type Definition' on x for x : Array Nat will yield results for Array and Nat.* #9163 disables the use of the header produced by lake setup-file in\nthe server for now. It will be re-enabled once Lake takes into account\nthe header given by the server when processing workspace modules.\nWithout that, setup-file header can produce odd behavior when the file\non disk and in an editor disagree on whether the file participates in\nthe module system.* #9563 performs some micro optimizations on fuzzy matching for a ~20%\ninstructions win.* #9784 ensures the editor progress bar better reflects the actual\nprogress of parallel elaboration.\n\n","context":"Lean Reference\u0009Release Notes\u0009Lean 4.23.0 (2025-09-15)","header":"Server","id":"/releases/v4.23.0/#The-Lean-Language-Reference--Release-Notes--Lean-4___23___0-_LPAR_2025-09-15_RPAR_--Server"}});