window.docContents[175].resolve({"/Basic-Types/Arrays/#subarray":{"contents":"A region of some underlying array.A subarray contains an array together with the start and end indices of a region of interest.\nSubarrays can be used to avoid copying or allocating space, while being more convenient than\ntracking the bounds by hand. The region of interest consists of every index that is both greater\nthan or equal to start and strictly less than stop.\n\nAllocates a new array that contains the contents of the subarray.\n\nThe empty subarray.This empty subarray is backed by an empty array.\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Arrays","header":"19.16.5. Sub-Arrays","id":"/Basic-Types/Arrays/#subarray"},"/Basic-Types/Natural-Numbers/#nat-api-predicates":{"contents":"Non-strict, or weak, inequality of natural numbers, usually accessed via the ≤ operator.Non-strict inequality is reflexive: n ≤ nIf n ≤ m, then n ≤ m + 1.\n\nStrict inequality of natural numbers, usually accessed via the < operator.It is defined as n < m = n + 1 ≤ m.\n\n","context":"Lean Reference\u0009Basic Types\u0009Natural Numbers\u0009API Reference\u0009Comparisons","header":"19.1.4.5.3. Predicates","id":"/Basic-Types/Natural-Numbers/#nat-api-predicates"},"/Basic-Types/Strings/#The-Lean-Language-Reference--Basic-Types--Strings--API-Reference--Raw-Positions--String-Lookups":{"contents":"Creates a new string that consists of the region of the input string delimited by the two positions.The result is \"\" if the start position is greater than or equal to the end position or if the\nstart position is at the end of the string. If either position is invalid (that is, if either points\nat the middle of a multi-byte UTF-8 character) then the result is unspecified.This is a legacy function. The recommended alternative is String.ValidPos.extract, but usually\nit is even better to operate on String.Slice instead and call String.Slice.copy (only) if\nrequired.Examples:* \"red green blue\".extract ⟨0⟩ ⟨3⟩ = \"red\"* \"red green blue\".extract ⟨3⟩ ⟨0⟩ = \"\"* \"red green blue\".extract ⟨0⟩ ⟨100⟩ = \"red green blue\"* \"red green blue\".extract ⟨4⟩ ⟨100⟩ = \"green blue\"* \"L∃∀N\".extract ⟨1⟩ ⟨2⟩ = \"∃∀N\"* \"L∃∀N\".extract ⟨2⟩ ⟨100⟩ = \"\"\n\nReturns the character at position p of a string. If p is not a valid position, returns the\nfallback value (default : Char), which is 'A', but does not panic.This function is overridden with an efficient implementation in runtime code. See\nString.Pos.Raw.utf8GetAux for the reference implementation.This is a legacy function. The recommended alternative is String.ValidPos.get, combined with\nString.pos or another means of obtaining a String.ValidPos.Examples:* \"abc\".get ⟨1⟩ = 'b'* \"abc\".get ⟨3⟩ = (default : Char) because byte 3 is at the end of the string.* \"L∃∀N\".get ⟨2⟩ = (default : Char) because byte 2 is in the middle of '∃'.\n\nReturns the character at position p of a string. Panics if p is not a valid position.See String.pos? and String.ValidPos.get for a safer alternative.This function is overridden with an efficient implementation in runtime code. See\nString.utf8GetAux for the reference implementation.This is a legacy function. The recommended alternative is String.ValidPos.get, combined with\nString.pos! or another means of obtaining a String.ValidPos.Examples* \"abc\".get! ⟨1⟩ = 'b'\n\nReturns the character at position p of a string. Returns (default : Char), which is 'A', if\np is not a valid position.Requires evidence, h, that p is within bounds instead of performing a run-time bounds check as\nin String.get.A typical pattern combines get' with a dependent if-expression to avoid the overhead of an\nadditional bounds check. For example:def getInBounds? (s : String) (p : String.Pos) : Option Char :=\n  if h : s.atEnd p then none else some (s.get' p h)\nEven with evidence of ¬ s.atEnd p, p may be invalid if a byte index points into the middle of a\nmulti-byte UTF-8 character. For example, \"L∃∀N\".get' ⟨2⟩ (by decide) = (default : Char).This is a legacy function. The recommended alternative is String.ValidPos.get, combined with\nString.pos or another means of obtaining a String.ValidPos.Examples:* \"abc\".get' 0 (by decide) = 'a'* let lean := \"L∃∀N\"; lean.get' (0 |> lean.next |> lean.next) (by decide) = '∀'\n\nReturns the character at position p of a string. If p is not a valid position, returns none.This function is overridden with an efficient implementation in runtime code. See\nString.utf8GetAux? for the reference implementation.This is a legacy function. The recommended alternative is String.ValidPos.get, combined with\nString.pos? or another means of obtaining a String.ValidPos.Examples:* \"abc\".get? ⟨1⟩ = some 'b'* \"abc\".get? ⟨3⟩ = none* \"L∃∀N\".get? ⟨1⟩ = some '∃'* \"L∃∀N\".get? ⟨2⟩ = none\n\n","context":"Lean Reference\u0009Basic Types\u0009Strings\u0009API Reference\u0009Raw Positions","header":"19.8.4.5.5. String Lookups","id":"/Basic-Types/Strings/#The-Lean-Language-Reference--Basic-Types--Strings--API-Reference--Raw-Positions--String-Lookups"},"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Configuration-File-Format--Lean-Format--Targets--External-Libraries":{"contents":"Because external libraries may be written in any language and require arbitrary build steps, they are defined as programs written in the FetchM monad that produce a Job.\nExternal library targets should produce a build job that carries out the build and then returns the location of the resulting static library.\nFor the external library to link properly when precompileModules is on, the static library produced by an extern_lib target must follow the platform's naming conventions for libraries (i.e., be named foo.a on Windows or libfoo.a on Unix-like systems).\nThe utility function Lake.nameToStaticLib converts a library name into its proper file name for current platform.\n\nExternal Library TargetsDefine a new external library target for the package. Has one form:extern_lib «target-name» (pkg : NPackage _package.name) :=\n  /- build term of type `FetchM (Job FilePath)` -/\nThe pkg parameter (and its type specifier) is optional.\nIt is of type NPackage _package.name to provably demonstrate the package\nprovided is the package in which the target is defined.The term should build the external library's static library.\n\n","context":"Lean Reference\u0009Build Tools\u0009Lake\u0009Configuration File Format\u0009Lean Format\u0009Targets","header":"22.1.3.2.4.3. External Libraries","id":"/Build-Tools-and-Distribution/Lake/#The-Lean-Language-Reference--Build-Tools-and-Distribution--Lake--Configuration-File-Format--Lean-Format--Targets--External-Libraries"},"/The--grind--tactic/Bigger-Examples/#The-Lean-Language-Reference--The--grind--tactic--Bigger-Examples--if---then---else--Normalization--The-solution-using--grind":{"contents":"Actually solving the problem is not that hard:\nwe just need a recursive function that carries along a record of “already assigned variables”,\nand then, whenever performing a branch on a variable, adding a new assignment in each of the branches.\nIt also needs to flatten nested if-then-else expressions which have another if-then-else in the “condition” position.\n(This is extracted from Chris Hughes's solution, but without the subtyping.)\n\nLet's work inside the IfExpr namespace.\n\nnamespace IfExpr\n\n\ndef normalize (assign : Std.HashMap Nat Bool) :\n    IfExpr → IfExpr\n  | lit b => lit b\n  | var v =>\n    match assign[v]? with\n    | none => var v\n    | some b => lit b\n  | ite (lit true)  t _ => normalize assign t\n  | ite (lit false) _ e => normalize assign e\n  | ite (ite a b c) t e =>\n    normalize assign (ite a (ite b t e) (ite c t e))\n  | ite (var v)     t e =>\n    match assign[v]? with\n    | none =>\n      let t' := normalize (assign.insert v true) t\n      let e' := normalize (assign.insert v false) e\n      if t' = e' then t' else ite (var v) t' e'\n    | some b => normalize assign (ite (lit b) t e)\n\nThis is pretty straightforward, but it immediately runs into a problem:fail to show termination for\n  IfExpr.normalize\nwith errors\nfailed to infer structural recursion:\nCannot use parameter assign:\n  the type HashMap Nat Bool does not have a `.brecOn` recursor\nCannot use parameter #2:\n  failed to eliminate recursive application\n    normalize assign (a.ite (b.ite t e) (c.ite t e))\n\n\nCould not find a decreasing measure.\nLean here is telling us that it can't see that the function is terminating.\nOften Lean is pretty good at working this out for itself, but for sufficiently complicated functions\nwe need to step in to give it a hint.In this case we can see that it's the recursive call\nite (ite a b c) t e which is calling normalize on (ite a (ite b t e) (ite c t e))\nwhere Lean is having difficulty. Lean has made a guess at a plausible termination measure,\nbased on using automatically generated sizeOf function, but can't prove the resulting goal,\nessentially because t and e appear multiple times in the recursive call.\n\nTo address problems like this, we nearly always want to stop using the automatically generated sizeOf function,\nand construct our own termination measure. We'll use\n\n@[simp] def normSize : IfExpr → Nat\n  | lit _ => 0\n  | var _ => 1\n  | .ite i t e => 2 * normSize i + max (normSize t) (normSize e) + 1\n\n\nMany different functions would work here. The basic idea is to increase the “weight” of the “condition” branch\n(this is the multiplicative factor in the 2 * normSize i ),\nso that as long the “condition” part shrinks a bit, the whole expression counts as shrinking even if the “then” and “else” branches have grown.\nWe've annotated the definition with @[simp] so Lean's automated termination checker is allowed to unfold the definition.\n\nWith this in place, the definition goes through using the termination_by clause:\n\ndef normalize (assign : Std.HashMap Nat Bool) :\n    IfExpr → IfExpr\n  | lit b => lit b\n  | var v =>\n    match assign[v]? with\n    | none => var v\n    | some b => lit b\n  | ite (lit true)  t _ => normalize assign t\n  | ite (lit false) _ e => normalize assign e\n  | ite (ite a b c) t e =>\n    normalize assign (ite a (ite b t e) (ite c t e))\n  | ite (var v)     t e =>\n    match assign[v]? with\n    | none =>\n      let t' := normalize (assign.insert v true) t\n      let e' := normalize (assign.insert v false) e\n      if t' = e' then t' else ite (var v) t' e'\n    | some b => normalize assign (ite (lit b) t e)\ntermination_by e => e.normSize\nNow it's time to prove some properties of this function.\nWe're just going to package together all the properties we want:theorem normalize_spec\n    (assign : Std.HashMap Nat Bool) (e : IfExpr) :\n    (normalize assign e).normalized\n      ∧ (∀ f, (normalize assign e).eval f =\n          e.eval fun w => assign[w]?.getD (f w))\n      ∧ ∀ (v : Nat),\n          v ∈ vars (normalize assign e) → ¬ v ∈ assign :=\n  sorry\nThat is:* the result of normalize is actually normalized according to the initial definitions,* if we normalize an “if-then-else” expression using some assignments, and then evaluate the remaining variables,\n  we get the same result as evaluating the original “if-then-else” using the composite of the two assignments,* and any variable appearing in the assignments no longer appears in the normalized expression.You might think that we should state these three properties as separate lemmas,\nbut it turns out that proving them all at once is really convenient, because we can use the fun_induction\ntactic to assume that all these properties hold for normalize in the recursive calls, and then\ngrind will just put all the facts together for the result:-- We tell `grind` to unfold our definitions above.\nattribute [local grind]\n  normalized hasNestedIf hasConstantIf hasRedundantIf\n  disjoint vars eval List.disjoint\n\ntheorem normalize_spec\n    (assign : Std.HashMap Nat Bool) (e : IfExpr) :\n    (normalize assign e).normalized\n      ∧ (∀ f, (normalize assign e).eval f =\n          e.eval fun w => assign[w]?.getD (f w))\n      ∧ ∀ (v : Nat),\n          v ∈ vars (normalize assign e) → ¬ v ∈ assign := by\n  fun_induction normalize with grind\nThe fact that the fun_induction plus grind combination just works here is sort of astonishing.\nWe're really excited about this, and we're hoping to see a lot more proofs in this style!A lovely consequence of highly automated proofs is that often you have some flexibility to change the statements,\nwithout changing the proof at all! As examples, the particular way that we asserted above that\n“any variable appearing in the assignments no longer appears in the normalized expression”\ncould be stated in many different ways (although not omitted!). The variations really don't matter,\nand grind can both prove, and use, any of them:Here we use assign.contains v = false:example (assign : Std.HashMap Nat Bool) (e : IfExpr) :\n    (normalize assign e).normalized\n      ∧ (∀ f, (normalize assign e).eval f =\n          e.eval fun w => assign[w]?.getD (f w))\n      ∧ ∀ (v : Nat), v ∈ vars (normalize assign e) →\n          assign.contains v = false := by\n  fun_induction normalize with grind\nand here we use assign[v]? = none:example (assign : Std.HashMap Nat Bool) (e : IfExpr) :\n    (normalize assign e).normalized\n      ∧ (∀ f, (normalize assign e).eval f =\n          e.eval fun w => assign[w]?.getD (f w))\n      ∧ ∀ (v : Nat),\n          v ∈ vars (normalize assign e) → assign[v]? = none := by\n  fun_induction normalize with grind\nIn fact, it's also of no consequence to grind whether we use a\nHashMap or a TreeMap to store the assignments,\nwe can simply switch that implementation detail out, without having to touch the proofs:\n\n\n\ndef normalize (assign : Std.TreeMap Nat Bool) :\n    IfExpr → IfExpr\n  | lit b => lit b\n  | var v =>\n    match assign[v]? with\n    | none => var v\n    | some b => lit b\n  | ite (lit true)  t _ => normalize assign t\n  | ite (lit false) _ e => normalize assign e\n  | ite (ite a b c) t e =>\n    normalize assign (ite a (ite b t e) (ite c t e))\n  | ite (var v)     t e =>\n    match assign[v]? with\n    | none =>\n      let t' := normalize (assign.insert v true) t\n      let e' := normalize (assign.insert v false) e\n      if t' = e' then t' else ite (var v) t' e'\n    | some b => normalize assign (ite (lit b) t e)\ntermination_by e => e.normSize\n\ntheorem normalize_spec\n    (assign : Std.TreeMap Nat Bool) (e : IfExpr) :\n    (normalize assign e).normalized\n      ∧ (∀ f, (normalize assign e).eval f =\n          e.eval fun w => assign[w]?.getD (f w))\n      ∧ ∀ (v : Nat),\n          v ∈ vars (normalize assign e) → ¬ v ∈ assign := by\n  fun_induction normalize with grind\n\n\n(The fact that we can do this relies on the fact that all the lemmas for both HashMap and for TreeMap that grind needs have already be annotated in the standard library.)\n\nIf you'd like to play around with this code,\nyou can find the whole file here,\nor in fact play with it with no installation\nin the Live Lean editor.\n\n\n\n","context":"Lean Reference\u0009The  grind  tactic\u0009Bigger Examples\u0009if - then - else  Normalization","header":"17.10.2.4. The solution using  grind","id":"/The--grind--tactic/Bigger-Examples/#The-Lean-Language-Reference--The--grind--tactic--Bigger-Examples--if---then---else--Normalization--The-solution-using--grind"},"/The--grind--tactic/Congruence-Closure/#The-Lean-Language-Reference--The--grind--tactic--Congruence-Closure--Congruence-Closure-vs___-Simplification":{"contents":"Congruence closure is a fundamentally different operation from simplification:* simp rewrites a goal, replacing occurrences of t₁ with t₂ as soon as it sees h : t₁ = t₂.\n  The rewrite is directional and destructive.* grind accumulates equalities bidirectionally.  No term is rewritten; instead, both representatives live in the same class.  All other engines ( E‑matching, theory solvers, propagation) can query these classes and add new facts, then the closure updates incrementally.This makes congruence closure especially robust in the presence of symmetrical reasoning, mutual recursion, and large nestings of constructors where rewriting would duplicate work.\n\n","context":"Lean Reference\u0009The  grind  tactic\u0009Congruence Closure","header":"17.3.1. Congruence Closure vs. Simplification","id":"/The--grind--tactic/Congruence-Closure/#The-Lean-Language-Reference--The--grind--tactic--Congruence-Closure--Congruence-Closure-vs___-Simplification"},"/The-Type-System/Functions/#The-Lean-Language-Reference--The-Type-System--Functions--Function-Abstractions":{"contents":"In Lean's type theory, functions are created using function abstractions that bind a variable.\nIn various communities, function abstractions are also known as lambdas, due to Alonzo Church's notation for them, or anonymous functions because they don't need to be defined with a name in the global environment.\nWhen the function is applied, the result is found by β-reduction: substituting the argument for the bound variable.\nIn compiled code, this happens strictly: the argument must already be a value.\nWhen type checking, there are no such restrictions; the equational theory of definitional equality allows β-reduction with any term.\n\nIn Lean's term language, function abstractions may take multiple parameters or use pattern matching.\nThese features are translated to simpler operations in the core language, where all functions abstractions take exactly one parameter.\nNot all functions originate from abstractions: type constructors, constructors, and recursors may have function types, but they cannot be defined using function abstractions alone.\n\n","context":"Lean Reference\u0009Type System\u0009Functions","header":"4.1.1. Function Abstractions","id":"/The-Type-System/Functions/#The-Lean-Language-Reference--The-Type-System--Functions--Function-Abstractions"}});