window.docContents[204].resolve({"/Basic-Types/Arrays/#array-api":{"contents":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Arrays","header":"20.16.4. API Reference","id":"/Basic-Types/Arrays/#array-api"},"/Basic-Types/Floating-Point-Numbers/#The-Lean-Language-Reference--Basic-Types--Floating-Point-Numbers--API-Reference--Trigonometry":{"contents":"\n\n\n\n\n\n","context":"Lean Reference\u0009Basic Types\u0009Floating-Point Numbers\u0009API Reference","header":"20.6.2.9. Trigonometry","id":"/Basic-Types/Floating-Point-Numbers/#The-Lean-Language-Reference--Basic-Types--Floating-Point-Numbers--API-Reference--Trigonometry"},"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Tree-Based-Sets--Iteration":{"contents":"Check if any element satisfies the predicate, short-circuiting if a predicate succeeds.\n\nCheck if all elements satisfy the predicate, short-circuiting if a predicate fails.\n\nFolds the given function over the elements of the tree set in ascending order.\n\nMonadically computes a value by folding the given function over the elements in the tree set in\nascending order.\n\nFolds the given function over the elements of the tree set in descending order.\n\nMonadically computes a value by folding the given function over the elements in the tree set in\ndescending order.\n\nSupport for the for loop construct in do blocks. The iteration happens in ascending\norder.\n\nCarries out a monadic action on each element in the tree set in ascending order.\n\n","context":"Lean Reference\u0009Basic Types\u0009Maps and Sets\u0009Tree-Based Sets","header":"20.18.10.5. Iteration","id":"/Basic-Types/Maps-and-Sets/#The-Lean-Language-Reference--Basic-Types--Maps-and-Sets--Tree-Based-Sets--Iteration"},"/Elaboration-and-Compilation/#elaboration-results":{"contents":"Lean's core type theory does not include pattern matching or recursive definitions.\nInstead, it provides low-level recursors that can be used to implement both case distinction and primitive recursion.\nThus, the elaborator must translate definitions that use pattern matching and recursion into definitions that use recursors.More details on the elaboration of recursive definitions is available in the dedicated section on the topic.\nThis translation is additionally a proof that the function terminates for all potential arguments, because all functions that can be translated to recursors also terminate.\n\nThe translation to recursors happens in two phases: during term elaboration, uses of pattern matching are replaced by appeals to auxiliary matching functions that implement the particular case distinction that occurs in the code.\nThese auxiliary functions are themselves defined using recursors, though they do not make use of the recursors' ability to actually implement recursive behavior.They use variants of the casesOn construction that is described in the section on recursors and elaboration, specialized to reduce code size.\nThe term elaborator thus returns core-language terms in which pattern matching has been replaced with the use of special functions that implement case distinction, but these terms may still contain recursive occurrences of the function being defined.\nA definition that still includes recursion, but has otherwise been elaborated to the core language, is called a pre-definition.\nTo see auxiliary pattern matching functions in Lean's output, set the option pp.match to false.\n\n(pretty printer) disable/enable 'match' notation\n\n\n\nThe pre-definition is then sent to the compiler and to the kernel.\nThe compiler receives the pre-definition as-is, with recursion intact.\nThe version sent to the kernel, on the other hand, undergoes a second transformation that replaces explicit recursion with uses of recursors, well-founded recursion, or .\nThis split is for three reasons:* The compiler can compile partial functions that the kernel treats as opaque constants for the purposes of reasoning.* The compiler can also compile unsafe functions that bypass the kernel entirely.* Translation to recursors does not necessarily preserve the cost model expected by programmers, in particular laziness vs strictness, but compiled code must have predictable performance.\n   The other strategies used to justify recursive definitions result in internal terms that are even further from the program as it was written.The compiler stores an intermediate representation in an environment extension.\n\nFor straightforwardly structurally recursive functions, the translation will use the type's recursor.\nThese functions tend to be relatively efficient when run in the kernel, their defining equations hold definitionally, and they are easy to understand.\nFunctions that use other patterns of recursion that cannot be captured by the type's recursor are translated using well-founded recursion, which is structural recursion on a proof that some measure decreases at each recursive call, or using partial fixpoints, which logically capture at least part of a function's specification by appealing to domain-theoretic constructions.\nLean can automatically derive many of these termination proofs, but some require manual proofs.\nWell-founded recursion is more flexible, but the resulting functions are often slower to execute in the kernel due to the proof terms that show that a measure decreases, and their defining equations may hold only propositionally.\nTo provide a uniform interface to functions defined via structural and well-founded recursion and to check its own correctness, the elaborator proves equational lemmas that relate the function to its original definition.\nIn the function's namespace, eq_unfold relates the function directly to its definition, eq_def relates it to the definition after instantiating implicit parameters, and N lemmas eq_N relate each case of its pattern-matching to the corresponding right-hand side, including sufficient assumptions to indicate that earlier branches were not taken.\n\nEquational LemmasGiven the definition of thirdOfFive:def thirdOfFive : List α → Option α\n  | [_, _, x, _, _] => some x\n  | _ => none\nequational lemmas are generated that relate thirdOfFive to its definition.thirdOfFive.eq_unfold states that it can be unfolded to its original definition when no arguments are provided:thirdOfFive.eq_unfold.{u_1} :\n  @thirdOfFive.{u_1} = fun {α : Type u_1} x =>\n    match x with\n    | [head, head_1, x, head_2, head_3] => some x\n    | x => none\nthirdOfFive.eq_def states that it matches its definition when applied to arguments:thirdOfFive.eq_def.{u_1} {α : Type u_1} :\n  ∀ (x : List α),\n    thirdOfFive x =\n      match x with\n      | [head, head_1, x, head_2, head_3] => some x\n      | x => none\nthirdOfFive.eq_1 shows that its first defining equation holds:thirdOfFive.eq_1.{u} {α : Type u}\n    (head head_1 x head_2 head_3 : α) :\n  thirdOfFive [head, head_1, x, head_2, head_3] = some x\nthirdOfFive.eq_2 shows that its second defining equation holds:thirdOfFive.eq_2.{u_1} {α : Type u_1} :\n  ∀ (x : List α),\n    (∀ (head head_1 x_1 head_2 head_3 : α),\n      x = [head, head_1, x_1, head_2, head_3] → False) →\n    thirdOfFive x = none\nThe final lemma thirdOfFive.eq_2 includes a premise that the first branch could not have matched (that is, that the list does not have exactly five elements).\n\nRecursive Equational LemmasGiven the definition of everyOther:def everyOther : List α → List α\n  | [] => []\n  | [x] => [x]\n  | x :: _ :: xs => x :: everyOther xs\nequational lemmas are generated that relate everyOther's recursor-based implementation to its original recursive definition.everyOther.eq_unfold states that everyOther with no arguments is equal to its unfolding:everyOther.eq_unfold.{u} :\n  @everyOther.{u} = fun {α} x =>\n    match x with\n    | [] => []\n    | [x] => [x]\n    | x :: _ :: xs => x :: everyOther xs\neveryOther.eq_def states that a everyOther is equal to its definition when applied to arguments:everyOther.eq_def.{u} {α : Type u} :\n  ∀ (x : List α),\n    everyOther x =\n      match x with\n      | [] => []\n      | [x] => [x]\n      | x :: _ :: xs => x :: everyOther xs\neveryOther.eq_1 demonstrates its first pattern:everyOther.eq_1.{u} {α : Type u} : everyOther [] = ([] : List α)\neveryOther.eq_2 demonstrates its second pattern:everyOther.eq_2.{u} {α : Type u} (x : α) : everyOther [x] = [x]\neveryOther.eq_3 demonstrates its final pattern:everyOther.eq_3.{u} {α : Type u} (x y : α) (xs : List α) :\n  everyOther (x :: y :: xs) = x :: everyOther xs\nBecause the patterns do not overlap, no assumptions about prior patterns not having matched are necessary for the equational lemmas.\n\nAfter elaborating a module, having checked each addition to the environment with the kernel, the changes that the module made to the global environment (including extensions) are serialized to a .olean file.\nIn these files, Lean terms and values are represented just as they are in memory; thus the file can be directly memory-mapped.\nAll code paths that lead to Lean adding to the environment involve the new type or definition first being checked by the kernel.\nHowever, Lean is a very open, flexible system.\nTo guard against the possibility of poorly-written metaprograms jumping through hoops to add unchecked values to the environment, a separate tool lean4checker can be used to validate that the entire environment in a .olean file satisfies the kernel.\n\nIn addition to the .olean file, the elaborator produces a .ilean file, which is an index used by the language server.\nThis file contains information needed to work interactively with the module without fully loading it, such as the source positions of definitions.\nThe contents of .ilean files are an implementation detail and may change at any release.\n\nFinally, the compiler is invoked to translate the intermediate representation of functions stored in its environment extension into C code.\nA C file is produced for each Lean module; these are then compiled to native code using a bundled C compiler.\nIf the precompileModules option is set in the build configuration, then this native code can be dynamically loaded and invoked by Lean; otherwise, an interpreter is used.\nFor most workloads, the overhead of compilation is larger than the time saved by avoiding the interpreter, but some workloads can be sped up dramatically by pre-compiling tactics, language extensions, or other extensions to Lean.\n\n","context":"Lean Reference\u0009Elaboration and Compilation","header":"2.4. Elaboration Results","id":"/Elaboration-and-Compilation/#elaboration-results"},"/IO/Tasks-and-Threads/#The-Lean-Language-Reference--IO--Tasks-and-Threads--Communication-Between-Tasks--Condition-Variables":{"contents":"The types and functions in this section are available after importing Std.Sync.Mutex.\n\nCondition variable, a synchronization primitive to be used with a BaseMutex or Mutex.The thread that wants to modify the shared variable must:1. Lock the BaseMutex or Mutex2. Work on the shared variable3. Call Condvar.notifyOne or Condvar.notifyAll after it is done. Note that this may be done\nbefore or after the mutex is unlocked.If working with a Mutex the thread that waits on the Condvar can use Mutex.atomicallyOnce\nto wait until a condition is true. If working with a BaseMutex it must:1. Lock the BaseMutex.2. Do one of the following:* Use Condvar.waitUntil to (potentially repeatedly wait) on the condition variable until\nthe condition is true.* Implement the waiting manually by:1. Checking the condition2. Calling Condvar.wait which releases the BaseMutex and suspends execution until the\ncondition variable is notified.3. Check the condition and resume waiting if not satisfied.\n\nCreates a new condition variable.\n\nWaits until another thread calls notifyOne or notifyAll.\n\nWakes up a single other thread executing wait.\n\nWakes up all other threads executing wait.\n\nWaits on the condition variable until the predicate is true.\n\n","context":"Lean Reference\u0009IO\u0009Tasks and Threads\u0009Communication Between Tasks","header":"15.11.6.3. Condition Variables","id":"/IO/Tasks-and-Threads/#The-Lean-Language-Reference--IO--Tasks-and-Threads--Communication-Between-Tasks--Condition-Variables"},"/The--grind--tactic/Constraint-Propagation/#grind-propagation":{"contents":"Constraint propagation works on the True and False buckets of the whiteboard.\nWhenever a term is added to one of those buckets, grind fires dozens of small forward rules that derive further information from its logical consequences:\n\n Boolean connectives\n\nThe truth tables of the Boolean connectives can be used to derive further true and false facts.\n  For example:* If A is True, then A ∨ B becomes True.* If A ∧ B is True, then both A and B become True.* If A ∧ B is False, at least one of A, B becomes False.\n\n Inductive Types\n\nIf terms formed by applications of two different constructors of the same inductive type (e.g. none and some) are placed in the same equivalence class, a contradiction is derived.\n  If two terms formed by applications of the same constructor are placed in the same equivalence class, then their arguments are also made equal.\n\n Projections\n\nFrom h : (x, y) = (x', y') we derive x = x' and y = y'.\n\n Casts\n\nAny term cast h a : β is equated with a : α immediately (using heterogeneous equality).\n\n Reduction\n\nDefinitional reduction is propagated, so (a, b).1 is equated with a.\n\n\n\nBelow is a representative slice of the propagators that demonstrates their overall style.\nEach follows the same skeleton.1. It inspect the truth value of sub‑expressions.2. If further facts can be derived, it either equates terms (connecting them on the metaphorical whiteboard) using (pushEq), or it indicates truth values using (pushEqTrue / pushEqFalse).\n   These steps produce proof terms using internal helper lemmas such as Grind.and_eq_of_eq_true_left.3. If a contradiction arises, the goal is closed using (closeGoal).Upward propagation derives facts about a term from facts about sub-terms, while downward propagation derives facts about sub-terms from facts about a term.\n\n\n\n\n/-- Propagate equalities *upwards* for conjunctions. -/\nbuiltin_grind_propagator propagateAndUp ↑And := fun e => do\n  let_expr And a b := e | return ()\n  if (← isEqTrue a) then\n    -- a = True  ⇒  (a ∧ b) = b\n    pushEq e b <|\n      mkApp3 (mkConst ``Grind.and_eq_of_eq_true_left)\n        a b (← mkEqTrueProof a)\n  else if (← isEqTrue b) then\n    -- b = True  ⇒  (a ∧ b) = a\n    pushEq e a <|\n      mkApp3 (mkConst ``Grind.and_eq_of_eq_true_right)\n        a b (← mkEqTrueProof b)\n  else if (← isEqFalse a) then\n    -- a = False  ⇒  (a ∧ b) = False\n    pushEqFalse e <|\n      mkApp3 (mkConst ``Grind.and_eq_of_eq_false_left)\n        a b (← mkEqFalseProof a)\n  else if (← isEqFalse b) then\n    -- b = False  ⇒  (a ∧ b) = False\n    pushEqFalse e <|\n      mkApp3 (mkConst ``Grind.and_eq_of_eq_false_right)\n        a b (← mkEqFalseProof b)\n\n/--\nTruth flows *down* when the whole `And` is proven `True`.\n-/\nbuiltin_grind_propagator propagateAndDown ↓And :=\n  fun e => do\n  if (← isEqTrue e) then\n    let_expr And a b := e | return ()\n    let h ← mkEqTrueProof e\n    -- (a ∧ b) = True  ⇒  a = True\n    pushEqTrue a <| mkApp3\n      (mkConst ``Grind.eq_true_of_and_eq_true_left) a b h\n    -- (a ∧ b) = True  ⇒  B = True\n    pushEqTrue b <| mkApp3\n      (mkConst ``Grind.eq_true_of_and_eq_true_right) a b h\n\n\n\n\nOther frequently‑triggered propagators follow the same pattern:\n\n* Propagator* Handles* Notes\n* propagateOrUp / propagateOrDown* A ∨ B* Uses the truth table for disjunction to derive further truth values\n* propagateNotUp / propagateNotDown* ¬ A* Ensures that ¬ A and A have opposite truth values\n* propagateEqUp / propagateEqDown* a = b* Bridges Booleans, detects constructor clash \n* propagateIte / propagateDIte* ite / dite* Equates the term with the chosen branch once the condition's truth value is known\n* propagateEtaStruct* Values of structures tagged [grind ext]* Generates η‑expansion a = ⟨a.1, …⟩\n\nMany specialized variants for Bool mirror these rules exactly (e.g. propagateBoolAndUp).\n\n\n\n","context":"Lean Reference\u0009The  grind  tactic","header":"17.4. Constraint Propagation","id":"/The--grind--tactic/Constraint-Propagation/#grind-propagation"},"/The--mvcgen--tactic/#The-Lean-Language-Reference--The--mvcgen--tactic--Verifying-Imperative-Programs-Using--mvcgen--Compositional-Reasoning-About-Effectful-Programs-Using-Hoare-Triples--Hoare-Triples":{"contents":"A Hoare triple consists of a precondition, a statement, and a postcondition; it asserts that if the precondition holds, then the postcondition holds after running the statement.\nIn Lean syntax, this is written ⦃ P ⦄ prog ⦃ Q ⦄, where P is the precondition, prog : m α is the statement, and Q is the postcondition.\nP and Q are written in an assertion language that is determined by the specific monad m.In particular, monad's instance of the type class WP specifies the ways in which assertions may refer to the monad's state or the exceptions it may throw.Specifications as Hoare triples are compositional because they allow statements to be sequenced.\nGiven ⦃P⦄ stmt1 ⦃Q⦄ and ⦃P'⦄ stmt2 ⦃Q'⦄, if Q implies P' then ⦃P⦄ (do stmt1; stmt2) ⦃Q'⦄.\nJust as proofs about ordinary functions can rely on lemmas about the functions that they call, proofs about monadic programs can use lemmas that are specified in terms of Hoare triples.One suitable specification for mkFresh as a Hoare triple is this translation of mkFreshN_correct:⦃⌜True⌝⦄ mkFreshN n ⦃⇓ r => ⌜r.Nodup⌝⦄\nCorner brackets embed propositions into the monadic assertion language, so ⌜p⌝ is the assertion of the proposition p.\nThe precondition ⌜True⌝ asserts that True is true; this trivial precondition is used to state that the specification imposes no requirements on the state in which it is called.\nThe postcondition states that the result value is a list with no duplicate elements.A specification for the single-step mkFresh describes its effects on the monad's state:∀ (c : Nat),\n⦃fun state => ⌜state.counter = c⌝⦄\nmkFresh\n⦃⇓ r state => ⌜r = c ∧ c < state.counter⌝⦄\nWhen working in a state monad, preconditions may be parameterized over the value of the state prior to running the code.\nHere, the universally quantified Nat is used to relate the initial state to the final state; the precondition is used to connect it to the initial state.\nSimilarly, the postcondition may also accept the final state as a parameter.\nThis Hoare triple states:If c refers to the Supply.counter field of the Supply prestate, then running mkFresh returns c and modifies the Supply.counter of the poststate to be larger than c.Note that this specification is lossy: mkFresh could increment its state by an arbitrary non-negative amount and still satisfy the specification.\nThis is good, because specifications may abstract over uninteresting implementation details, ensuring resilient and small proofs.Hoare triples are defined in terms of a logic of stateful predicates plus a weakest precondition semantics wp⟦prog⟧ that translates monadic programs into this logic.\nA weakest precondition semantics is an interpretation of programs as mappings from postconditions to the weakest precondition that the program would require to ensure the postcondition; in this interpretation, programs are understood as predicate transformers.\nThe Hoare triple syntax is notation for Std.Do.Triple:-- This is the definition of Std.Do.Triple:\ndef Triple [WP m ps] {α : Type u} (prog : m α)\n    (P : Assertion ps) (Q : PostCond α ps) : Prop :=\n  P ⊢ₛ wp⟦prog⟧ Q\nThe WP type class maps a monad m to its PostShape ps, and this PostShape governs the exact shape of the Std.Do.Triple.\nMany of the standard monad transformers such as StateT, ReaderT and ExceptT come with a canonical WP instance.\nFor example, StateT σ comes with a WP instance that adds a σ argument to every Assertion.\nStateful entailment ⊢ₛ eta-expands through these additional σ arguments.\nFor StateM programs, the following type is definitionally equivalent to Std.Do.Triple:def StateMTriple {α σ : Type u} (prog : StateM σ α)\n    (P : σ → ULift Prop) (Q : (α → σ → ULift Prop) × PUnit) : Prop :=\n  ∀ s, (P s).down → let (a, s') := prog.run s; (Q.1 a s').down\nThe common postcondition notation ⇓ r => ... injects an assertion of type α → Assertion ps into\nPostCond α ps (the ⇓ is meant to be parsed like fun); in case of StateM by adjoining it with an empty tuple PUnit.unit.\nThe shape of postconditions becomes more interesting once exceptions enter the picture.\nThe notation ⌜p⌝ embeds a pure hypotheses p into a stateful assertion.\nVice versa, any stateful hypothesis P is called pure if it is equivalent to ⌜p⌝\nfor some p.\nPure, stateful hypotheses may be freely moved into the regular Lean context and back.\n(This can be done manually with the mpure tactic.)\n\n","context":"Lean Reference\u0009The  mvcgen  tactic\u0009Verifying Imperative Programs Using  mvcgen\u0009Compositional Reasoning About Effectful Programs Using Hoare Triples","header":"18.1.4.1. Hoare Triples","id":"/The--mvcgen--tactic/#The-Lean-Language-Reference--The--mvcgen--tactic--Verifying-Imperative-Programs-Using--mvcgen--Compositional-Reasoning-About-Effectful-Programs-Using-Hoare-Triples--Hoare-Triples"},"/Type-Classes/Basic-Classes/#The-Lean-Language-Reference--Type-Classes--Basic-Classes--Subsingleton-Types":{"contents":"A subsingleton is a type with at most one element. It is either empty or has a unique element.All propositions are subsingletons because of proof irrelevance: false propositions are empty, and\nall proofs of a true proposition are equal to one another. Some non-propositional types are also\nsubsingletons.Prove that α is a subsingleton by showing that any two elements are equal.Any two elements of a subsingleton are equal.\n\nIf a type is a subsingleton, then all of its elements are equal.\n\nIf two types are equal and one of them is a subsingleton, then all of their elements are\nheterogeneously equal.\n\n","context":"Lean Reference\u0009Type Classes\u0009Basic Classes","header":"11.5.6. Subsingleton Types","id":"/Type-Classes/Basic-Classes/#The-Lean-Language-Reference--Type-Classes--Basic-Classes--Subsingleton-Types"},"/releases/v4.8.0/#release-v4___8___0":{"contents":"\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n","context":"Lean Reference\u0009Release Notes","header":"Lean 4.8.0 (2024-06-05)","id":"/releases/v4.8.0/#release-v4___8___0"}});